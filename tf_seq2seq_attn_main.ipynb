{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_seq2seq_attn_main.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "pCor_QpNH2v2",
        "Z5kGD2XaVs_I",
        "oRlvnjN2brFN",
        "BD2K-vW6YVSX",
        "MxTYP4xOZSEb",
        "PyUwjTBBDYUz"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO1nuF2A7+ERKp61L2eEUOv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhavnicksm/marathi-neural-machine-translation/blob/main/tf_seq2seq_attn_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m8OV0wClQDQ"
      },
      "source": [
        "Before beginning this notebook, ensure that you have data.csv in available in the working directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diGgpmn6_hO5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdc123fb-ed71-4e87-fa4a-4c58d457c049"
      },
      "source": [
        "!pip install torchtext==0.8.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/23/8499af6d9c22b29b01f66a2c11d38ce71cd1cafa2655913c29818ed4a00f/torchtext-0.8.0-cp36-cp36m-manylinux1_x86_64.whl (6.9MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9MB 33.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.8.0) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.8.0) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.8.0) (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.8.0) (1.7.0+cu101)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.8.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.8.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.8.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.8.0) (1.24.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.8.0) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.8.0) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.8.0) (0.8)\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed torchtext-0.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vdbql_pf8PhO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34a05e91-2a4f-4fd7-a139-c6a1c3b4e122"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (53.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkCLyMjMK0g_"
      },
      "source": [
        "## Hyperparameter declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-VxIa3PK5ZA"
      },
      "source": [
        "from argparse import Namespace"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mnp0_Z41K9OS"
      },
      "source": [
        "hype = Namespace(\r\n",
        "    LR = 0.00001,\r\n",
        "    BATCH_SIZE = 64,\r\n",
        "    NUM_EPOCHS = 100,\r\n",
        "    CLIP = 1,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILw_JUj5MGTP"
      },
      "source": [
        "model_hype = Namespace(\r\n",
        "    EMBEDDING_SIZE = 8,\r\n",
        "    GRU_UNITS = 256,\r\n",
        "    ATTN_SIZE = 2,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDHMJQQALwNZ",
        "outputId": "907d0c5f-00b8-4d80-8279-42d43a650d1e"
      },
      "source": [
        "#example usage\r\n",
        "hype.BATCH_SIZE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqxGUlxQNzEo",
        "outputId": "6fc418e0-7621-4c6f-e35d-a11b80657650"
      },
      "source": [
        "#to dict\r\n",
        "vars(hype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'BATCH_SIZE': 64, 'CLIP': 1, 'LR': 0.01, 'NUM_EPOCHS': 100}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wznA4tHCk3ZN"
      },
      "source": [
        "## Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRM-bUZo60qp"
      },
      "source": [
        "### Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2-a9XNPlOym"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "K1ftPojC5LWC",
        "outputId": "e86fb605-295c-4799-c6a4-e946aef00aeb"
      },
      "source": [
        "data = pd.read_csv('data.csv', header=None)\r\n",
        "data.columns = ['english', 'marathi']\r\n",
        "data.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>marathi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>40746</th>\n",
              "      <td>Just saying you don't like fish because of the...</td>\n",
              "      <td>हड्डींमुळे मासे आवडत नाही असं म्हणणं हे काय मा...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40747</th>\n",
              "      <td>The Japanese Parliament today officially elect...</td>\n",
              "      <td>आज जपानी संसदेने अधिकृतरित्या र्‍यौतारौ हाशिमो...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40748</th>\n",
              "      <td>Tom tried to sell his old VCR instead of throw...</td>\n",
              "      <td>टॉमने त्याचा जुना व्ही.सी.आर फेकून टाकण्याऐवजी...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40749</th>\n",
              "      <td>You can't view Flash content on an iPad. Howev...</td>\n",
              "      <td>आयपॅडवर फ्लॅश आशय बघता येत नाही. पण तुम्ही त्य...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40750</th>\n",
              "      <td>In 1969, Roger Miller recorded a song called \"...</td>\n",
              "      <td>१९६९मध्ये रॉजर मिलरने \"यू डोन्ट वॉन्ट माय लव्ह...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 english                                            marathi\n",
              "40746  Just saying you don't like fish because of the...  हड्डींमुळे मासे आवडत नाही असं म्हणणं हे काय मा...\n",
              "40747  The Japanese Parliament today officially elect...  आज जपानी संसदेने अधिकृतरित्या र्‍यौतारौ हाशिमो...\n",
              "40748  Tom tried to sell his old VCR instead of throw...  टॉमने त्याचा जुना व्ही.सी.आर फेकून टाकण्याऐवजी...\n",
              "40749  You can't view Flash content on an iPad. Howev...  आयपॅडवर फ्लॅश आशय बघता येत नाही. पण तुम्ही त्य...\n",
              "40750  In 1969, Roger Miller recorded a song called \"...  १९६९मध्ये रॉजर मिलरने \"यू डोन्ट वॉन्ट माय लव्ह..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La4DKCxV65JZ"
      },
      "source": [
        "### Building tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0le-1MgY5N3",
        "outputId": "eab3ae0d-5ae5-41fc-b2e3-fdec6a50c186"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.preprocessing import text\r\n",
        "from tensorflow.keras.preprocessing import sequence\r\n",
        "\r\n",
        "import re\r\n",
        "import string\r\n",
        "\r\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zvkz5RLnbBnq"
      },
      "source": [
        "def sep_punk(text):\r\n",
        "  for punk in string.punctuation:\r\n",
        "    text = text.replace(punk,\" \"+punk+\" \")\r\n",
        "  return text\r\n",
        "\r\n",
        "def add_init_token(sent_list):\r\n",
        "  new_sent_list = []\r\n",
        "  for sent in sent_list:\r\n",
        "    sent = sep_punk(sent)\r\n",
        "    sent = '<sos> ' + sent + ' <eos>'\r\n",
        "    new_sent_list.append(sent)\r\n",
        "\r\n",
        "  return new_sent_list    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rvtzx8peSqI"
      },
      "source": [
        "mar_list = list(data['marathi'])\r\n",
        "eng_list = list(data['english'])\r\n",
        "\r\n",
        "mar_list = add_init_token(mar_list)\r\n",
        "eng_list = add_init_token(eng_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MEWxWBge5KQ",
        "outputId": "471a1517-eff6-42d0-cc71-f7f60604e3fb"
      },
      "source": [
        "print(mar_list[100])\r\n",
        "print(eng_list[100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<sos> मी आहे !  <eos>\n",
            "<sos> It ' s me !  <eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ0NLlyiYy-a"
      },
      "source": [
        "def tokenize(sent_list):\r\n",
        "  tokenizer = text.Tokenizer(filters='')\r\n",
        "  tokenizer.fit_on_texts(sent_list)\r\n",
        "\r\n",
        "  tensor_list = tokenizer.texts_to_sequences(sent_list)\r\n",
        "  tensor_list = sequence.pad_sequences(tensor_list, padding='post')\r\n",
        "  \r\n",
        "  return {'Tensors': tensor_list, 'Tokenizer': tokenizer} "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fWvfmqviaYG"
      },
      "source": [
        "marathi = tokenize(sent_list=mar_list)\r\n",
        "english = tokenize(sent_list=eng_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xvatkmpznpnx",
        "outputId": "24abd5a3-3327-42e2-d717-cb906b24ef3f"
      },
      "source": [
        "mar_tokenizer = marathi['Tokenizer']\r\n",
        "eng_tokenizer = english['Tokenizer']\r\n",
        "\r\n",
        "print(f'The length of marathi vocab: {len(mar_tokenizer.word_index)}')\r\n",
        "print(f'The length of english vocab: {len(eng_tokenizer.word_index)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of marathi vocab: 13841\n",
            "The length of english vocab: 5715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhYYsIzKnvY8",
        "outputId": "8980b481-2e8c-4eda-f44d-daaf12b80349"
      },
      "source": [
        "mar_tensors = marathi['Tensors']\r\n",
        "eng_tensors = english['Tensors']\r\n",
        "\r\n",
        "print(f'Max length of sequence: {len(mar_tensors[0])}')\r\n",
        "print(f'Max length of sequence: {len(eng_tensors[0])}')\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max length of sequence: 44\n",
            "Max length of sequence: 50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9V2vLbF8sXd6",
        "outputId": "009ea849-3423-4af0-bb04-cc94221b1037"
      },
      "source": [
        "print(mar_tensors[0])\r\n",
        "print(eng_tensors[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  1 706   3   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0]\n",
            "[ 1 48  3  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SOsuFHSpZbA"
      },
      "source": [
        "### Implimenting TF Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LM20hTegrjI3"
      },
      "source": [
        "from tensorflow.data import Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTSwVN5gsLY6"
      },
      "source": [
        "BUFFER_SIZE = len(mar_tensors)\r\n",
        "BATCH_SIZE = hype.BATCH_SIZE\r\n",
        "\r\n",
        "dataset = Dataset.from_tensor_slices((mar_tensors, eng_tensors)).shuffle(BUFFER_SIZE, reshuffle_each_iteration=True)\r\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDvbQm1DuduE",
        "outputId": "63b6418b-62f0-448b-b015-3914c9ec387d"
      },
      "source": [
        "ex_mar_batch, ex_eng_batch = next(iter(dataset))\r\n",
        "print(ex_mar_batch.shape)\r\n",
        "print(ex_eng_batch.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 44)\n",
            "(64, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C35L-D1utri"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LadoJbptvE4a"
      },
      "source": [
        "from tensorflow import nn\r\n",
        "from tensorflow.keras import layers, Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7gTP9YY64sM"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMw78u1kvHu2"
      },
      "source": [
        "class Encoder(Model):\r\n",
        "  def __init__(self, vocab_size, embedding_size, enc_units, batch_size):\r\n",
        "    \r\n",
        "    super(Encoder, self).__init__()\r\n",
        "\r\n",
        "    self.batch_size = batch_size\r\n",
        "    self.enc_units = enc_units\r\n",
        "    self.embedding = layers.Embedding(vocab_size, embedding_size)\r\n",
        "    self.gru = layers.GRU(enc_units, return_sequences= True, return_state= True, recurrent_initializer='glorot_uniform')\r\n",
        "\r\n",
        "\r\n",
        "  def call(self, x, hidden):\r\n",
        "    x = self.embedding(x)\r\n",
        "    output, state = self.gru(x, initial_state=hidden)\r\n",
        "    return output,state\r\n",
        "\r\n",
        "  def initialize_hidden_state(self):\r\n",
        "    return tf.zeros((self.batch_size, self.enc_units))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKAKKKLC9a5l"
      },
      "source": [
        "mar_vocab_size = len(mar_tokenizer.word_index) + 1\r\n",
        "EMBEDDING_SIZE = model_hype.EMBEDDING_SIZE\r\n",
        "GRU_UNITS = model_hype.GRU_UNITS\r\n",
        "\r\n",
        "encoder = Encoder(mar_vocab_size, EMBEDDING_SIZE, GRU_UNITS, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kugg8Jj1AgPV",
        "outputId": "84f509df-0e06-4dec-d8c7-a48f591352d0"
      },
      "source": [
        "#Example input\r\n",
        "\r\n",
        "ex_hidden = encoder.initialize_hidden_state()\r\n",
        "sample_out, sample_hidden = encoder(ex_mar_batch, ex_hidden)\r\n",
        "\r\n",
        "print(sample_out.shape)\r\n",
        "print(sample_hidden.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 44, 256)\n",
            "(64, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BwKYo4qBz0_"
      },
      "source": [
        "### Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqR_Q13dB5lf"
      },
      "source": [
        "class Attention(layers.Layer):\r\n",
        "  def __init__(self, units):\r\n",
        "\r\n",
        "    super(Attention, self).__init__()\r\n",
        "    self.W1 = layers.Dense(units)\r\n",
        "    self.W2 = layers.Dense(units)\r\n",
        "    self.V = layers.Dense(1)\r\n",
        "\r\n",
        "  def call(self, q, val):\r\n",
        "    #make q i.e. the hidden value into the same shape\r\n",
        "    q_with_time_axis = tf.expand_dims(q, 1)\r\n",
        "\r\n",
        "    score = self.V( nn.tanh( self.W1(q_with_time_axis) + self.W2(val) ) )\r\n",
        "\r\n",
        "    attention_w = nn.softmax(score, axis=1)\r\n",
        "\r\n",
        "    context_vec = attention_w * val\r\n",
        "    context_vec = tf.reduce_sum(context_vec, axis=1)\r\n",
        "\r\n",
        "    return context_vec, attention_w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5mexiuZB6t5"
      },
      "source": [
        "ATTN_SIZE = model_hype.ATTN_SIZE\r\n",
        "attention = Attention(ATTN_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoyIpD_JHsn2",
        "outputId": "2057ace7-7671-4f62-9df7-c2302b4408b6"
      },
      "source": [
        "#example code\r\n",
        "attn_res ,  attn_w = attention(sample_hidden, sample_out)\r\n",
        "print(attn_res.shape)\r\n",
        "print(attn_w.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 256)\n",
            "(64, 44, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCor_QpNH2v2"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMpa-eiBIALo"
      },
      "source": [
        "class Decoder(Model):\r\n",
        "\r\n",
        "  def __init__(self, vocab_size, embedding_size, dec_units, batch_size):\r\n",
        "    super(Decoder,self).__init__()\r\n",
        "\r\n",
        "    self.batch_size = batch_size\r\n",
        "    self.dec_units = dec_units\r\n",
        "    \r\n",
        "    self.embedding = layers.Embedding(vocab_size, embedding_size)\r\n",
        "    self.gru = layers.GRU(dec_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\r\n",
        "\r\n",
        "    self.fc = layers.Dense(vocab_size)\r\n",
        "\r\n",
        "    self.attention = Attention(dec_units)\r\n",
        "\r\n",
        "  def call(self, x, hidden, enc_out):\r\n",
        "    context_vec, attention_w = self.attention(hidden, enc_out)\r\n",
        "\r\n",
        "    x = self.embedding(x)\r\n",
        "\r\n",
        "    x = tf.concat([tf.expand_dims(context_vec, 1), x], axis=-1)\r\n",
        "\r\n",
        "    output, state = self.gru(x)\r\n",
        "\r\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\r\n",
        "\r\n",
        "    x = self.fc(output)\r\n",
        "\r\n",
        "    return x, state, attention_w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiZ7ouwZIBAV"
      },
      "source": [
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\r\n",
        "\r\n",
        "decoder = Decoder(eng_vocab_size, EMBEDDING_SIZE, GRU_UNITS, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaQLmkzWVB9I",
        "outputId": "c3279b85-53e3-401c-87d3-1a8051e6ccc0"
      },
      "source": [
        "#example code\r\n",
        "\r\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),sample_hidden, sample_out)\r\n",
        "\r\n",
        "print (sample_decoder_output.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 5716)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwffpIeIVLqn"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5kGD2XaVs_I"
      },
      "source": [
        "### Optimizers and Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnh5QPXBVwW9"
      },
      "source": [
        "from tensorflow.keras import optimizers as optim\r\n",
        "from tensorflow.keras import losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD9cEv6fV_d7"
      },
      "source": [
        "optimizer = optim.Adam(learning_rate=hype.LR)\r\n",
        "criteria = losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\r\n",
        "\r\n",
        "def loss_function(real, pred):\r\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\r\n",
        "  loss = criteria(real, pred)\r\n",
        "\r\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)\r\n",
        "  loss = loss*mask\r\n",
        "\r\n",
        "  return tf.reduce_mean(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyA6rWvdU3qP",
        "outputId": "7111e4dc-b6f7-4337-ebd2-1b6156d1c26e"
      },
      "source": [
        "optimizer.learning_rate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-05>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRlvnjN2brFN"
      },
      "source": [
        "### Azure Blob set-up and loading\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-be280Axbu7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb7aa844-18e3-4181-c58c-89a3f7ec9f7c"
      },
      "source": [
        "pip install azure-storage-blob"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting azure-storage-blob\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/00/6772472a99cd0a5e74e4e90f87947fa041b37981a3ff93d883cbc450518d/azure_storage_blob-12.7.1-py2.py3-none-any.whl (339kB)\n",
            "\r\u001b[K     |█                               | 10kB 26.4MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 31.6MB/s eta 0:00:01\r\u001b[K     |███                             | 30kB 23.1MB/s eta 0:00:01\r\u001b[K     |███▉                            | 40kB 26.6MB/s eta 0:00:01\r\u001b[K     |████▉                           | 51kB 25.6MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 61kB 28.4MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 71kB 18.4MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 81kB 19.4MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 92kB 17.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 102kB 17.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 112kB 17.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 122kB 17.9MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 133kB 17.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 143kB 17.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 153kB 17.9MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 163kB 17.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 174kB 17.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 184kB 17.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 194kB 17.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 204kB 17.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 215kB 17.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 225kB 17.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 235kB 17.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 245kB 17.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 256kB 17.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 266kB 17.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 276kB 17.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 286kB 17.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 296kB 17.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 307kB 17.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 317kB 17.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 327kB 17.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 337kB 17.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 348kB 17.9MB/s \n",
            "\u001b[?25hCollecting azure-core<2.0.0,>=1.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/9e/6bb67fe85f6a89d71f50c86a0da778a5064f749a485ed9ba498067034227/azure_core-1.10.0-py2.py3-none-any.whl (125kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 58.1MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.1.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/de/7054df0620b5411ba45480f0261e1fb66a53f3db31b28e3aa52c026e72d9/cryptography-3.3.1-cp36-abi3-manylinux2010_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 56.9MB/s \n",
            "\u001b[?25hCollecting msrest>=0.6.18\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/cc/6c96bfb3d3cf4c3bdedfa6b46503223f4c2a4fa388377697e0f8082a4fed/msrest-0.6.21-py2.py3-none-any.whl (85kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 13.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from azure-core<2.0.0,>=1.10.0->azure-storage-blob) (2.23.0)\n",
            "Requirement already satisfied: six>=1.6 in /usr/local/lib/python3.6/dist-packages (from azure-core<2.0.0,>=1.10.0->azure-storage-blob) (1.15.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.1.4->azure-storage-blob) (1.14.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from msrest>=0.6.18->azure-storage-blob) (2020.12.5)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from msrest>=0.6.18->azure-storage-blob) (1.3.0)\n",
            "Collecting isodate>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.10.0->azure-storage-blob) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.10.0->azure-storage-blob) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.10.0->azure-storage-blob) (2.10)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob) (2.20)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-storage-blob) (3.1.0)\n",
            "Installing collected packages: azure-core, cryptography, isodate, msrest, azure-storage-blob\n",
            "Successfully installed azure-core-1.10.0 azure-storage-blob-12.7.1 cryptography-3.3.1 isodate-0.6.0 msrest-0.6.21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSo4NhBweZma",
        "outputId": "cec8ae1e-3b9b-4ff8-a917-4ebfa1bac2ef"
      },
      "source": [
        "import os, uuid\r\n",
        "from azure.storage import blob\r\n",
        "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient, __version__\r\n",
        "print(__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBx6J1OEzy89"
      },
      "source": [
        "os.mkdir(\"tf_checkpoint\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PDZyfMTb2OF"
      },
      "source": [
        "connect_str = \"DefaultEndpointsProtocol=https;AccountName=tfmodel;AccountKey=PinzJZWJy/mFOWDgkBcCTPA9Fnfr7/qvaZSbjxQVH4YGrBt4MseqbKYjUGNKYX9PpBh+zgAk6uDrVpmvejBCiw==;EndpointSuffix=core.windows.net\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Sc3KtIbeM05"
      },
      "source": [
        "blob_service_client =  BlobServiceClient.from_connection_string(connect_str)\r\n",
        "container_client = blob_service_client.get_container_client(\"tf-ckpt\")\r\n",
        "blob_list = [blob.name for blob in container_client.list_blobs()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYKiqdOUmDLr"
      },
      "source": [
        "for file in blob_list:\r\n",
        "  blob_client = blob_service_client.get_blob_client('tf-ckpt', file)\r\n",
        "  with open('./tf_checkpoint/'+file, \"wb\") as f:\r\n",
        "    f.write(blob_client.download_blob().readall())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD2K-vW6YVSX"
      },
      "source": [
        "### Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLZIwVbXYZri"
      },
      "source": [
        "checkpoint_path = './tf_checkpoint'\r\n",
        "checkpoint = tf.train.Checkpoint(epoch=tf.Variable(1),\r\n",
        "                                 optimizer = optimizer,\r\n",
        "                                 encoder=encoder,\r\n",
        "                                 decoder=decoder,\r\n",
        "                                 )\r\n",
        "manager = tf.train.CheckpointManager(checkpoint, checkpoint_path, max_to_keep=1)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clFCC5V3Qk9I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5f83f47e-9a86-4737-968d-865b727eb804"
      },
      "source": [
        "manager.save()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./tf_checkpoint/ckpt-10'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7faMmu3U56K",
        "outputId": "dff80aa7-2929-44f3-c7d9-d7828a276e4c"
      },
      "source": [
        "manager.checkpoints"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./tf_checkpoint/ckpt-10']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CWrLTO4JWLBk",
        "outputId": "a460e8b3-cb88-409d-ed24-75a63b172e88"
      },
      "source": [
        "manager.restore_or_initialize()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./tf_checkpoint/ckpt-10'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxTYP4xOZSEb"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtJK_B3xcks6"
      },
      "source": [
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fFng4yJZVtN"
      },
      "source": [
        "@tf.function\r\n",
        "def train_step(src, trg, enc_hidden):\r\n",
        "  loss = 0\r\n",
        "\r\n",
        "\r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    enc_out, enc_hidden = encoder(src, enc_hidden)\r\n",
        "\r\n",
        "    dec_hidden = enc_hidden\r\n",
        "\r\n",
        "    dec_input = tf.expand_dims([eng_tokenizer.word_index['<sos>']]*BATCH_SIZE, 1)\r\n",
        "\r\n",
        "    for t in range(1, trg.shape[1]):\r\n",
        "\r\n",
        "      pred, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_out)\r\n",
        "\r\n",
        "      loss += loss_function(trg[:,t], pred)\r\n",
        "\r\n",
        "      dec_input = tf.expand_dims(trg[:,t],1)\r\n",
        "\r\n",
        "  \r\n",
        "  batch_loss = loss/ int(trg.shape[1])\r\n",
        "\r\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\r\n",
        "\r\n",
        "  grads = tape.gradient(loss,variables)\r\n",
        "\r\n",
        "  optimizer.apply_gradients(zip(grads, variables))\r\n",
        "\r\n",
        "  return batch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7JXc0-gxb_TV",
        "outputId": "69e131a9-8e27-4a72-9a06-c84f92d3e573"
      },
      "source": [
        "EPOCHS = 50\r\n",
        "steps_per_epoch = len(mar_tensors)//BATCH_SIZE\r\n",
        "\r\n",
        "\r\n",
        "for epoch in range(EPOCHS):\r\n",
        "  start = time.time()\r\n",
        "\r\n",
        "  enc_hidden = encoder.initialize_hidden_state()\r\n",
        "\r\n",
        "  total_loss = 0\r\n",
        "\r\n",
        "  for (batch, (src,trg)) in enumerate(dataset.take(steps_per_epoch)):\r\n",
        "\r\n",
        "    batch_loss = train_step(src, trg, enc_hidden)\r\n",
        "\r\n",
        "    total_loss += batch_loss\r\n",
        "\r\n",
        "    if batch%100 == 0:\r\n",
        "      print(f'Epoch {epoch} Batch {batch} Loss{batch_loss.numpy():.4f}')\r\n",
        "\r\n",
        "  \r\n",
        "  if (epoch+1)%2 == 0:\r\n",
        "    manager.save()\r\n",
        "\r\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\r\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 0 Loss0.0183\n",
            "Epoch 0 Batch 100 Loss0.0073\n",
            "Epoch 0 Batch 200 Loss0.0141\n",
            "Epoch 0 Batch 300 Loss0.0104\n",
            "Epoch 0 Batch 400 Loss0.0096\n",
            "Epoch 0 Batch 500 Loss0.0168\n",
            "Epoch 0 Batch 600 Loss0.0136\n",
            "Epoch 1 Loss 0.0149\n",
            "Time taken for 1 epoch 61.20926761627197 sec\n",
            "\n",
            "Epoch 1 Batch 0 Loss0.0078\n",
            "Epoch 1 Batch 100 Loss0.0165\n",
            "Epoch 1 Batch 200 Loss0.0123\n",
            "Epoch 1 Batch 300 Loss0.0228\n",
            "Epoch 1 Batch 400 Loss0.0091\n",
            "Epoch 1 Batch 500 Loss0.0130\n",
            "Epoch 1 Batch 600 Loss0.0126\n",
            "Epoch 2 Loss 0.0149\n",
            "Time taken for 1 epoch 60.95401334762573 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss0.0244\n",
            "Epoch 2 Batch 100 Loss0.0159\n",
            "Epoch 2 Batch 200 Loss0.0139\n",
            "Epoch 2 Batch 300 Loss0.0185\n",
            "Epoch 2 Batch 400 Loss0.0213\n",
            "Epoch 2 Batch 500 Loss0.0174\n",
            "Epoch 2 Batch 600 Loss0.0095\n",
            "Epoch 3 Loss 0.0149\n",
            "Time taken for 1 epoch 60.842631578445435 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss0.0198\n",
            "Epoch 3 Batch 100 Loss0.0186\n",
            "Epoch 3 Batch 200 Loss0.0125\n",
            "Epoch 3 Batch 300 Loss0.0118\n",
            "Epoch 3 Batch 400 Loss0.0213\n",
            "Epoch 3 Batch 500 Loss0.0106\n",
            "Epoch 3 Batch 600 Loss0.0166\n",
            "Epoch 4 Loss 0.0149\n",
            "Time taken for 1 epoch 60.931883335113525 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss0.0147\n",
            "Epoch 4 Batch 100 Loss0.0163\n",
            "Epoch 4 Batch 200 Loss0.0148\n",
            "Epoch 4 Batch 300 Loss0.0184\n",
            "Epoch 4 Batch 400 Loss0.0145\n",
            "Epoch 4 Batch 500 Loss0.0132\n",
            "Epoch 4 Batch 600 Loss0.0141\n",
            "Epoch 5 Loss 0.0149\n",
            "Time taken for 1 epoch 60.83014965057373 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss0.0199\n",
            "Epoch 5 Batch 100 Loss0.0118\n",
            "Epoch 5 Batch 200 Loss0.0148\n",
            "Epoch 5 Batch 300 Loss0.0100\n",
            "Epoch 5 Batch 400 Loss0.0141\n",
            "Epoch 5 Batch 500 Loss0.0099\n",
            "Epoch 5 Batch 600 Loss0.0132\n",
            "Epoch 6 Loss 0.0148\n",
            "Time taken for 1 epoch 61.082314014434814 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss0.0124\n",
            "Epoch 6 Batch 100 Loss0.0125\n",
            "Epoch 6 Batch 200 Loss0.0153\n",
            "Epoch 6 Batch 300 Loss0.0115\n",
            "Epoch 6 Batch 400 Loss0.0205\n",
            "Epoch 6 Batch 500 Loss0.0139\n",
            "Epoch 6 Batch 600 Loss0.0115\n",
            "Epoch 7 Loss 0.0148\n",
            "Time taken for 1 epoch 60.4655077457428 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss0.0133\n",
            "Epoch 7 Batch 100 Loss0.0160\n",
            "Epoch 7 Batch 200 Loss0.0192\n",
            "Epoch 7 Batch 300 Loss0.0190\n",
            "Epoch 7 Batch 400 Loss0.0128\n",
            "Epoch 7 Batch 500 Loss0.0128\n",
            "Epoch 7 Batch 600 Loss0.0105\n",
            "Epoch 8 Loss 0.0148\n",
            "Time taken for 1 epoch 60.785664558410645 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss0.0167\n",
            "Epoch 8 Batch 100 Loss0.0157\n",
            "Epoch 8 Batch 200 Loss0.0215\n",
            "Epoch 8 Batch 300 Loss0.0138\n",
            "Epoch 8 Batch 400 Loss0.0135\n",
            "Epoch 8 Batch 500 Loss0.0112\n",
            "Epoch 8 Batch 600 Loss0.0158\n",
            "Epoch 9 Loss 0.0148\n",
            "Time taken for 1 epoch 60.8827269077301 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss0.0131\n",
            "Epoch 9 Batch 100 Loss0.0209\n",
            "Epoch 9 Batch 200 Loss0.0084\n",
            "Epoch 9 Batch 300 Loss0.0159\n",
            "Epoch 9 Batch 400 Loss0.0090\n",
            "Epoch 9 Batch 500 Loss0.0141\n",
            "Epoch 9 Batch 600 Loss0.0197\n",
            "Epoch 10 Loss 0.0148\n",
            "Time taken for 1 epoch 61.009618282318115 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss0.0154\n",
            "Epoch 10 Batch 100 Loss0.0227\n",
            "Epoch 10 Batch 200 Loss0.0156\n",
            "Epoch 10 Batch 300 Loss0.0150\n",
            "Epoch 10 Batch 400 Loss0.0108\n",
            "Epoch 10 Batch 500 Loss0.0128\n",
            "Epoch 10 Batch 600 Loss0.0147\n",
            "Epoch 11 Loss 0.0148\n",
            "Time taken for 1 epoch 61.021387577056885 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss0.0096\n",
            "Epoch 11 Batch 100 Loss0.0117\n",
            "Epoch 11 Batch 200 Loss0.0148\n",
            "Epoch 11 Batch 300 Loss0.0102\n",
            "Epoch 11 Batch 400 Loss0.0136\n",
            "Epoch 11 Batch 500 Loss0.0137\n",
            "Epoch 11 Batch 600 Loss0.0213\n",
            "Epoch 12 Loss 0.0148\n",
            "Time taken for 1 epoch 60.87447381019592 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss0.0141\n",
            "Epoch 12 Batch 100 Loss0.0189\n",
            "Epoch 12 Batch 200 Loss0.0095\n",
            "Epoch 12 Batch 300 Loss0.0187\n",
            "Epoch 12 Batch 400 Loss0.0146\n",
            "Epoch 12 Batch 500 Loss0.0120\n",
            "Epoch 12 Batch 600 Loss0.0115\n",
            "Epoch 13 Loss 0.0147\n",
            "Time taken for 1 epoch 60.9293270111084 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss0.0125\n",
            "Epoch 13 Batch 100 Loss0.0131\n",
            "Epoch 13 Batch 200 Loss0.0175\n",
            "Epoch 13 Batch 300 Loss0.0118\n",
            "Epoch 13 Batch 400 Loss0.0161\n",
            "Epoch 13 Batch 500 Loss0.0153\n",
            "Epoch 13 Batch 600 Loss0.0144\n",
            "Epoch 14 Loss 0.0147\n",
            "Time taken for 1 epoch 61.016213178634644 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss0.0077\n",
            "Epoch 14 Batch 100 Loss0.0122\n",
            "Epoch 14 Batch 200 Loss0.0187\n",
            "Epoch 14 Batch 300 Loss0.0233\n",
            "Epoch 14 Batch 400 Loss0.0182\n",
            "Epoch 14 Batch 500 Loss0.0223\n",
            "Epoch 14 Batch 600 Loss0.0117\n",
            "Epoch 15 Loss 0.0147\n",
            "Time taken for 1 epoch 61.067235231399536 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss0.0129\n",
            "Epoch 15 Batch 100 Loss0.0157\n",
            "Epoch 15 Batch 200 Loss0.0191\n",
            "Epoch 15 Batch 300 Loss0.0150\n",
            "Epoch 15 Batch 400 Loss0.0117\n",
            "Epoch 15 Batch 500 Loss0.0130\n",
            "Epoch 15 Batch 600 Loss0.0153\n",
            "Epoch 16 Loss 0.0147\n",
            "Time taken for 1 epoch 61.04212546348572 sec\n",
            "\n",
            "Epoch 16 Batch 0 Loss0.0095\n",
            "Epoch 16 Batch 100 Loss0.0116\n",
            "Epoch 16 Batch 200 Loss0.0132\n",
            "Epoch 16 Batch 300 Loss0.0139\n",
            "Epoch 16 Batch 400 Loss0.0136\n",
            "Epoch 16 Batch 500 Loss0.0166\n",
            "Epoch 16 Batch 600 Loss0.0132\n",
            "Epoch 17 Loss 0.0147\n",
            "Time taken for 1 epoch 61.08282279968262 sec\n",
            "\n",
            "Epoch 17 Batch 0 Loss0.0184\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-206-5dc85fd6dc0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mOCVNMNqC9Km",
        "outputId": "d1ef3070-8e7a-4896-ee89-6a24f3268135"
      },
      "source": [
        "manager.save()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./tf_checkpoint/ckpt-229'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyUwjTBBDYUz"
      },
      "source": [
        "### Saving in blob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1Snhyf3pmiR"
      },
      "source": [
        "**Caution:** Only change this in case you wish to permanently change the model file. Do not change this otherwise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxkjZlsTi_Ks",
        "outputId": "6e2fee64-dfcd-4645-9ca1-52a265931358"
      },
      "source": [
        "blob_list = [blob.name for blob in container_client.list_blobs()]\r\n",
        "blob_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['checkpoint', 'ckpt-229.data-00000-of-00001', 'ckpt-229.index']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7YFVlchDcDG"
      },
      "source": [
        "# clear the blob\r\n",
        "for file_name in blob_list:\r\n",
        "  container_client.delete_blob(blob=file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukrq_eQNEVfJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11c477f4-9faf-4382-d168-114891a65783"
      },
      "source": [
        "# getting the file names\r\n",
        "files = os.listdir('./tf_checkpoint')\r\n",
        "files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ckpt-229.data-00000-of-00001', 'ckpt-229.index', 'checkpoint']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FegNMHjxEjGf"
      },
      "source": [
        "# uploading the files\r\n",
        "for file in files:\r\n",
        "  blob_client = container_client.get_blob_client(file)\r\n",
        "  with open(\"./tf_checkpoint/\" + file,\"rb\") as data:\r\n",
        "    blob_client.upload_blob(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0irQlukDUrU"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp4TCi25u8Xq"
      },
      "source": [
        "from matplotlib import ticker"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IBuyk-Dekcx"
      },
      "source": [
        "def evaluate(sentence):\r\n",
        "  attention_plot = np.zeros((eng_tensors.shape[1],mar_tensors.shape[1]))\r\n",
        "\r\n",
        "  sentence = sep_punk(sentence)\r\n",
        "\r\n",
        "  inputs = [mar_tokenizer.word_index[i] for i in sentence.lower().split(' ') if i!='']\r\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\r\n",
        "                                                         maxlen=mar_tensors.shape[1],\r\n",
        "                                                         padding='post')\r\n",
        "  inputs = tf.convert_to_tensor(inputs)\r\n",
        "\r\n",
        "  result = []\r\n",
        "\r\n",
        "  hidden = [tf.zeros((1, GRU_UNITS))]\r\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\r\n",
        "\r\n",
        "  dec_hidden = enc_hidden\r\n",
        "  dec_input = tf.expand_dims([eng_tokenizer.word_index['<sos>']], 0)\r\n",
        "\r\n",
        "  for t in range(eng_tensors.shape[1]):\r\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\r\n",
        "                                                         dec_hidden,\r\n",
        "                                                         enc_out)\r\n",
        "\r\n",
        "    # storing the attention weights to plot later on\r\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\r\n",
        "    attention_plot[t] = attention_weights.numpy()\r\n",
        "\r\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\r\n",
        "\r\n",
        "    result.append(eng_tokenizer.index_word[predicted_id])\r\n",
        "\r\n",
        "    if eng_tokenizer.index_word[predicted_id] == '<eos>':\r\n",
        "      return result, sentence, attention_plot\r\n",
        "\r\n",
        "    # the predicted ID is fed back into the model\r\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\r\n",
        "\r\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "AbwQr01qsZI-",
        "outputId": "0ca43b18-8b0a-4e2b-e41f-51c591ecc051"
      },
      "source": [
        "res, sentence , _ = evaluate(data['marathi'][20222])\r\n",
        "\r\n",
        "\r\n",
        "print(sentence)\r\n",
        "print(data['english'][20222])\r\n",
        "print(res)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-ce1864da2b2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'marathi'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20222\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20222\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '_io.BufferedReader' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoyusI6ZQuFx"
      },
      "source": [
        "# BLEU Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW451gOXxAzQ"
      },
      "source": [
        "from torchtext.data.metrics import bleu_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqS9X-RowQrQ"
      },
      "source": [
        "def calculate_bleu_score(data):\r\n",
        "  \r\n",
        "  trgs = []\r\n",
        "  preds = []\r\n",
        "\r\n",
        "  for i in range(len(data)):\r\n",
        "    src = data['marathi'][i]\r\n",
        "    trg = data['english'][i]\r\n",
        "\r\n",
        "    trg = [tok for tok in sep_punk(trg).split(\" \") if tok!='']\r\n",
        "\r\n",
        "    pred, _, _ = evaluate(src)\r\n",
        "\r\n",
        "    #preds.append(trg)\r\n",
        "    preds.append(pred[:-1])\r\n",
        "    trgs.append([trg])\r\n",
        "\r\n",
        "  return bleu_score(preds, trgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7CiLX7ikxAGD",
        "outputId": "15ad168b-7053-488d-f984-3cda6afbc9ab"
      },
      "source": [
        "bleu = calculate_bleu_score(data)\r\n",
        "print(f\"The BLEU score is {bleu*100:.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-ac3fd1410242>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbleu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_bleu_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The BLEU score is {bleu*100:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-a7dbe7c4ed57>\u001b[0m in \u001b[0;36mcalculate_bleu_score\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtok\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msep_punk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#preds.append(trg)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-9034780183a3>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     21\u001b[0m     predictions, dec_hidden, attention_weights = decoder(dec_input,\n\u001b[1;32m     22\u001b[0m                                                          \u001b[0mdec_hidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                                                          enc_out)\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# storing the attention weights to plot later on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-2c51d278be01>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, hidden, enc_out)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mcontext_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-19ace7a723f2>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, q, val)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mq_with_time_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_with_time_axis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mattention_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1212\u001b[0;31m         dtype=self._compute_dtype_object)\n\u001b[0m\u001b[1;32m   1213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/ops/core.py\u001b[0m in \u001b[0;36mdense\u001b[0;34m(inputs, kernel, bias, activation, dtype)\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0;31m# Broadcast kernel to inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandard_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m# Reshape the output back to the original ndim of the input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mtensordot\u001b[0;34m(a, b, axes, name)\u001b[0m\n\u001b[1;32m   4613\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tensordot\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4614\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4615\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4616\u001b[0m     \u001b[0ma_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensordot_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4617\u001b[0m     \u001b[0ma_reshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_free_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_free_dims_static\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensordot_reshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_dense_var_to_tensor\u001b[0;34m(var, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_dense_var_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1992\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_var_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_dense_var_to_tensor\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1391\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1393\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iadd__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_other\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mvalue\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    563\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_existing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    670\u001b[0m           \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mread_and_set_handle\u001b[0;34m()\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m       result = gen_resource_variable_ops.read_variable_op(\n\u001b[0;32m--> 663\u001b[0;31m           self._handle, self._dtype)\n\u001b[0m\u001b[1;32m    664\u001b[0m       \u001b[0m_maybe_set_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mread_variable_op\u001b[0;34m(resource, dtype, name)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m--> 471\u001b[0;31m         _ctx, \"ReadVariableOp\", name, resource, \"dtype\", dtype)\n\u001b[0m\u001b[1;32m    472\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS3GjYiXS2I6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "7c14f597-9c1b-44bc-fe99-478c5d9ae8da"
      },
      "source": [
        "trgs = []\r\n",
        "preds = []\r\n",
        "\r\n",
        "for i in range(len(data)):\r\n",
        "  src = data['marathi'][i]\r\n",
        "  trg = data['english'][i]\r\n",
        "\r\n",
        "  trg = [tok for tok in sep_punk(trg).split(\" \") if tok!='']\r\n",
        "\r\n",
        "  pred, _, _ = evaluate(src)\r\n",
        "\r\n",
        "  #preds.append(trg)\r\n",
        "  preds.append(pred[:-1])\r\n",
        "  trgs.append([trg])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-d9ffde54a69e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mtrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtok\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msep_punk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m#preds.append(trg)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-9034780183a3>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     21\u001b[0m     predictions, dec_hidden, attention_weights = decoder(dec_input,\n\u001b[1;32m     22\u001b[0m                                                          \u001b[0mdec_hidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                                                          enc_out)\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# storing the attention weights to plot later on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-2c51d278be01>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, hidden, enc_out)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mcontext_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-19ace7a723f2>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, q, val)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mq_with_time_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_with_time_axis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mattention_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_autographed_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6618\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6620\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6621\u001b[0m     \"\"\"Start the scope block.\n\u001b[1;32m   6622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0InokXUYcOT",
        "outputId": "fa7586be-6700-476b-a1bb-78a94eba0150"
      },
      "source": [
        "bleu_score(preds, trgs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5000459551811218"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VolGCINWccO3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}