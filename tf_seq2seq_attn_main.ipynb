{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_seq2seq_attn_main.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO8P9yjdxBKQzNo+IZrWXFQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhavnicksm/marathi-neural-machine-translation/blob/main/tf_seq2seq_attn_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m8OV0wClQDQ"
      },
      "source": [
        "Before beginning this notebook, ensure that you have data.csv in available in the working directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diGgpmn6_hO5"
      },
      "source": [
        "#!pip install torchtext==0.8.0"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vdbql_pf8PhO"
      },
      "source": [
        "#!python -m spacy download en"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkCLyMjMK0g_"
      },
      "source": [
        "## Hyperparameter declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-VxIa3PK5ZA"
      },
      "source": [
        "from argparse import Namespace"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mnp0_Z41K9OS"
      },
      "source": [
        "hype = Namespace(\r\n",
        "    LR = 0.01,\r\n",
        "    BATCH_SIZE = 128,\r\n",
        "    NUM_EPOCHS = 100,\r\n",
        "    CLIP = 1,\r\n",
        "    DEVICE = None,\r\n",
        "    save_checkpoint =True,\r\n",
        "    load_checkpoint = False\r\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILw_JUj5MGTP"
      },
      "source": [
        "checkpoint = Namespace(\r\n",
        "    epoch_num = 0,\r\n",
        "    model_params = None,\r\n",
        "    optim_params = None,\r\n",
        "    scheduler_params = None,\r\n",
        "    losses = [],\r\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDHMJQQALwNZ",
        "outputId": "c5910ef8-5eaa-46c9-ac57-b73bfc11b197"
      },
      "source": [
        "#example usage\r\n",
        "hype.BATCH_SIZE"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqxGUlxQNzEo",
        "outputId": "fec19cd1-cd42-44b5-c08a-b818c78a8ec1"
      },
      "source": [
        "#to dict\r\n",
        "vars(hype)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'BATCH_SIZE': 128,\n",
              " 'CLIP': 1,\n",
              " 'DEVICE': None,\n",
              " 'LR': 0.01,\n",
              " 'NUM_EPOCHS': 100,\n",
              " 'load_checkpoint': False,\n",
              " 'save_checkpoint': True}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wznA4tHCk3ZN"
      },
      "source": [
        "## Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRM-bUZo60qp"
      },
      "source": [
        "### Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2-a9XNPlOym"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "%matplotlib inline"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "K1ftPojC5LWC",
        "outputId": "90bebbc3-5e89-417f-afeb-5b5bbf526004"
      },
      "source": [
        "data = pd.read_csv('data.csv', header=None)\r\n",
        "data.columns = ['english', 'marathi']\r\n",
        "data.tail()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>marathi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>40746</th>\n",
              "      <td>Just saying you don't like fish because of the...</td>\n",
              "      <td>हड्डींमुळे मासे आवडत नाही असं म्हणणं हे काय मा...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40747</th>\n",
              "      <td>The Japanese Parliament today officially elect...</td>\n",
              "      <td>आज जपानी संसदेने अधिकृतरित्या र्‍यौतारौ हाशिमो...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40748</th>\n",
              "      <td>Tom tried to sell his old VCR instead of throw...</td>\n",
              "      <td>टॉमने त्याचा जुना व्ही.सी.आर फेकून टाकण्याऐवजी...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40749</th>\n",
              "      <td>You can't view Flash content on an iPad. Howev...</td>\n",
              "      <td>आयपॅडवर फ्लॅश आशय बघता येत नाही. पण तुम्ही त्य...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40750</th>\n",
              "      <td>In 1969, Roger Miller recorded a song called \"...</td>\n",
              "      <td>१९६९मध्ये रॉजर मिलरने \"यू डोन्ट वॉन्ट माय लव्ह...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 english                                            marathi\n",
              "40746  Just saying you don't like fish because of the...  हड्डींमुळे मासे आवडत नाही असं म्हणणं हे काय मा...\n",
              "40747  The Japanese Parliament today officially elect...  आज जपानी संसदेने अधिकृतरित्या र्‍यौतारौ हाशिमो...\n",
              "40748  Tom tried to sell his old VCR instead of throw...  टॉमने त्याचा जुना व्ही.सी.आर फेकून टाकण्याऐवजी...\n",
              "40749  You can't view Flash content on an iPad. Howev...  आयपॅडवर फ्लॅश आशय बघता येत नाही. पण तुम्ही त्य...\n",
              "40750  In 1969, Roger Miller recorded a song called \"...  १९६९मध्ये रॉजर मिलरने \"यू डोन्ट वॉन्ट माय लव्ह..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La4DKCxV65JZ"
      },
      "source": [
        "### Building tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0le-1MgY5N3",
        "outputId": "c3578782-0ac9-4f00-80a2-cd0c9c8e9f9c"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.preprocessing import text\r\n",
        "from tensorflow.keras.preprocessing import sequence\r\n",
        "\r\n",
        "import re\r\n",
        "import string\r\n",
        "\r\n",
        "print(tf.__version__)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zvkz5RLnbBnq"
      },
      "source": [
        "def sep_punk(text):\r\n",
        "  for punk in string.punctuation:\r\n",
        "    text = text.replace(punk,\" \"+punk+\" \")\r\n",
        "  return text\r\n",
        "\r\n",
        "def add_init_token(sent_list):\r\n",
        "  new_sent_list = []\r\n",
        "  for sent in sent_list:\r\n",
        "    sent = sep_punk(sent)\r\n",
        "    sent = '<sos> ' + sent + ' <eos>'\r\n",
        "    new_sent_list.append(sent)\r\n",
        "\r\n",
        "  return new_sent_list    "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rvtzx8peSqI"
      },
      "source": [
        "mar_list = list(data['marathi'])\r\n",
        "eng_list = list(data['english'])\r\n",
        "\r\n",
        "mar_list = add_init_token(mar_list)\r\n",
        "eng_list = add_init_token(eng_list)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MEWxWBge5KQ",
        "outputId": "6b15e90a-6c86-4ade-b9b3-8a16d79e50c3"
      },
      "source": [
        "print(mar_list[100])\r\n",
        "print(eng_list[100])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<sos> मी आहे !  <eos>\n",
            "<sos> It ' s me !  <eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ0NLlyiYy-a"
      },
      "source": [
        "def tokenize(sent_list):\r\n",
        "  tokenizer = text.Tokenizer(filters='')\r\n",
        "  tokenizer.fit_on_texts(sent_list)\r\n",
        "\r\n",
        "  tensor_list = tokenizer.texts_to_sequences(sent_list)\r\n",
        "  tensor_list = sequence.pad_sequences(tensor_list, padding='post')\r\n",
        "  \r\n",
        "  return {'Tensors': tensor_list, 'Tokenizer': tokenizer} "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fWvfmqviaYG"
      },
      "source": [
        "marathi = tokenize(sent_list=mar_list)\r\n",
        "english = tokenize(sent_list=eng_list)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xvatkmpznpnx",
        "outputId": "778a8fa3-112a-4c9e-a638-e7118000132e"
      },
      "source": [
        "mar_tokenizer = marathi['Tokenizer']\r\n",
        "eng_tokenizer = english['Tokenizer']\r\n",
        "\r\n",
        "print(f'The length of marathi vocab: {len(mar_tokenizer.word_index)}')\r\n",
        "print(f'The length of english vocab: {len(eng_tokenizer.word_index)}')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of marathi vocab: 13841\n",
            "The length of english vocab: 5715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhYYsIzKnvY8",
        "outputId": "783730ac-4643-4681-d3d4-72e4bb1a867b"
      },
      "source": [
        "mar_tensors = marathi['Tensors']\r\n",
        "eng_tensors = english['Tensors']\r\n",
        "\r\n",
        "print(f'Max length of sequence: {len(mar_tensors[0])}')\r\n",
        "print(f'Max length of sequence: {len(eng_tensors[0])}')\r\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max length of sequence: 44\n",
            "Max length of sequence: 50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9V2vLbF8sXd6",
        "outputId": "c4d61fe8-f88a-4f15-bc90-7427f03e9eb7"
      },
      "source": [
        "print(mar_tensors[0])\r\n",
        "print(eng_tensors[0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  1 706   3   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0]\n",
            "[ 1 48  3  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SOsuFHSpZbA"
      },
      "source": [
        "### Implimenting TF Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LM20hTegrjI3"
      },
      "source": [
        "from tensorflow.data import Dataset"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTSwVN5gsLY6"
      },
      "source": [
        "BUFFER_SIZE = len(mar_tensors)\r\n",
        "BATCH_SIZE = 64\r\n",
        "\r\n",
        "dataset = Dataset.from_tensor_slices((mar_tensors, eng_tensors)).shuffle(BUFFER_SIZE, reshuffle_each_iteration=True)\r\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDvbQm1DuduE",
        "outputId": "6a893fce-7b60-40b2-d428-eadb88c1507d"
      },
      "source": [
        "ex_mar_batch, ex_eng_batch = next(iter(dataset))\r\n",
        "print(ex_mar_batch.shape)\r\n",
        "print(ex_eng_batch.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 44)\n",
            "(64, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C35L-D1utri"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LadoJbptvE4a"
      },
      "source": [
        "from tensorflow import nn\r\n",
        "from tensorflow.keras import layers, Model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7gTP9YY64sM"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMw78u1kvHu2"
      },
      "source": [
        "class Encoder(Model):\r\n",
        "\r\n",
        "  '''\r\n",
        "      I know it may not seem like it, but I coded it myself. So please, stfu.\r\n",
        "      I am super professional adding this docstring for you. Thank me later.\r\n",
        "  '''\r\n",
        "  def __init__(self, vocab_size, embedding_size, enc_units, batch_size):\r\n",
        "    \r\n",
        "    super(Encoder, self).__init__()\r\n",
        "\r\n",
        "    self.batch_size = batch_size\r\n",
        "    self.enc_units = enc_units\r\n",
        "    self.embedding = layers.Embedding(vocab_size, embedding_size)\r\n",
        "    self.gru = layers.GRU(enc_units, return_sequences= True, return_state= True, recurrent_initializer='glorot_uniform')\r\n",
        "\r\n",
        "\r\n",
        "  def call(self, x, hidden):\r\n",
        "    x = self.embedding(x)\r\n",
        "    output, state = self.gru(x, initial_state=hidden)\r\n",
        "    return output,state\r\n",
        "\r\n",
        "  def initialize_hidden_state(self):\r\n",
        "    return tf.zeros((self.batch_size, self.enc_units))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKAKKKLC9a5l"
      },
      "source": [
        "mar_vocab_size = len(mar_tokenizer.word_index) + 1\r\n",
        "EMBEDDING_SIZE = 256\r\n",
        "GRU_UNITS = 1024\r\n",
        "\r\n",
        "encoder = Encoder(mar_vocab_size, EMBEDDING_SIZE, GRU_UNITS, BATCH_SIZE)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kugg8Jj1AgPV",
        "outputId": "82cedc58-559c-4111-df1b-f0c750888558"
      },
      "source": [
        "#Example input\r\n",
        "\r\n",
        "ex_hidden = encoder.initialize_hidden_state()\r\n",
        "sample_out, sample_hidden = encoder(ex_mar_batch, ex_hidden)\r\n",
        "\r\n",
        "print(sample_out.shape)\r\n",
        "print(sample_hidden.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 44, 1024)\n",
            "(64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BwKYo4qBz0_"
      },
      "source": [
        "### Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqR_Q13dB5lf"
      },
      "source": [
        "class Attention(layers.Layer):\r\n",
        "  '''\r\n",
        "  Yes, even this I coded myself. I did not just add the docstring later, bitch ass dickhead.\r\n",
        "  BTW, FYI, this is Bahdanau Attention\r\n",
        "  '''\r\n",
        "  def __init__(self, units):\r\n",
        "\r\n",
        "    super(Attention, self).__init__()\r\n",
        "    self.W1 = layers.Dense(units)\r\n",
        "    self.W2 = layers.Dense(units)\r\n",
        "    self.V = layers.Dense(1)\r\n",
        "\r\n",
        "  def call(self, q, val):\r\n",
        "    #make q i.e. the hidden value into the same shape\r\n",
        "    q_with_time_axis = tf.expand_dims(q, 1)\r\n",
        "\r\n",
        "    score = self.V( nn.tanh( self.W1(q_with_time_axis) + self.W2(val) ) )\r\n",
        "\r\n",
        "    attention_w = nn.softmax(score, axis=1)\r\n",
        "\r\n",
        "    context_vec = attention_w * val\r\n",
        "    context_vec = tf.reduce_sum(context_vec, axis=1)\r\n",
        "\r\n",
        "    return context_vec, attention_w"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5mexiuZB6t5"
      },
      "source": [
        "attention = Attention(10)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoyIpD_JHsn2",
        "outputId": "5acb76a4-0c2a-4071-a138-b2ddcacc2a78"
      },
      "source": [
        "#example code\r\n",
        "attn_res ,  attn_w = attention(sample_hidden, sample_out)\r\n",
        "print(attn_res.shape)\r\n",
        "print(attn_w.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 1024)\n",
            "(64, 44, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCor_QpNH2v2"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMpa-eiBIALo"
      },
      "source": [
        "class Decoder(Model):\r\n",
        "\r\n",
        "  def __init__(self, vocab_size, embedding_size, dec_units, batch_size):\r\n",
        "    super(Decoder,self).__init__()\r\n",
        "\r\n",
        "    self.batch_size = batch_size\r\n",
        "    self.dec_units = dec_units\r\n",
        "    \r\n",
        "    self.embedding = layers.Embedding(vocab_size, embedding_size)\r\n",
        "    self.gru = layers.GRU(dec_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\r\n",
        "\r\n",
        "    self.fc = layers.Dense(vocab_size)\r\n",
        "\r\n",
        "    self.attention = Attention(dec_units)\r\n",
        "\r\n",
        "  def call(self, x, hidden, enc_out):\r\n",
        "    context_vec, attention_w = self.attention(hidden, enc_out)\r\n",
        "\r\n",
        "    x = self.embedding(x)\r\n",
        "\r\n",
        "    x = tf.concat([tf.expand_dims(context_vec, 1), x], axis=-1)\r\n",
        "\r\n",
        "    output, state = self.gru(x)\r\n",
        "\r\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\r\n",
        "\r\n",
        "    x = self.fc(output)\r\n",
        "\r\n",
        "    return x, state, attention_w"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiZ7ouwZIBAV"
      },
      "source": [
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\r\n",
        "\r\n",
        "decoder = Decoder(eng_vocab_size, EMBEDDING_SIZE, GRU_UNITS, BATCH_SIZE)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaQLmkzWVB9I",
        "outputId": "5139d01d-43e2-4733-9f99-eef3c8126686"
      },
      "source": [
        "#example code\r\n",
        "\r\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),sample_hidden, sample_out)\r\n",
        "\r\n",
        "print (sample_decoder_output.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 5716)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwffpIeIVLqn"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5kGD2XaVs_I"
      },
      "source": [
        "### Optimizers and Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnh5QPXBVwW9"
      },
      "source": [
        "from tensorflow.keras import optimizers as optim\r\n",
        "from tensorflow.keras import losses"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD9cEv6fV_d7"
      },
      "source": [
        "optimizer = optim.Adam()\r\n",
        "criteria = losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\r\n",
        "\r\n",
        "def loss_function(real, pred):\r\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\r\n",
        "  loss = criteria(real, pred)\r\n",
        "\r\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)\r\n",
        "  loss = loss*mask\r\n",
        "\r\n",
        "  return tf.reduce_mean(loss)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD2K-vW6YVSX"
      },
      "source": [
        "### Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLZIwVbXYZri"
      },
      "source": [
        "checkpoint_path = './tf_checkpoint'\r\n",
        "checkpoint = tf.train.Checkpoint(optimizer = optimizer,\r\n",
        "                                 encoder=encoder,\r\n",
        "                                 decoder=decoder\r\n",
        "                                 )"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxTYP4xOZSEb"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtJK_B3xcks6"
      },
      "source": [
        "import time"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fFng4yJZVtN"
      },
      "source": [
        "@tf.function\r\n",
        "def train_step(src, trg, enc_hidden):\r\n",
        "  loss = 0\r\n",
        "\r\n",
        "\r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    enc_out, enc_hidden = encoder(src, enc_hidden)\r\n",
        "\r\n",
        "    dec_hidden = enc_hidden\r\n",
        "\r\n",
        "    dec_input = tf.expand_dims([eng_tokenizer.word_index['<sos>']]*BATCH_SIZE, 1)\r\n",
        "\r\n",
        "    for t in range(1, trg.shape[1]):\r\n",
        "\r\n",
        "      pred, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_out)\r\n",
        "\r\n",
        "      loss += loss_function(trg[:,t], pred)\r\n",
        "\r\n",
        "      dec_input = tf.expand_dims(trg[:,t],1)\r\n",
        "\r\n",
        "  \r\n",
        "  batch_loss = loss/ int(trg.shape[1])\r\n",
        "\r\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\r\n",
        "\r\n",
        "  grads = tape.gradient(loss,variables)\r\n",
        "\r\n",
        "  optimizer.apply_gradients(zip(grads, variables))\r\n",
        "\r\n",
        "  return batch_loss"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JXc0-gxb_TV",
        "outputId": "5b8dec8c-125b-4733-f445-d1d335a5a9ea"
      },
      "source": [
        "EPOCHS = 10\r\n",
        "steps_per_epoch = len(mar_tensors)//BATCH_SIZE\r\n",
        "\r\n",
        "\r\n",
        "for epoch in range(EPOCHS):\r\n",
        "  start = time.time()\r\n",
        "\r\n",
        "  enc_hidden = encoder.initialize_hidden_state()\r\n",
        "\r\n",
        "  total_loss = 0\r\n",
        "\r\n",
        "  for (batch, (src,trg)) in enumerate(dataset.take(steps_per_epoch)):\r\n",
        "\r\n",
        "    batch_loss = train_step(src, trg, enc_hidden)\r\n",
        "\r\n",
        "    total_loss += batch_loss\r\n",
        "\r\n",
        "    if batch%100 == 0:\r\n",
        "      print(f'Epoch {epoch} Batch {batch} Loss{batch_loss.numpy():.4f}')\r\n",
        "\r\n",
        "  \r\n",
        "  if (epoch+1)%2 == 0:\r\n",
        "    checkpoint.save(file_prefix=checkpoint_path)\r\n",
        "\r\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\r\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 0 Loss1.4381\n",
            "Epoch 0 Batch 100 Loss0.6549\n",
            "Epoch 0 Batch 200 Loss0.6018\n",
            "Epoch 0 Batch 300 Loss0.6292\n",
            "Epoch 0 Batch 400 Loss0.4723\n",
            "Epoch 0 Batch 500 Loss0.5306\n",
            "Epoch 0 Batch 600 Loss0.4074\n",
            "Epoch 1 Loss 0.5714\n",
            "Time taken for 1 epoch 359.6276400089264 sec\n",
            "\n",
            "Epoch 1 Batch 0 Loss0.4249\n",
            "Epoch 1 Batch 100 Loss0.3775\n",
            "Epoch 1 Batch 200 Loss0.3672\n",
            "Epoch 1 Batch 300 Loss0.3786\n",
            "Epoch 1 Batch 400 Loss0.3537\n",
            "Epoch 1 Batch 500 Loss0.3106\n",
            "Epoch 1 Batch 600 Loss0.2496\n",
            "Epoch 2 Loss 0.3403\n",
            "Time taken for 1 epoch 322.93631196022034 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss0.2315\n",
            "Epoch 2 Batch 100 Loss0.1924\n",
            "Epoch 2 Batch 200 Loss0.1953\n",
            "Epoch 2 Batch 300 Loss0.2088\n",
            "Epoch 2 Batch 400 Loss0.1613\n",
            "Epoch 2 Batch 500 Loss0.1674\n",
            "Epoch 2 Batch 600 Loss0.1937\n",
            "Epoch 3 Loss 0.2036\n",
            "Time taken for 1 epoch 322.043879032135 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss0.1153\n",
            "Epoch 3 Batch 100 Loss0.1301\n",
            "Epoch 3 Batch 200 Loss0.0985\n",
            "Epoch 3 Batch 300 Loss0.1385\n",
            "Epoch 3 Batch 400 Loss0.1185\n",
            "Epoch 3 Batch 500 Loss0.1319\n",
            "Epoch 3 Batch 600 Loss0.0844\n",
            "Epoch 4 Loss 0.1214\n",
            "Time taken for 1 epoch 322.68089628219604 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss0.0831\n",
            "Epoch 4 Batch 100 Loss0.0673\n",
            "Epoch 4 Batch 200 Loss0.0664\n",
            "Epoch 4 Batch 300 Loss0.0749\n",
            "Epoch 4 Batch 400 Loss0.0556\n",
            "Epoch 4 Batch 500 Loss0.0714\n",
            "Epoch 4 Batch 600 Loss0.0845\n",
            "Epoch 5 Loss 0.0735\n",
            "Time taken for 1 epoch 322.2883803844452 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss0.0388\n",
            "Epoch 5 Batch 100 Loss0.0661\n",
            "Epoch 5 Batch 200 Loss0.0478\n",
            "Epoch 5 Batch 300 Loss0.0525\n",
            "Epoch 5 Batch 400 Loss0.0390\n",
            "Epoch 5 Batch 500 Loss0.0347\n",
            "Epoch 5 Batch 600 Loss0.0675\n",
            "Epoch 6 Loss 0.0457\n",
            "Time taken for 1 epoch 322.3882715702057 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss0.0498\n",
            "Epoch 6 Batch 100 Loss0.0339\n",
            "Epoch 6 Batch 200 Loss0.0337\n",
            "Epoch 6 Batch 300 Loss0.0391\n",
            "Epoch 6 Batch 400 Loss0.0287\n",
            "Epoch 6 Batch 500 Loss0.0301\n",
            "Epoch 6 Batch 600 Loss0.0225\n",
            "Epoch 7 Loss 0.0303\n",
            "Time taken for 1 epoch 322.04899287223816 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss0.0130\n",
            "Epoch 7 Batch 100 Loss0.0181\n",
            "Epoch 7 Batch 200 Loss0.0200\n",
            "Epoch 7 Batch 300 Loss0.0305\n",
            "Epoch 7 Batch 400 Loss0.0268\n",
            "Epoch 7 Batch 500 Loss0.0354\n",
            "Epoch 7 Batch 600 Loss0.0229\n",
            "Epoch 8 Loss 0.0224\n",
            "Time taken for 1 epoch 322.69126892089844 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss0.0112\n",
            "Epoch 8 Batch 100 Loss0.0153\n",
            "Epoch 8 Batch 200 Loss0.0222\n",
            "Epoch 8 Batch 300 Loss0.0137\n",
            "Epoch 8 Batch 400 Loss0.0157\n",
            "Epoch 8 Batch 500 Loss0.0223\n",
            "Epoch 8 Batch 600 Loss0.0160\n",
            "Epoch 9 Loss 0.0180\n",
            "Time taken for 1 epoch 322.0503785610199 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss0.0164\n",
            "Epoch 9 Batch 100 Loss0.0133\n",
            "Epoch 9 Batch 200 Loss0.0106\n",
            "Epoch 9 Batch 300 Loss0.0185\n",
            "Epoch 9 Batch 400 Loss0.0134\n",
            "Epoch 9 Batch 500 Loss0.0182\n",
            "Epoch 9 Batch 600 Loss0.0165\n",
            "Epoch 10 Loss 0.0148\n",
            "Time taken for 1 epoch 322.67265009880066 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp4TCi25u8Xq"
      },
      "source": [
        "from matplotlib import ticker"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IBuyk-Dekcx"
      },
      "source": [
        "def evaluate(sentence):\r\n",
        "  attention_plot = np.zeros((eng_tensors.shape[1],mar_tensors.shape[1]))\r\n",
        "\r\n",
        "  sentence = sep_punk(sentence)\r\n",
        "\r\n",
        "  inputs = [mar_tokenizer.word_index[i] for i in sentence.split(' ') if i!='']\r\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\r\n",
        "                                                         maxlen=mar_tensors.shape[1],\r\n",
        "                                                         padding='post')\r\n",
        "  inputs = tf.convert_to_tensor(inputs)\r\n",
        "\r\n",
        "  result = ''\r\n",
        "\r\n",
        "  hidden = [tf.zeros((1, GRU_UNITS))]\r\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\r\n",
        "\r\n",
        "  dec_hidden = enc_hidden\r\n",
        "  dec_input = tf.expand_dims([eng_tokenizer.word_index['<sos>']], 0)\r\n",
        "\r\n",
        "  for t in range(eng_tensors.shape[1]):\r\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\r\n",
        "                                                         dec_hidden,\r\n",
        "                                                         enc_out)\r\n",
        "\r\n",
        "    # storing the attention weights to plot later on\r\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\r\n",
        "    attention_plot[t] = attention_weights.numpy()\r\n",
        "\r\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\r\n",
        "\r\n",
        "    result += eng_tokenizer.index_word[predicted_id] + ' '\r\n",
        "\r\n",
        "    if eng_tokenizer.index_word[predicted_id] == '<eos>':\r\n",
        "      return result, sentence, attention_plot\r\n",
        "\r\n",
        "    # the predicted ID is fed back into the model\r\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\r\n",
        "\r\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjInIu7CsI1B"
      },
      "source": [
        "# function for plotting the attention weights\r\n",
        "def plot_attention(attention, sentence, predicted_sentence):\r\n",
        "  fig = plt.figure(figsize=(10,10))\r\n",
        "  ax = fig.add_subplot(1, 1, 1)\r\n",
        "  ax.matshow(attention, cmap='viridis')\r\n",
        "\r\n",
        "  fontdict = {'fontsize': 14}\r\n",
        "\r\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\r\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\r\n",
        "\r\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "\r\n",
        "  plt.show()"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-EUiOtzsKux"
      },
      "source": [
        "def translate(sentence):\r\n",
        "  result, sentence, attention_plot = evaluate(sentence)\r\n",
        "\r\n",
        "  print('Input: %s' % (sentence))\r\n",
        "  print('Predicted translation: {}'.format(result))\r\n",
        "\r\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\r\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRmtzieCsMQI",
        "outputId": "8f4d741b-d82e-491b-fa39-a4a386b62248"
      },
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_path))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.InitializationOnlyStatus at 0x7fc7eee368d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbwQr01qsZI-",
        "outputId": "e0767bb4-f475-43c3-ab7f-e14b952cbd95"
      },
      "source": [
        "res, sentence , _ = evaluate(data['marathi'][20212])\r\n",
        "\r\n",
        "\r\n",
        "print(sentence)\r\n",
        "print(data['english'][20212])\r\n",
        "print(res)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "तिघांना अटक करण्यात आली . \n",
            "The three were arrested.\n",
            "the three were arrested . <eos> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1o4XYGEvc2S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}