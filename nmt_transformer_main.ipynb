{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nmt_transformer_main.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPYebuh9d7f5UvOZToWtHi1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "578465539c554cd2a688ebe480b0c00f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_94d651ff766246469c13a9b0724145f0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d6cebcf0b3374532ad3e5377c9eb0c1b",
              "IPY_MODEL_473b4855d31440e0b1f3055ab3f9bf70"
            ]
          }
        },
        "94d651ff766246469c13a9b0724145f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d6cebcf0b3374532ad3e5377c9eb0c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a65d865054a14e65a5339fd0f56b3190",
            "_dom_classes": [],
            "description": "loss:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 10,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_84c86ef2b9f34fb29acc1b4e2d43b17e"
          }
        },
        "473b4855d31440e0b1f3055ab3f9bf70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4e6bb8fa55ca4b259d372dd1263c0339",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/10 [00:03&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e17830af88104ff48d032d134345d933"
          }
        },
        "a65d865054a14e65a5339fd0f56b3190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "84c86ef2b9f34fb29acc1b4e2d43b17e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e6bb8fa55ca4b259d372dd1263c0339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e17830af88104ff48d032d134345d933": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhavnicksm/marathi-neural-machine-translation/blob/main/nmt_transformer_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m8OV0wClQDQ"
      },
      "source": [
        "Before beginning this notebook, ensure that you have data.csv in available in the working directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diGgpmn6_hO5"
      },
      "source": [
        "#!pip install torchtext==0.8.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vdbql_pf8PhO"
      },
      "source": [
        "#!python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkCLyMjMK0g_"
      },
      "source": [
        "## Hyperparameter declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-VxIa3PK5ZA"
      },
      "source": [
        "from argparse import Namespace"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mnp0_Z41K9OS"
      },
      "source": [
        "hype = Namespace(\r\n",
        "    BATCH_SIZE = 128,\r\n",
        "    NUM_EPOCHS = 10,\r\n",
        "    CLIP = 1,\r\n",
        "    DEVICE = None,\r\n",
        "    \r\n",
        "    save_checkpoint =True,\r\n",
        "    load_checkpoint = False\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILw_JUj5MGTP"
      },
      "source": [
        "checkpoint = Namespace(\r\n",
        "    epoch_num = 0,\r\n",
        "    model_params = None,\r\n",
        "    optim_params = None,\r\n",
        "    loss=0,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDHMJQQALwNZ",
        "outputId": "66759b38-bd02-4f88-b18e-40c19b3a491d"
      },
      "source": [
        "#example usage\r\n",
        "hype.BATCH_SIZE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqxGUlxQNzEo",
        "outputId": "7eb63afa-3c49-4725-f7cd-8e9f33d5b6dc"
      },
      "source": [
        "#to dict\r\n",
        "vars(hype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'BATCH_SIZE': 128,\n",
              " 'CLIP': 1,\n",
              " 'DEVICE': None,\n",
              " 'NUM_EPOCHS': 10,\n",
              " 'load_checkpoint': False,\n",
              " 'save_checkpoint': True}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wznA4tHCk3ZN"
      },
      "source": [
        "## Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRM-bUZo60qp"
      },
      "source": [
        "### Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2-a9XNPlOym"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "K1ftPojC5LWC",
        "outputId": "b0ce261e-4f16-478f-912c-8f695ba459ff"
      },
      "source": [
        "data = pd.read_csv('data.csv', header=None)\r\n",
        "data.columns = ['english', 'marathi']\r\n",
        "data.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>marathi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>40746</th>\n",
              "      <td>Just saying you don't like fish because of the...</td>\n",
              "      <td>हड्डींमुळे मासे आवडत नाही असं म्हणणं हे काय मा...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40747</th>\n",
              "      <td>The Japanese Parliament today officially elect...</td>\n",
              "      <td>आज जपानी संसदेने अधिकृतरित्या र्‍यौतारौ हाशिमो...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40748</th>\n",
              "      <td>Tom tried to sell his old VCR instead of throw...</td>\n",
              "      <td>टॉमने त्याचा जुना व्ही.सी.आर फेकून टाकण्याऐवजी...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40749</th>\n",
              "      <td>You can't view Flash content on an iPad. Howev...</td>\n",
              "      <td>आयपॅडवर फ्लॅश आशय बघता येत नाही. पण तुम्ही त्य...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40750</th>\n",
              "      <td>In 1969, Roger Miller recorded a song called \"...</td>\n",
              "      <td>१९६९मध्ये रॉजर मिलरने \"यू डोन्ट वॉन्ट माय लव्ह...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 english                                            marathi\n",
              "40746  Just saying you don't like fish because of the...  हड्डींमुळे मासे आवडत नाही असं म्हणणं हे काय मा...\n",
              "40747  The Japanese Parliament today officially elect...  आज जपानी संसदेने अधिकृतरित्या र्‍यौतारौ हाशिमो...\n",
              "40748  Tom tried to sell his old VCR instead of throw...  टॉमने त्याचा जुना व्ही.सी.आर फेकून टाकण्याऐवजी...\n",
              "40749  You can't view Flash content on an iPad. Howev...  आयपॅडवर फ्लॅश आशय बघता येत नाही. पण तुम्ही त्य...\n",
              "40750  In 1969, Roger Miller recorded a song called \"...  १९६९मध्ये रॉजर मिलरने \"यू डोन्ट वॉन्ट माय लव्ह..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La4DKCxV65JZ"
      },
      "source": [
        "### Building tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7B9lmEV6-YN"
      },
      "source": [
        "import re\r\n",
        "import string\r\n",
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LRf3QcZ5UYr"
      },
      "source": [
        "#tokenizers for both\r\n",
        "\r\n",
        "def tokenize_mar(text):\r\n",
        "  for punc in string.punctuation:\r\n",
        "    text = text.replace(punc, \" \"+punc+\" \" )\r\n",
        "  return [tok.strip() for tok in re.split(r' ', text) if tok!='']\r\n",
        "\r\n",
        "spacy_en = spacy.load('en')\r\n",
        "\r\n",
        "def tokenize_eng(text):\r\n",
        "  return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NikIP1q18A0N",
        "outputId": "a34b6003-6e6a-4d58-8bb8-34e0be0b3916"
      },
      "source": [
        "#examples of tokenized sentences\r\n",
        "ex_tok_mar = tokenize_mar(data['marathi'][40000])\r\n",
        "print(ex_tok_mar)\r\n",
        "\r\n",
        "ex_tok_eng = tokenize_eng(data['english'][40000])\r\n",
        "print(ex_tok_eng)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['उद्याची', 'मीटिंग', 'कुठे', 'असणार', 'आहे', 'हे', 'तुम्हाला', 'माहीत', 'आहे', 'का', '?']\n",
            "['Do', 'you', 'know', 'where', 'tomorrow', \"'s\", 'meeting', 'is', 'going', 'to', 'be', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heI-Yc9i8pBc"
      },
      "source": [
        "### Building Vocabularies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VslioD3n_IQk",
        "outputId": "afdc5785-bc07-4b68-d323-d22c13271de2"
      },
      "source": [
        "import torchtext\r\n",
        "from torchtext.vocab import Vocab\r\n",
        "from collections import Counter\r\n",
        "\r\n",
        "print(torchtext.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPlbylwm-x_0"
      },
      "source": [
        "def build_vocab(data, tokenizer):\r\n",
        "  counter = Counter()\r\n",
        "  for text in data:\r\n",
        "    counter.update(tokenizer(text))\r\n",
        "  return Vocab(counter, max_size=10000, specials=('<unk>','<pad>','<sos>','<eos>'),)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxdcFTz0AI61"
      },
      "source": [
        "mar_vocab = build_vocab(data['marathi'],tokenize_mar)\r\n",
        "eng_vocab = build_vocab(data['english'],tokenize_eng)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYHsSxxGAWi5",
        "outputId": "fd744bed-f49a-4062-cdaa-c4d3afb55d90"
      },
      "source": [
        "print(f'Length of Marathi vocab: {len(mar_vocab)}')\r\n",
        "print(f'Length of English vocab: {len(eng_vocab)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Marathi vocab: 10004\n",
            "Length of English vocab: 6400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB33hYgXAatb"
      },
      "source": [
        "### Changing the dataset to have tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85pgie6eI0n6"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QiR_mu7IC1l"
      },
      "source": [
        "def data_process(data, src_tokenizer, tar_tokenizer, src_vocab, tar_vocab):\r\n",
        "  raw_src_iter = iter(data['marathi'])\r\n",
        "  raw_tar_iter = iter(data['english'])\r\n",
        "\r\n",
        "  data = []\r\n",
        "\r\n",
        "  for (raw_src, raw_tar) in zip(raw_src_iter,raw_tar_iter):\r\n",
        "    src_tensor = torch.tensor([src_vocab[tok] for tok in src_tokenizer(raw_src)], dtype=torch.long)\r\n",
        "    tar_tensor = torch.tensor([tar_vocab[tok] for tok in tar_tokenizer(raw_tar)], dtype=torch.long)\r\n",
        "\r\n",
        "    data.append((src_tensor,tar_tensor))\r\n",
        "\r\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9_SDBaaJjvx"
      },
      "source": [
        "dataset = data_process(data, tokenize_mar, tokenize_eng, mar_vocab, eng_vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KYl2hSoJ32p"
      },
      "source": [
        "### DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SP46HnCPUfL"
      },
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\r\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oJc34wNLOgKQ",
        "outputId": "394996e1-90a9-4e04-d401-d5bfc52e8c73"
      },
      "source": [
        "hype.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n",
        "hype.DEVICE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cpu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW0CDpopO3c2",
        "outputId": "2b5cf3a5-b76f-4087-a4b7-f41035d72d18"
      },
      "source": [
        "PAD_IDX = mar_vocab[\"<pad>\"]\r\n",
        "SOS_IDX = mar_vocab[\"<sos>\"]\r\n",
        "EOS_IDX = mar_vocab[\"<eos>\"]\r\n",
        "\r\n",
        "print(f\"pad index: {PAD_IDX}\")\r\n",
        "print(f\"sos index: {SOS_IDX}\")\r\n",
        "print(f\"eos index: {EOS_IDX}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pad index: 1\n",
            "sos index: 2\n",
            "eos index: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBmP0A76PS2A"
      },
      "source": [
        "def batch_proc(data_batch):\r\n",
        "  src_batch = []\r\n",
        "  tar_batch = []\r\n",
        "  \r\n",
        "  for (src_item, tar_item) in data_batch:\r\n",
        "    src_batch.append(torch.cat([torch.tensor([SOS_IDX]), src_item , torch.tensor([EOS_IDX])], dim=0))\r\n",
        "    tar_batch.append(torch.cat([torch.tensor([SOS_IDX]), tar_item , torch.tensor([EOS_IDX])], dim=0))\r\n",
        "  \r\n",
        "  src_batch = pad_sequence(src_batch, padding_value= PAD_IDX)\r\n",
        "  tar_batch = pad_sequence(tar_batch, padding_value= PAD_IDX)\r\n",
        "\r\n",
        "  return src_batch, tar_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONdBjn6-V_oo"
      },
      "source": [
        "train_iter = DataLoader(dataset, batch_size= hype.BATCH_SIZE , shuffle=True, collate_fn= batch_proc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjsfaWVfCy1m"
      },
      "source": [
        "# a = next(iter(train_iter))\r\n",
        "# print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajP6GIFXORYE"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfpEN8iIdgZM"
      },
      "source": [
        "import random\r\n",
        "from typing import Tuple\r\n",
        "\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch import Tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfIkX3HqXbmF"
      },
      "source": [
        "class Transformer(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self,\r\n",
        "               embedding_size: int,\r\n",
        "               src_vocab_size: int,\r\n",
        "               trg_vocab_size: int,\r\n",
        "               src_pad_idx: int,\r\n",
        "               num_heads: int,\r\n",
        "               num_encoder_layers: int,\r\n",
        "               num_decoder_layers: int,\r\n",
        "               forward_expansion: int,\r\n",
        "               dropout: float,\r\n",
        "               max_len: int, \r\n",
        "               device: str,\r\n",
        "               ):\r\n",
        "    \r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\r\n",
        "    self.src_position_embedding = nn.Embedding(max_len, embedding_size)\r\n",
        "    self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\r\n",
        "    self.trg_position_embedding = nn.Embedding(max_len, embedding_size)\r\n",
        "\r\n",
        "    self.device = device\r\n",
        "\r\n",
        "    self.transformer = nn.Transformer(embedding_size, num_heads, num_encoder_layers, num_decoder_layers, forward_expansion, dropout)\r\n",
        "\r\n",
        "    self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\r\n",
        "    self.dropout = nn.Dropout(dropout)\r\n",
        "    self.src_pad_idx = src_pad_idx\r\n",
        "\r\n",
        "\r\n",
        "  def make_src_mask(self, src):\r\n",
        "    src_mask = src.transpose(0, 1) == self.src_pad_idx\r\n",
        "\r\n",
        "    # (N, src_len)\r\n",
        "    return src_mask.to(self.device)\r\n",
        "\r\n",
        "  def forward(self, src, trg):\r\n",
        "    src_seq_length, N = src.shape\r\n",
        "    trg_seq_length, N = trg.shape\r\n",
        "\r\n",
        "    src_positions = (\r\n",
        "        torch.arange(0, src_seq_length)\r\n",
        "        .unsqueeze(1)\r\n",
        "        .expand(src_seq_length, N)\r\n",
        "        .to(self.device)\r\n",
        "    )\r\n",
        "\r\n",
        "    trg_positions = (\r\n",
        "        torch.arange(0, trg_seq_length)\r\n",
        "        .unsqueeze(1)\r\n",
        "        .expand(trg_seq_length, N)\r\n",
        "        .to(self.device)\r\n",
        "    )\r\n",
        "\r\n",
        "    embed_src = self.dropout(\r\n",
        "        (self.src_word_embedding(src) + self.src_position_embedding(src_positions))\r\n",
        "    )\r\n",
        "    embed_trg = self.dropout(\r\n",
        "        (self.trg_word_embedding(trg) + self.trg_position_embedding(trg_positions))\r\n",
        "    )\r\n",
        "\r\n",
        "    src_padding_mask = self.make_src_mask(src)\r\n",
        "    trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(\r\n",
        "        self.device\r\n",
        "    )\r\n",
        "\r\n",
        "    out = self.transformer(\r\n",
        "        embed_src,\r\n",
        "        embed_trg,\r\n",
        "        src_key_padding_mask=src_padding_mask,\r\n",
        "        tgt_mask=trg_mask,\r\n",
        "    )\r\n",
        "    out = self.fc_out(out)\r\n",
        "    return out\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DQKSr8a3mq9"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZe3CSK59eqL"
      },
      "source": [
        "import tqdm\r\n",
        "from tqdm import notebook\r\n",
        "\r\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i-heIfr3qkJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22eba417-e268-4c2b-ce0e-eb376b02f142"
      },
      "source": [
        "model_hype = Namespace(\r\n",
        "    src_vocab_size = len(mar_vocab),\r\n",
        "    trg_vocab_size = len(eng_vocab),\r\n",
        "    embedding_size = 512,\r\n",
        "    num_heads = 8,\r\n",
        "    num_encoder_layers = 3,\r\n",
        "    num_decoder_layers = 3,\r\n",
        "    dropout = 0.10,\r\n",
        "    max_len = 100,\r\n",
        "    forward_expansion = 4,\r\n",
        "    src_pad_idx = mar_vocab[\"<pad>\"]\r\n",
        ")\r\n",
        "\r\n",
        "model_hype.src_pad_idx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Eltcn6N4Rbd"
      },
      "source": [
        "# creating the final model object\r\n",
        "model = Transformer(\r\n",
        "    model_hype.embedding_size,\r\n",
        "    model_hype.src_vocab_size,\r\n",
        "    model_hype.trg_vocab_size,\r\n",
        "    model_hype.src_pad_idx,\r\n",
        "    model_hype.num_heads,\r\n",
        "    model_hype.num_encoder_layers,\r\n",
        "    model_hype.num_decoder_layers,\r\n",
        "    model_hype.forward_expansion,\r\n",
        "    model_hype.dropout,\r\n",
        "    model_hype.max_len,\r\n",
        "    hype.DEVICE,\r\n",
        ").to(hype.DEVICE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ-goHav4ll5",
        "outputId": "fab166b2-d3c9-415a-c731-6d17fbb0a574"
      },
      "source": [
        "def init_model(model: nn.Module):\r\n",
        "  for name, param in model.named_parameters():\r\n",
        "    if 'weight' in name:\r\n",
        "      nn.init.normal_(param.data, mean=0., std = 0.01)\r\n",
        "    else:\r\n",
        "      nn.init.constant_(param.data, 0.)\r\n",
        "\r\n",
        "model.apply(init_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (src_word_embedding): Embedding(10004, 512)\n",
              "  (src_position_embedding): Embedding(100, 512)\n",
              "  (trg_word_embedding): Embedding(6400, 512)\n",
              "  (trg_position_embedding): Embedding(100, 512)\n",
              "  (transformer): Transformer(\n",
              "    (encoder): TransformerEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=512, out_features=4, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=4, out_features=512, bias=True)\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (1): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=512, out_features=4, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=4, out_features=512, bias=True)\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (2): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=512, out_features=4, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=4, out_features=512, bias=True)\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): TransformerDecoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=512, out_features=4, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=4, out_features=512, bias=True)\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          (dropout3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (1): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=512, out_features=4, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=4, out_features=512, bias=True)\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          (dropout3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (2): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=512, out_features=4, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=4, out_features=512, bias=True)\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          (dropout3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (fc_out): Linear(in_features=512, out_features=6400, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzDB7jGZ5Bug",
        "outputId": "31bc02a7-ba2f-4e4b-b09f-734d4a5909de"
      },
      "source": [
        "def count_params (model: nn.Module):\r\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "\r\n",
        "print(f\"There are {count_params(model):,} parameters in the model.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 21,285,144 parameters in the model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPbcN95I6aKv"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())\r\n",
        "\r\n",
        "tar_PAD_IDX = eng_vocab['<pad>']\r\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tar_PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T_DC5VA7BjV"
      },
      "source": [
        "def train(model: nn.Module, iterator: torch.utils.data.DataLoader, optimizer: optim.Optimizer, criteria: nn.Module , clip: float, device: str):\r\n",
        "  model.train()\r\n",
        "\r\n",
        "  epoch_loss = 0\r\n",
        "\r\n",
        "  for _, (src,tar) in enumerate(iterator):\r\n",
        "    src, tar = src.to(device), tar.to(device)\r\n",
        "\r\n",
        "    optimizer.zero_grad()\r\n",
        "\r\n",
        "    output = model(src, tar)\r\n",
        "\r\n",
        "    output = output[1:].view(-1, output.shape[-1])\r\n",
        "    tar = tar[1:].view(-1)\r\n",
        "\r\n",
        "    loss = criteria(output, tar)\r\n",
        "\r\n",
        "    loss.backward()\r\n",
        "\r\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\r\n",
        "\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    epoch_loss += loss.item()\r\n",
        "  \r\n",
        "  return epoch_loss/len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IobAIJgP8Ky"
      },
      "source": [
        "if hype.load_checkpoint:\r\n",
        "  checkpoint = torch.load('transformer_checkpoint.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402,
          "referenced_widgets": [
            "578465539c554cd2a688ebe480b0c00f",
            "94d651ff766246469c13a9b0724145f0",
            "d6cebcf0b3374532ad3e5377c9eb0c1b",
            "473b4855d31440e0b1f3055ab3f9bf70",
            "a65d865054a14e65a5339fd0f56b3190",
            "84c86ef2b9f34fb29acc1b4e2d43b17e",
            "4e6bb8fa55ca4b259d372dd1263c0339",
            "e17830af88104ff48d032d134345d933"
          ]
        },
        "id": "N6-0mnLCilCz",
        "outputId": "3dd35786-2f50-477d-e8ea-19f0189dff8e"
      },
      "source": [
        "epoch_t = notebook.trange(hype.NUM_EPOCHS, desc='loss')\r\n",
        "\r\n",
        "for epoch in epoch_t:\r\n",
        "\r\n",
        "  train_loss = train(model,train_iter, optimizer, criterion, hype.CLIP, hype.DEVICE)\r\n",
        "\r\n",
        "  if hype.save_checkpoint:\r\n",
        "    checkpoint.epoch_num = epoch\r\n",
        "    checkpoint.model_params = model.state_dict\r\n",
        "    checkpoint.optim_params = optimizer.state_dict\r\n",
        "    checkpoint.loss = train_loss\r\n",
        "    torch.save(checkpoint,'transformer_checkpoint.pth')\r\n",
        "\r\n",
        "  epoch_t.set_description(f\"loss: {train_loss: .5f}\")\r\n",
        "  epoch_t.refresh()\r\n",
        "  time.sleep(0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "578465539c554cd2a688ebe480b0c00f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='loss', max=10.0, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-ffb2d47ee0f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_t\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLIP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-0007bfd29376>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criteria, clip, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N32a3h1kivIb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}