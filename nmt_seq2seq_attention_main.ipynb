{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nmt_seq2seq_attention_main.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "DRM-bUZo60qp",
        "La4DKCxV65JZ",
        "heI-Yc9i8pBc"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPAWaAQqhNXUhkesB9P8rPp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a5bc69a50df4f969fa3a87ef92dc73e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_897278a38794450598cfdd4c27f2a622",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7f9dfb0a912e4b5ea53b808223c8b58d",
              "IPY_MODEL_700bcb83ee1e4a0d8bac09ac0f7b75e6"
            ]
          }
        },
        "897278a38794450598cfdd4c27f2a622": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7f9dfb0a912e4b5ea53b808223c8b58d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5c384684e2774f018415d6025c05d61e",
            "_dom_classes": [],
            "description": "loss:  3.28084: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 10,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c0955f812c014a80880d0efa6a18d103"
          }
        },
        "700bcb83ee1e4a0d8bac09ac0f7b75e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_492aa27d8af0464fa9746efcaaeed5c4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10/10 [1:23:55&lt;00:00, 503.59s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8593c4064e3045aab8769ea0cc96bad9"
          }
        },
        "5c384684e2774f018415d6025c05d61e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c0955f812c014a80880d0efa6a18d103": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "492aa27d8af0464fa9746efcaaeed5c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8593c4064e3045aab8769ea0cc96bad9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhavnicksm/marathi-neural-machine-translation/blob/main/nmt_seq2seq_attention_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m8OV0wClQDQ"
      },
      "source": [
        "Before beginning this notebook, ensure that you have data.csv in available in the working directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diGgpmn6_hO5"
      },
      "source": [
        "#!pip install torchtext==0.8.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vdbql_pf8PhO"
      },
      "source": [
        "#!python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkCLyMjMK0g_"
      },
      "source": [
        "## Hyperparameter declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-VxIa3PK5ZA"
      },
      "source": [
        "from argparse import Namespace"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mnp0_Z41K9OS"
      },
      "source": [
        "hype = Namespace(\r\n",
        "    BATCH_SIZE = 128,\r\n",
        "    NUM_EPOCHS = 10,\r\n",
        "    CLIP = 1,\r\n",
        "    DEVICE = None,\r\n",
        "    \r\n",
        "    save_checkpoint =True,\r\n",
        "    load_checkpoint = True\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILw_JUj5MGTP"
      },
      "source": [
        "checkpoint = Namespace(\r\n",
        "    epoch_num = 0,\r\n",
        "    model_params = None,\r\n",
        "    optim_params = None,\r\n",
        "    loss=0,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDHMJQQALwNZ",
        "outputId": "a949186e-05ea-499f-a24f-2b1bedccd918"
      },
      "source": [
        "#example usage\r\n",
        "hype.BATCH_SIZE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqxGUlxQNzEo",
        "outputId": "c582c489-5cfa-473e-b3d1-84dbd3335bd8"
      },
      "source": [
        "#to dict\r\n",
        "vars(hype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'BATCH_SIZE': 128,\n",
              " 'CLIP': 1,\n",
              " 'DEVICE': None,\n",
              " 'NUM_EPOCHS': 10,\n",
              " 'load_checkpoint': False,\n",
              " 'save_checkpoint': True}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wznA4tHCk3ZN"
      },
      "source": [
        "## Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRM-bUZo60qp"
      },
      "source": [
        "### Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2-a9XNPlOym"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1ftPojC5LWC",
        "outputId": "91716313-eb4d-49cf-86f5-0ae5d8afa2b9"
      },
      "source": [
        "data = pd.read_csv('data.csv', header=None)\r\n",
        "data.columns = ['english', 'marathi']\r\n",
        "data.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>marathi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>40746</th>\n",
              "      <td>Just saying you don't like fish because of the...</td>\n",
              "      <td>हड्डींमुळे मासे आवडत नाही असं म्हणणं हे काय मा...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40747</th>\n",
              "      <td>The Japanese Parliament today officially elect...</td>\n",
              "      <td>आज जपानी संसदेने अधिकृतरित्या र्‍यौतारौ हाशिमो...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40748</th>\n",
              "      <td>Tom tried to sell his old VCR instead of throw...</td>\n",
              "      <td>टॉमने त्याचा जुना व्ही.सी.आर फेकून टाकण्याऐवजी...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40749</th>\n",
              "      <td>You can't view Flash content on an iPad. Howev...</td>\n",
              "      <td>आयपॅडवर फ्लॅश आशय बघता येत नाही. पण तुम्ही त्य...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40750</th>\n",
              "      <td>In 1969, Roger Miller recorded a song called \"...</td>\n",
              "      <td>१९६९मध्ये रॉजर मिलरने \"यू डोन्ट वॉन्ट माय लव्ह...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 english                                            marathi\n",
              "40746  Just saying you don't like fish because of the...  हड्डींमुळे मासे आवडत नाही असं म्हणणं हे काय मा...\n",
              "40747  The Japanese Parliament today officially elect...  आज जपानी संसदेने अधिकृतरित्या र्‍यौतारौ हाशिमो...\n",
              "40748  Tom tried to sell his old VCR instead of throw...  टॉमने त्याचा जुना व्ही.सी.आर फेकून टाकण्याऐवजी...\n",
              "40749  You can't view Flash content on an iPad. Howev...  आयपॅडवर फ्लॅश आशय बघता येत नाही. पण तुम्ही त्य...\n",
              "40750  In 1969, Roger Miller recorded a song called \"...  १९६९मध्ये रॉजर मिलरने \"यू डोन्ट वॉन्ट माय लव्ह..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La4DKCxV65JZ"
      },
      "source": [
        "### Building tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7B9lmEV6-YN"
      },
      "source": [
        "import re\r\n",
        "import string\r\n",
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LRf3QcZ5UYr"
      },
      "source": [
        "#tokenizers for both\r\n",
        "\r\n",
        "def tokenize_mar(text):\r\n",
        "  for punc in string.punctuation:\r\n",
        "    text = text.replace(punc, \" \"+punc+\" \" )\r\n",
        "  return [tok.strip() for tok in re.split(r' ', text) if tok!='']\r\n",
        "\r\n",
        "spacy_en = spacy.load('en')\r\n",
        "\r\n",
        "def tokenize_eng(text):\r\n",
        "  return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NikIP1q18A0N",
        "outputId": "41037dc5-783f-4af0-960b-b2efdd3bfa68"
      },
      "source": [
        "#examples of tokenized sentences\r\n",
        "ex_tok_mar = tokenize_mar(data['marathi'][40000])\r\n",
        "print(ex_tok_mar)\r\n",
        "\r\n",
        "ex_tok_eng = tokenize_eng(data['english'][40000])\r\n",
        "print(ex_tok_eng)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['उद्याची', 'मीटिंग', 'कुठे', 'असणार', 'आहे', 'हे', 'तुम्हाला', 'माहीत', 'आहे', 'का', '?']\n",
            "['Do', 'you', 'know', 'where', 'tomorrow', \"'s\", 'meeting', 'is', 'going', 'to', 'be', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heI-Yc9i8pBc"
      },
      "source": [
        "### Building Vocabularies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VslioD3n_IQk",
        "outputId": "402fbb7b-207e-49b2-a83a-add4398142c0"
      },
      "source": [
        "import torchtext\r\n",
        "from torchtext.vocab import Vocab\r\n",
        "from collections import Counter\r\n",
        "\r\n",
        "print(torchtext.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPlbylwm-x_0"
      },
      "source": [
        "def build_vocab(data, tokenizer):\r\n",
        "  counter = Counter()\r\n",
        "  for text in data:\r\n",
        "    counter.update(tokenizer(text))\r\n",
        "  return Vocab(counter, max_size=10000, specials=('<unk>','<pad>','<sos>','<eos>'),)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxdcFTz0AI61"
      },
      "source": [
        "mar_vocab = build_vocab(data['marathi'],tokenize_mar)\r\n",
        "eng_vocab = build_vocab(data['english'],tokenize_eng)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYHsSxxGAWi5",
        "outputId": "9fa8f7fd-8b5c-4726-d09d-514a6d2617ca"
      },
      "source": [
        "print(f'Length of Marathi vocab: {len(mar_vocab)}')\r\n",
        "print(f'Length of English vocab: {len(eng_vocab)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Marathi vocab: 10004\n",
            "Length of English vocab: 6400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB33hYgXAatb"
      },
      "source": [
        "### Changing the dataset to have tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85pgie6eI0n6"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QiR_mu7IC1l"
      },
      "source": [
        "def data_process(data, src_tokenizer, tar_tokenizer, src_vocab, tar_vocab):\r\n",
        "  raw_src_iter = iter(data['marathi'])\r\n",
        "  raw_tar_iter = iter(data['english'])\r\n",
        "\r\n",
        "  data = []\r\n",
        "\r\n",
        "  for (raw_src, raw_tar) in zip(raw_src_iter,raw_tar_iter):\r\n",
        "    src_tensor = torch.tensor([src_vocab[tok] for tok in src_tokenizer(raw_src)], dtype=torch.long)\r\n",
        "    tar_tensor = torch.tensor([tar_vocab[tok] for tok in tar_tokenizer(raw_tar)], dtype=torch.long)\r\n",
        "\r\n",
        "    data.append((src_tensor,tar_tensor))\r\n",
        "\r\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9_SDBaaJjvx"
      },
      "source": [
        "dataset = data_process(data, tokenize_mar, tokenize_eng, mar_vocab, eng_vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KYl2hSoJ32p"
      },
      "source": [
        "### DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SP46HnCPUfL"
      },
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\r\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJc34wNLOgKQ",
        "outputId": "089aaad2-7cb3-4f3c-e6e7-5cf69fb13b2a"
      },
      "source": [
        "hype.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n",
        "hype.DEVICE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cpu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW0CDpopO3c2",
        "outputId": "6d1629ed-d1e8-4740-a332-faf2631e11b1"
      },
      "source": [
        "PAD_IDX = mar_vocab[\"<pad>\"]\r\n",
        "SOS_IDX = mar_vocab[\"<sos>\"]\r\n",
        "EOS_IDX = mar_vocab[\"<eos>\"]\r\n",
        "\r\n",
        "print(f\"pad index: {PAD_IDX}\")\r\n",
        "print(f\"sos index: {SOS_IDX}\")\r\n",
        "print(f\"eos index: {EOS_IDX}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pad index: 1\n",
            "sos index: 2\n",
            "eos index: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBmP0A76PS2A"
      },
      "source": [
        "def batch_proc(data_batch):\r\n",
        "  src_batch = []\r\n",
        "  tar_batch = []\r\n",
        "  \r\n",
        "  for (src_item, tar_item) in data_batch:\r\n",
        "    src_batch.append(torch.cat([torch.tensor([SOS_IDX]), src_item , torch.tensor([EOS_IDX])], dim=0))\r\n",
        "    tar_batch.append(torch.cat([torch.tensor([SOS_IDX]), tar_item , torch.tensor([EOS_IDX])], dim=0))\r\n",
        "  \r\n",
        "  src_batch = pad_sequence(src_batch, padding_value= PAD_IDX)\r\n",
        "  tar_batch = pad_sequence(tar_batch, padding_value= PAD_IDX)\r\n",
        "\r\n",
        "  return src_batch, tar_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONdBjn6-V_oo"
      },
      "source": [
        "train_iter = DataLoader(dataset, batch_size= hype.BATCH_SIZE , shuffle=True, collate_fn= batch_proc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjsfaWVfCy1m",
        "outputId": "e56b6ba7-c576-4cf1-f7cc-2b742953a7a1"
      },
      "source": [
        "a = next(iter(train_iter))\r\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   7,   10,  107,  ...,   10,   38,   23],\n",
            "        [  67,  308, 1751,  ..., 1988,  229,   21],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]]), tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   5, 2416,    7,  ...,    7,   46,   62],\n",
            "        [ 465,  108,  314,  ...,  124,   17,   16],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajP6GIFXORYE"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfpEN8iIdgZM"
      },
      "source": [
        "import random\r\n",
        "from typing import Tuple\r\n",
        "\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch import Tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loyr0GQSOUA7"
      },
      "source": [
        "class Encoder(nn.Module):\r\n",
        "  '''\r\n",
        "      Encoder for the Sequence to sequence model\r\n",
        "  '''\r\n",
        "  def __init__(self, input_dim: int, emb_dim: int, encoder_hid_dim: int, decoder_hid_dim: int, dropout_p: float):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.input_dim = input_dim\r\n",
        "    self.emb_dim = emb_dim\r\n",
        "    self.enc_hid_dim = encoder_hid_dim\r\n",
        "    self.dec_hid_dim = decoder_hid_dim\r\n",
        "    self.dropout_p = dropout_p\r\n",
        "\r\n",
        "\r\n",
        "    self.embedding = nn.Embedding(input_dim, emb_dim)\r\n",
        "    self.rnn = nn.GRU(emb_dim, encoder_hid_dim, bidirectional= True)\r\n",
        "    self.fc = nn.Linear(2*encoder_hid_dim, decoder_hid_dim)\r\n",
        "    self.dropout = nn.Dropout(dropout_p)\r\n",
        "\r\n",
        "\r\n",
        "  def forward(self, src: Tensor) -> Tuple[Tensor]:\r\n",
        "    \r\n",
        "    embedded = self.dropout(self.embedding(src))\r\n",
        "\r\n",
        "    outputs, hidden = self.rnn(embedded)\r\n",
        "\r\n",
        "    hidden = torch.tanh( self.fc( torch.cat( [ hidden[-2,:,:] , hidden[-1,:,:] ], dim=1) ) )\r\n",
        "\r\n",
        "    return outputs, hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EAgvX7Kf3Zy"
      },
      "source": [
        "class Attention(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, enc_hid_dim: int, dec_hid_dim: int, attention_dim: int):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.enc_hid_dim = enc_hid_dim\r\n",
        "    self.dec_hid_dim = dec_hid_dim\r\n",
        "\r\n",
        "    self.attn_in = 2*enc_hid_dim + dec_hid_dim\r\n",
        "\r\n",
        "    self.attn = nn.Linear(self.attn_in, attention_dim)\r\n",
        "\r\n",
        "\r\n",
        "  def forward(self, decoder_hidden: Tensor, encoder_outputs: Tensor) -> Tensor:\r\n",
        "\r\n",
        "    src_len = encoder_outputs.shape[0]\r\n",
        "\r\n",
        "    repeated_dec_hid = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\r\n",
        "\r\n",
        "    encoder_outputs = encoder_outputs.permute(1,0,2)\r\n",
        "\r\n",
        "    energy = torch.tanh(self.attn(torch.cat((repeated_dec_hid,encoder_outputs), dim=2)))\r\n",
        "\r\n",
        "    attention = torch.sum(energy, dim=2)\r\n",
        "\r\n",
        "    return F.softmax(attention, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_LVPqBPg_lY"
      },
      "source": [
        "class Decoder(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, output_dim: int, emb_dim: int, enc_hid_dim: int, dec_hid_dim: int, dropout_p: float, attention: nn.Module ):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.output_dim = output_dim\r\n",
        "    self.emb_dim = emb_dim\r\n",
        "    self.enc_hid_dim = enc_hid_dim\r\n",
        "    self.dec_hid_dim = dec_hid_dim\r\n",
        "    self.dropout_p = dropout_p\r\n",
        "    self.attention = attention\r\n",
        "\r\n",
        "\r\n",
        "    self.embedding = nn.Embedding(output_dim, emb_dim)\r\n",
        "    self.rnn = nn.GRU( enc_hid_dim*2 +  emb_dim, dec_hid_dim)\r\n",
        "    self.out = nn.Linear(self.attention.attn_in + emb_dim, output_dim)\r\n",
        "    self.dropout = nn.Dropout(self.dropout_p)\r\n",
        "    \r\n",
        "  def _weighted_encoder_rep(self, decoder_hidden: Tensor, encoder_outputs: Tensor) -> Tensor:\r\n",
        "\r\n",
        "    a = self.attention(decoder_hidden, encoder_outputs)\r\n",
        "\r\n",
        "    a = a.unsqueeze(1)\r\n",
        "\r\n",
        "    encoder_outputs = encoder_outputs.permute(1, 0, 2)\r\n",
        "\r\n",
        "    weighted_encoder_rep = torch.bmm(a, encoder_outputs)\r\n",
        "\r\n",
        "    weighted_encoder_rep = weighted_encoder_rep.permute(1, 0, 2)\r\n",
        "\r\n",
        "    return weighted_encoder_rep\r\n",
        "\r\n",
        "  def forward(self, input: Tensor, decoder_hidden: Tensor, encoder_outputs: Tensor) -> Tuple[Tensor]:\r\n",
        "\r\n",
        "    input = input.unsqueeze(0)\r\n",
        "\r\n",
        "    embedded = self.dropout(self.embedding(input))\r\n",
        "\r\n",
        "    weighted_encoder_rep = self._weighted_encoder_rep(decoder_hidden, encoder_outputs)\r\n",
        "\r\n",
        "    rnn_input = torch.cat((embedded, weighted_encoder_rep), dim = 2)\r\n",
        "\r\n",
        "    output, decoder_hidden = self.rnn(rnn_input, decoder_hidden.unsqueeze(0))\r\n",
        "\r\n",
        "    embedded = embedded.squeeze(0)\r\n",
        "    output = output.squeeze(0)\r\n",
        "    weighted_encoder_rep = weighted_encoder_rep.squeeze(0)\r\n",
        "\r\n",
        "    output = self.out(torch.cat((output, weighted_encoder_rep, embedded), dim = 1))\r\n",
        "\r\n",
        "    return output, decoder_hidden.squeeze(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTCCvVme3Rba"
      },
      "source": [
        "class Seq2Seq(nn.Module):\r\n",
        "  def __init__(self, encoder: nn.Module, decoder: nn.Module, device: torch.device):\r\n",
        "      super().__init__()\r\n",
        "\r\n",
        "      self.encoder = encoder\r\n",
        "      self.decoder = decoder\r\n",
        "      self.device = device\r\n",
        "\r\n",
        "  def forward(self, src: Tensor, trg: Tensor, teacher_forcing_ratio: float = 0.5) -> Tensor:\r\n",
        "\r\n",
        "      batch_size = src.shape[1]\r\n",
        "      max_len = trg.shape[0]\r\n",
        "      trg_vocab_size = self.decoder.output_dim\r\n",
        "\r\n",
        "      outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\r\n",
        "\r\n",
        "      encoder_outputs, hidden = self.encoder(src)\r\n",
        "\r\n",
        "      # first input to the decoder is the <sos> token\r\n",
        "      output = trg[0,:]\r\n",
        "\r\n",
        "      for t in range(1, max_len):\r\n",
        "        output, hidden = self.decoder(output, hidden, encoder_outputs)\r\n",
        "        outputs[t] = output\r\n",
        "        teacher_force = random.random() < teacher_forcing_ratio\r\n",
        "        top1 = output.max(1)[1]\r\n",
        "        output = (trg[t] if teacher_force else top1)\r\n",
        "\r\n",
        "      return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DQKSr8a3mq9"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZe3CSK59eqL"
      },
      "source": [
        "import tqdm\r\n",
        "from tqdm import notebook\r\n",
        "\r\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i-heIfr3qkJ"
      },
      "source": [
        "model_hype = Namespace(\r\n",
        "    INPUT_DIM = len(mar_vocab),\r\n",
        "    OUTPUT_DIM = len(eng_vocab),\r\n",
        "    ENC_EMB_DIM = 32,\r\n",
        "    DEC_EMB_DIM = 32,\r\n",
        "    ENC_HID_DIM = 64,\r\n",
        "    DEC_HID_DIM = 64,\r\n",
        "    ATTN_DIM = 8,\r\n",
        "    ENC_DROPOUT = 0.5,\r\n",
        "    DEC_DROPOUT = 0.5,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Eltcn6N4Rbd"
      },
      "source": [
        "# creating the final model object\r\n",
        "enc = Encoder(model_hype.INPUT_DIM, model_hype.ENC_EMB_DIM, model_hype.ENC_HID_DIM, model_hype.DEC_HID_DIM, model_hype.ENC_DROPOUT)\r\n",
        "attn = Attention(model_hype.ENC_HID_DIM, model_hype.DEC_HID_DIM, model_hype.ATTN_DIM)\r\n",
        "dec = Decoder(model_hype.OUTPUT_DIM, model_hype.DEC_EMB_DIM, model_hype.ENC_HID_DIM, model_hype.DEC_HID_DIM, model_hype.DEC_DROPOUT, attn)\r\n",
        "model = Seq2Seq(enc, dec, hype.DEVICE).to(hype.DEVICE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ-goHav4ll5",
        "outputId": "d1dcba7e-c1bb-4c58-f1d4-687019dd1d39"
      },
      "source": [
        "def init_model(model: nn.Module):\r\n",
        "  for name, param in model.named_parameters():\r\n",
        "    if 'weight' in name:\r\n",
        "      nn.init.normal_(param.data, mean=0., std = 0.01)\r\n",
        "    else:\r\n",
        "      nn.init.constant_(param.data, 0.)\r\n",
        "\r\n",
        "model.apply(init_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(10004, 32)\n",
              "    (rnn): GRU(32, 64, bidirectional=True)\n",
              "    (fc): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=192, out_features=8, bias=True)\n",
              "    )\n",
              "    (embedding): Embedding(6400, 32)\n",
              "    (rnn): GRU(160, 64)\n",
              "    (out): Linear(in_features=224, out_features=6400, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzDB7jGZ5Bug",
        "outputId": "dae588af-70a9-403f-c36a-f37383d76e8b"
      },
      "source": [
        "def count_params (model: nn.Module):\r\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "\r\n",
        "print(f\"There are {count_params(model):,} parameters in the model.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 2,055,752 parameters in the model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPbcN95I6aKv"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())\r\n",
        "\r\n",
        "tar_PAD_IDX = eng_vocab['<pad>']\r\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tar_PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T_DC5VA7BjV"
      },
      "source": [
        "def train(model: nn.Module, iterator: torch.utils.data.DataLoader, optimizer: optim.Optimizer, criteria: nn.Module , clip: float, device: str):\r\n",
        "  model.train()\r\n",
        "\r\n",
        "  epoch_loss = 0\r\n",
        "\r\n",
        "  for _, (src,tar) in enumerate(iterator):\r\n",
        "    src, tar = src.to(device), tar.to(device)\r\n",
        "\r\n",
        "    optimizer.zero_grad()\r\n",
        "\r\n",
        "    output = model(src, tar)\r\n",
        "\r\n",
        "    output = output[1:].view(-1, output.shape[-1])\r\n",
        "    tar = tar[1:].view(-1)\r\n",
        "\r\n",
        "    loss = criteria(output, tar)\r\n",
        "\r\n",
        "    loss.backward()\r\n",
        "\r\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\r\n",
        "\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    epoch_loss += loss.item()\r\n",
        "  \r\n",
        "  return epoch_loss/len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IobAIJgP8Ky",
        "outputId": "bf9cb574-2ed0-4276-9b34-3b45f22f1a4b"
      },
      "source": [
        "if hype.load_checkpoint:\r\n",
        "  checkpoint = torch.load('seq2seq_attn_checkpoint.pth')\r\n",
        "\r\n",
        "  model.load_state_dict(checkpoint.model_params)\r\n",
        "  optimizer.load_state_dict(checkpoint.optim_params)\r\n",
        "  print(f\"epochs: {checkpoint.epoch_num} || loss: {checkpoint.loss}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epochs: 9 || loss: 3.2808422444382432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "0a5bc69a50df4f969fa3a87ef92dc73e",
            "897278a38794450598cfdd4c27f2a622",
            "7f9dfb0a912e4b5ea53b808223c8b58d",
            "700bcb83ee1e4a0d8bac09ac0f7b75e6",
            "5c384684e2774f018415d6025c05d61e",
            "c0955f812c014a80880d0efa6a18d103",
            "492aa27d8af0464fa9746efcaaeed5c4",
            "8593c4064e3045aab8769ea0cc96bad9"
          ]
        },
        "id": "3MucNUcv_pG9",
        "outputId": "5bba6f67-eec6-4d6e-ad35-3ee558237405"
      },
      "source": [
        "epoch_t = notebook.trange(hype.NUM_EPOCHS, desc='loss')\r\n",
        "\r\n",
        "for epoch in epoch_t:\r\n",
        "\r\n",
        "  train_loss = train(model,train_iter, optimizer, criterion, hype.CLIP, hype.DEVICE)\r\n",
        "\r\n",
        "  if hype.save_checkpoint:\r\n",
        "    checkpoint.epoch_num = epoch\r\n",
        "    checkpoint.model_params = model.state_dict()\r\n",
        "    checkpoint.optim_params = optimizer.state_dict()\r\n",
        "    checkpoint.loss = train_loss\r\n",
        "    torch.save(checkpoint,'seq2seq_attn_checkpoint.pth')\r\n",
        "\r\n",
        "  epoch_t.set_description(f\"loss: {train_loss: .5f}\")\r\n",
        "  epoch_t.refresh()\r\n",
        "  time.sleep(0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a5bc69a50df4f969fa3a87ef92dc73e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='loss', max=10.0, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-d9f0nIB0no"
      },
      "source": [
        "# Saving a checkpoint\r\n",
        "if hype.save_checkpoint:\r\n",
        "  checkpoint.model_params = model.state_dict()\r\n",
        "  checkpoint.optim_params = optimizer.state_dict()\r\n",
        "  torch.save(checkpoint,'seq2seq_attn_checkpoint.pth')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdrO9trQnwK8"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBh_ugPXoshz"
      },
      "source": [
        "def translate_sentence(sentence, src_tokenizer, trg_tokenizer, src_vocab, trg_vocab, model, device, max_len = 50):\r\n",
        "\r\n",
        "    model.eval()\r\n",
        "        \r\n",
        "    if isinstance(sentence, str):\r\n",
        "        tokens = [token.lower() for token in src_tokenizer(sentence)]\r\n",
        "    else:\r\n",
        "        tokens = [token.lower() for token in sentence]\r\n",
        "\r\n",
        "    tokens = [src_vocab['<sos>']] + tokens + [src_vocab['<eos>']]\r\n",
        "        \r\n",
        "    src_indexes = [src_vocab.stoi[token] for token in tokens]\r\n",
        "    \r\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\r\n",
        "\r\n",
        "    src_len = torch.LongTensor([len(src_indexes)]).to(device)\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "        encoder_outputs, hidden = model.encoder(src_tensor)\r\n",
        "\r\n",
        "    # mask = model.create_mask(src_tensor)\r\n",
        "        \r\n",
        "    trg_indexes = [trg_vocab.stoi[trg_vocab['<sos>']]]\r\n",
        "\r\n",
        "    # attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\r\n",
        "    \r\n",
        "    for i in range(max_len):\r\n",
        "\r\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\r\n",
        "                \r\n",
        "        with torch.no_grad():\r\n",
        "            output, hidden = model.decoder(trg_tensor, hidden, encoder_outputs,)\r\n",
        "\r\n",
        "        # attentions[i] = attention\r\n",
        "            \r\n",
        "        pred_token = output.argmax(1).item()\r\n",
        "        \r\n",
        "        trg_indexes.append(pred_token)\r\n",
        "\r\n",
        "        if pred_token == trg_vocab.stoi[trg_vocab['<eos>']]:\r\n",
        "            break\r\n",
        "    \r\n",
        "    trg_tokens = [trg_vocab.itos[i] for i in trg_indexes]\r\n",
        "    \r\n",
        "    return trg_tokens[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XCBSRPBq0yA",
        "outputId": "1a4b34e8-1ccb-42e3-e78a-d5ea8c570e51"
      },
      "source": [
        "sentence = data['marathi'][10000]\r\n",
        "print(sentence)\r\n",
        "out = translate_sentence(sentence, tokenize_mar, tokenize_eng, mar_vocab, eng_vocab, model, hype.DEVICE)\r\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "तसं चालेल.\n",
            "['He', 'can', 'be', 'a', 'to', '.', '.', '.', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSJBY23Uq522"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}