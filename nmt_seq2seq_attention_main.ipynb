{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nmt_seq2seq_attention_main.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "DRM-bUZo60qp",
        "La4DKCxV65JZ",
        "heI-Yc9i8pBc"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMyBYR0Q09OqtRdXRJqc+8w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "65649839b75e4461839b67b32a92a711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1bcc0995b94c450c8eb5683552a0e6ab",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1d9b3d62c0c74b2e927b3cedcff6a84d",
              "IPY_MODEL_761de3c3b44046deaaeadda67799b232"
            ]
          }
        },
        "1bcc0995b94c450c8eb5683552a0e6ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d9b3d62c0c74b2e927b3cedcff6a84d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7682f7ec71454ff1acf59f5ea0380813",
            "_dom_classes": [],
            "description": "loss:  2.55589: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 10,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_012f0f348cfb45099d6f540aea98fae1"
          }
        },
        "761de3c3b44046deaaeadda67799b232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7b107e34362a475a9e24d319ee1eba33",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10/10 [50:52&lt;00:00, 305.21s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1395a12c6f084572a059be06a9b1156a"
          }
        },
        "7682f7ec71454ff1acf59f5ea0380813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "012f0f348cfb45099d6f540aea98fae1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b107e34362a475a9e24d319ee1eba33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1395a12c6f084572a059be06a9b1156a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhavnicksm/marathi-neural-machine-translation/blob/main/nmt_seq2seq_attention_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m8OV0wClQDQ"
      },
      "source": [
        "Before beginning this notebook, ensure that you have data.csv in available in the working directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diGgpmn6_hO5"
      },
      "source": [
        "#!pip install torchtext==0.8.0"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vdbql_pf8PhO"
      },
      "source": [
        "#!python -m spacy download en"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkCLyMjMK0g_"
      },
      "source": [
        "## Hyperparameter declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-VxIa3PK5ZA"
      },
      "source": [
        "from argparse import Namespace"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mnp0_Z41K9OS"
      },
      "source": [
        "hype = Namespace(\r\n",
        "    LR = 0.1,\r\n",
        "    BATCH_SIZE = 128,\r\n",
        "    NUM_EPOCHS = 10,\r\n",
        "    CLIP = 1,\r\n",
        "    DEVICE = None,\r\n",
        "    save_checkpoint =True,\r\n",
        "    load_checkpoint = False\r\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILw_JUj5MGTP"
      },
      "source": [
        "checkpoint = Namespace(\r\n",
        "    epoch_num = 0,\r\n",
        "    model_params = None,\r\n",
        "    optim_params = None,\r\n",
        "    scheduler_params = None,\r\n",
        "    losses = [],\r\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDHMJQQALwNZ",
        "outputId": "e47efc5e-a6b9-412d-a473-ae760ff4133e"
      },
      "source": [
        "#example usage\r\n",
        "hype.BATCH_SIZE"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqxGUlxQNzEo",
        "outputId": "5673a644-f5be-46cb-a936-89c9404bbffc"
      },
      "source": [
        "#to dict\r\n",
        "vars(hype)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'BATCH_SIZE': 128,\n",
              " 'CLIP': 1,\n",
              " 'DEVICE': None,\n",
              " 'LR': 0.1,\n",
              " 'NUM_EPOCHS': 10,\n",
              " 'load_checkpoint': True,\n",
              " 'save_checkpoint': True}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wznA4tHCk3ZN"
      },
      "source": [
        "## Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRM-bUZo60qp"
      },
      "source": [
        "### Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2-a9XNPlOym"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "%matplotlib inline"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "K1ftPojC5LWC",
        "outputId": "1c7a44bb-43d4-4b4b-b066-c204178076c6"
      },
      "source": [
        "data = pd.read_csv('data.csv', header=None)\r\n",
        "data.columns = ['english', 'marathi']\r\n",
        "data.tail()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>marathi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>40746</th>\n",
              "      <td>Just saying you don't like fish because of the...</td>\n",
              "      <td>हड्डींमुळे मासे आवडत नाही असं म्हणणं हे काय मा...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40747</th>\n",
              "      <td>The Japanese Parliament today officially elect...</td>\n",
              "      <td>आज जपानी संसदेने अधिकृतरित्या र्‍यौतारौ हाशिमो...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40748</th>\n",
              "      <td>Tom tried to sell his old VCR instead of throw...</td>\n",
              "      <td>टॉमने त्याचा जुना व्ही.सी.आर फेकून टाकण्याऐवजी...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40749</th>\n",
              "      <td>You can't view Flash content on an iPad. Howev...</td>\n",
              "      <td>आयपॅडवर फ्लॅश आशय बघता येत नाही. पण तुम्ही त्य...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40750</th>\n",
              "      <td>In 1969, Roger Miller recorded a song called \"...</td>\n",
              "      <td>१९६९मध्ये रॉजर मिलरने \"यू डोन्ट वॉन्ट माय लव्ह...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 english                                            marathi\n",
              "40746  Just saying you don't like fish because of the...  हड्डींमुळे मासे आवडत नाही असं म्हणणं हे काय मा...\n",
              "40747  The Japanese Parliament today officially elect...  आज जपानी संसदेने अधिकृतरित्या र्‍यौतारौ हाशिमो...\n",
              "40748  Tom tried to sell his old VCR instead of throw...  टॉमने त्याचा जुना व्ही.सी.आर फेकून टाकण्याऐवजी...\n",
              "40749  You can't view Flash content on an iPad. Howev...  आयपॅडवर फ्लॅश आशय बघता येत नाही. पण तुम्ही त्य...\n",
              "40750  In 1969, Roger Miller recorded a song called \"...  १९६९मध्ये रॉजर मिलरने \"यू डोन्ट वॉन्ट माय लव्ह..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La4DKCxV65JZ"
      },
      "source": [
        "### Building tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7B9lmEV6-YN"
      },
      "source": [
        "import re\r\n",
        "import string\r\n",
        "import spacy"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LRf3QcZ5UYr"
      },
      "source": [
        "#tokenizers for both\r\n",
        "\r\n",
        "def tokenize_mar(text):\r\n",
        "  for punc in string.punctuation:\r\n",
        "    text = text.replace(punc, \" \"+punc+\" \" )\r\n",
        "  return [tok.strip() for tok in re.split(r' ', text) if tok!='']\r\n",
        "\r\n",
        "spacy_en = spacy.load('en')\r\n",
        "\r\n",
        "def tokenize_eng(text):\r\n",
        "  return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NikIP1q18A0N",
        "outputId": "8e04abf0-04c1-4f15-c032-605907672cdf"
      },
      "source": [
        "#examples of tokenized sentences\r\n",
        "ex_tok_mar = tokenize_mar(data['marathi'][40000])\r\n",
        "print(ex_tok_mar)\r\n",
        "\r\n",
        "ex_tok_eng = tokenize_eng(data['english'][40000])\r\n",
        "print(ex_tok_eng)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['उद्याची', 'मीटिंग', 'कुठे', 'असणार', 'आहे', 'हे', 'तुम्हाला', 'माहीत', 'आहे', 'का', '?']\n",
            "['Do', 'you', 'know', 'where', 'tomorrow', \"'s\", 'meeting', 'is', 'going', 'to', 'be', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heI-Yc9i8pBc"
      },
      "source": [
        "### Building Vocabularies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VslioD3n_IQk",
        "outputId": "98c25851-ac5d-42f6-a9e5-bd96509acf97"
      },
      "source": [
        "import torchtext\r\n",
        "from torchtext.vocab import Vocab\r\n",
        "from collections import Counter\r\n",
        "\r\n",
        "print(torchtext.__version__)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPlbylwm-x_0"
      },
      "source": [
        "def build_vocab(data, tokenizer):\r\n",
        "  counter = Counter()\r\n",
        "  for text in data:\r\n",
        "    counter.update(tokenizer(text))\r\n",
        "  return Vocab(counter, max_size=10000, specials=('<unk>','<pad>','<sos>','<eos>'),)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxdcFTz0AI61"
      },
      "source": [
        "mar_vocab = build_vocab(data['marathi'],tokenize_mar)\r\n",
        "eng_vocab = build_vocab(data['english'],tokenize_eng)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYHsSxxGAWi5",
        "outputId": "714e65e1-7106-42c0-8b9e-c951e38b9d0b"
      },
      "source": [
        "print(f'Length of Marathi vocab: {len(mar_vocab)}')\r\n",
        "print(f'Length of English vocab: {len(eng_vocab)}')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Marathi vocab: 10004\n",
            "Length of English vocab: 6400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB33hYgXAatb"
      },
      "source": [
        "### Changing the dataset to have tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85pgie6eI0n6"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QiR_mu7IC1l"
      },
      "source": [
        "def data_process(data, src_tokenizer, tar_tokenizer, src_vocab, tar_vocab):\r\n",
        "  raw_src_iter = iter(data['marathi'])\r\n",
        "  raw_tar_iter = iter(data['english'])\r\n",
        "\r\n",
        "  data = []\r\n",
        "\r\n",
        "  for (raw_src, raw_tar) in zip(raw_src_iter,raw_tar_iter):\r\n",
        "    src_tensor = torch.tensor([src_vocab.stoi[tok] for tok in src_tokenizer(raw_src)], dtype=torch.long)\r\n",
        "    tar_tensor = torch.tensor([tar_vocab.stoi[tok] for tok in tar_tokenizer(raw_tar)], dtype=torch.long)\r\n",
        "\r\n",
        "    data.append((src_tensor,tar_tensor))\r\n",
        "\r\n",
        "  return data"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9_SDBaaJjvx"
      },
      "source": [
        "dataset = data_process(data, tokenize_mar, tokenize_eng, mar_vocab, eng_vocab)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KYl2hSoJ32p"
      },
      "source": [
        "### DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SP46HnCPUfL"
      },
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\r\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oJc34wNLOgKQ",
        "outputId": "eb421b91-64e9-4aba-cad5-2dc61ce4cc29"
      },
      "source": [
        "hype.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n",
        "hype.DEVICE"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cpu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW0CDpopO3c2",
        "outputId": "67f7974a-d884-4d93-e4ec-0ff21ef0a572"
      },
      "source": [
        "PAD_IDX = mar_vocab[\"<pad>\"]\r\n",
        "SOS_IDX = mar_vocab[\"<sos>\"]\r\n",
        "EOS_IDX = mar_vocab[\"<eos>\"]\r\n",
        "\r\n",
        "print(f\"pad index: {PAD_IDX}\")\r\n",
        "print(f\"sos index: {SOS_IDX}\")\r\n",
        "print(f\"eos index: {EOS_IDX}\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pad index: 1\n",
            "sos index: 2\n",
            "eos index: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBmP0A76PS2A"
      },
      "source": [
        "def batch_proc(data_batch):\r\n",
        "  src_batch = []\r\n",
        "  tar_batch = []\r\n",
        "  \r\n",
        "  for (src_item, tar_item) in data_batch:\r\n",
        "    src_batch.append(torch.cat([torch.tensor([SOS_IDX]), src_item , torch.tensor([EOS_IDX])], dim=0))\r\n",
        "    tar_batch.append(torch.cat([torch.tensor([SOS_IDX]), tar_item , torch.tensor([EOS_IDX])], dim=0))\r\n",
        "  \r\n",
        "  src_batch = pad_sequence(src_batch, padding_value= PAD_IDX)\r\n",
        "  tar_batch = pad_sequence(tar_batch, padding_value= PAD_IDX)\r\n",
        "\r\n",
        "  return src_batch, tar_batch"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONdBjn6-V_oo"
      },
      "source": [
        "train_iter = DataLoader(dataset, batch_size= hype.BATCH_SIZE , shuffle=True, collate_fn= batch_proc)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjsfaWVfCy1m"
      },
      "source": [
        "# a = next(iter(train_iter))\r\n",
        "# print(a)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajP6GIFXORYE"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfpEN8iIdgZM"
      },
      "source": [
        "import random\r\n",
        "from typing import Tuple\r\n",
        "\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch import Tensor"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loyr0GQSOUA7"
      },
      "source": [
        "class Encoder(nn.Module):\r\n",
        "  '''\r\n",
        "      Encoder for the Sequence to sequence model\r\n",
        "  '''\r\n",
        "  def __init__(self, input_dim: int, emb_dim: int, encoder_hid_dim: int, decoder_hid_dim: int, dropout_p: float):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.input_dim = input_dim\r\n",
        "    self.emb_dim = emb_dim\r\n",
        "    self.enc_hid_dim = encoder_hid_dim\r\n",
        "    self.dec_hid_dim = decoder_hid_dim\r\n",
        "    self.dropout_p = dropout_p\r\n",
        "\r\n",
        "\r\n",
        "    self.embedding = nn.Embedding(input_dim, emb_dim)\r\n",
        "    self.rnn = nn.GRU(emb_dim, encoder_hid_dim, bidirectional= True)\r\n",
        "    self.fc = nn.Linear(2*encoder_hid_dim, decoder_hid_dim)\r\n",
        "    self.dropout = nn.Dropout(dropout_p)\r\n",
        "\r\n",
        "\r\n",
        "  def forward(self, src: Tensor) -> Tuple[Tensor]:\r\n",
        "    \r\n",
        "    embedded = self.dropout(self.embedding(src))\r\n",
        "\r\n",
        "    outputs, hidden = self.rnn(embedded)\r\n",
        "\r\n",
        "    hidden = torch.tanh( self.fc( torch.cat( [ hidden[-2,:,:] , hidden[-1,:,:] ], dim=1) ) )\r\n",
        "\r\n",
        "    return outputs, hidden"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EAgvX7Kf3Zy"
      },
      "source": [
        "class Attention(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, enc_hid_dim: int, dec_hid_dim: int, attention_dim: int):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.enc_hid_dim = enc_hid_dim\r\n",
        "    self.dec_hid_dim = dec_hid_dim\r\n",
        "\r\n",
        "    self.attn_in = 2*enc_hid_dim + dec_hid_dim\r\n",
        "\r\n",
        "    self.attn = nn.Linear(self.attn_in, attention_dim)\r\n",
        "\r\n",
        "\r\n",
        "  def forward(self, decoder_hidden: Tensor, encoder_outputs: Tensor) -> Tensor:\r\n",
        "\r\n",
        "    src_len = encoder_outputs.shape[0]\r\n",
        "\r\n",
        "    repeated_dec_hid = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\r\n",
        "\r\n",
        "    encoder_outputs = encoder_outputs.permute(1,0,2)\r\n",
        "\r\n",
        "    energy = torch.tanh(self.attn(torch.cat((repeated_dec_hid,encoder_outputs), dim=2)))\r\n",
        "\r\n",
        "    attention = torch.sum(energy, dim=2)\r\n",
        "\r\n",
        "    return F.softmax(attention, dim=1)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_LVPqBPg_lY"
      },
      "source": [
        "class Decoder(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, output_dim: int, emb_dim: int, enc_hid_dim: int, dec_hid_dim: int, dropout_p: float, attention: nn.Module ):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.output_dim = output_dim\r\n",
        "    self.emb_dim = emb_dim\r\n",
        "    self.enc_hid_dim = enc_hid_dim\r\n",
        "    self.dec_hid_dim = dec_hid_dim\r\n",
        "    self.dropout_p = dropout_p\r\n",
        "    self.attention = attention\r\n",
        "\r\n",
        "\r\n",
        "    self.embedding = nn.Embedding(output_dim, emb_dim)\r\n",
        "    self.rnn = nn.GRU( enc_hid_dim*2 +  emb_dim, dec_hid_dim)\r\n",
        "    self.out = nn.Linear(self.attention.attn_in + emb_dim, output_dim)\r\n",
        "    self.dropout = nn.Dropout(self.dropout_p)\r\n",
        "    \r\n",
        "  def _weighted_encoder_rep(self, decoder_hidden: Tensor, encoder_outputs: Tensor) -> Tensor:\r\n",
        "\r\n",
        "    a = self.attention(decoder_hidden, encoder_outputs)\r\n",
        "\r\n",
        "    a = a.unsqueeze(1)\r\n",
        "\r\n",
        "    encoder_outputs = encoder_outputs.permute(1, 0, 2)\r\n",
        "\r\n",
        "    weighted_encoder_rep = torch.bmm(a, encoder_outputs)\r\n",
        "\r\n",
        "    weighted_encoder_rep = weighted_encoder_rep.permute(1, 0, 2)\r\n",
        "\r\n",
        "    return weighted_encoder_rep\r\n",
        "\r\n",
        "  def forward(self, input: Tensor, decoder_hidden: Tensor, encoder_outputs: Tensor) -> Tuple[Tensor]:\r\n",
        "\r\n",
        "    input = input.unsqueeze(0)\r\n",
        "\r\n",
        "    embedded = self.dropout(self.embedding(input))\r\n",
        "\r\n",
        "    weighted_encoder_rep = self._weighted_encoder_rep(decoder_hidden, encoder_outputs)\r\n",
        "\r\n",
        "    rnn_input = torch.cat((embedded, weighted_encoder_rep), dim = 2)\r\n",
        "\r\n",
        "    output, decoder_hidden = self.rnn(rnn_input, decoder_hidden.unsqueeze(0))\r\n",
        "\r\n",
        "    embedded = embedded.squeeze(0)\r\n",
        "    output = output.squeeze(0)\r\n",
        "    weighted_encoder_rep = weighted_encoder_rep.squeeze(0)\r\n",
        "\r\n",
        "    output = self.out(torch.cat((output, weighted_encoder_rep, embedded), dim = 1))\r\n",
        "\r\n",
        "    return output, decoder_hidden.squeeze(0)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTCCvVme3Rba"
      },
      "source": [
        "class Seq2Seq(nn.Module):\r\n",
        "  def __init__(self, encoder: nn.Module, decoder: nn.Module, device: torch.device):\r\n",
        "      super().__init__()\r\n",
        "\r\n",
        "      self.encoder = encoder\r\n",
        "      self.decoder = decoder\r\n",
        "      self.device = device\r\n",
        "\r\n",
        "  def forward(self, src: Tensor, trg: Tensor, teacher_forcing_ratio: float = 0.5) -> Tensor:\r\n",
        "\r\n",
        "      batch_size = src.shape[1]\r\n",
        "      max_len = trg.shape[0]\r\n",
        "      trg_vocab_size = self.decoder.output_dim\r\n",
        "\r\n",
        "      outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\r\n",
        "\r\n",
        "      encoder_outputs, hidden = self.encoder(src)\r\n",
        "\r\n",
        "      # first input to the decoder is the <sos> token\r\n",
        "      output = trg[0,:]\r\n",
        "\r\n",
        "      for t in range(1, max_len):\r\n",
        "        output, hidden = self.decoder(output, hidden, encoder_outputs)\r\n",
        "        outputs[t] = output\r\n",
        "        teacher_force = random.random() < teacher_forcing_ratio\r\n",
        "        top1 = output.max(1)[1]\r\n",
        "        output = (trg[t] if teacher_force else top1)\r\n",
        "\r\n",
        "      return outputs"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DQKSr8a3mq9"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZe3CSK59eqL"
      },
      "source": [
        "import tqdm\r\n",
        "from tqdm import notebook\r\n",
        "\r\n",
        "import time"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i-heIfr3qkJ"
      },
      "source": [
        "model_hype = Namespace(\r\n",
        "    INPUT_DIM = len(mar_vocab),\r\n",
        "    OUTPUT_DIM = len(eng_vocab),\r\n",
        "    ENC_EMB_DIM = 32,\r\n",
        "    DEC_EMB_DIM = 32,\r\n",
        "    ENC_HID_DIM = 64,\r\n",
        "    DEC_HID_DIM = 64,\r\n",
        "    ATTN_DIM = 8,\r\n",
        "    ENC_DROPOUT = 0.5,\r\n",
        "    DEC_DROPOUT = 0.5,\r\n",
        ")"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Eltcn6N4Rbd"
      },
      "source": [
        "# creating the final model object\r\n",
        "enc = Encoder(model_hype.INPUT_DIM, model_hype.ENC_EMB_DIM, model_hype.ENC_HID_DIM, model_hype.DEC_HID_DIM, model_hype.ENC_DROPOUT)\r\n",
        "attn = Attention(model_hype.ENC_HID_DIM, model_hype.DEC_HID_DIM, model_hype.ATTN_DIM)\r\n",
        "dec = Decoder(model_hype.OUTPUT_DIM, model_hype.DEC_EMB_DIM, model_hype.ENC_HID_DIM, model_hype.DEC_HID_DIM, model_hype.DEC_DROPOUT, attn)\r\n",
        "model = Seq2Seq(enc, dec, hype.DEVICE).to(hype.DEVICE)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ-goHav4ll5",
        "outputId": "d4ba01c1-d661-40cb-dc65-56fcbb42ec16"
      },
      "source": [
        "def init_model(model: nn.Module):\r\n",
        "  for name, param in model.named_parameters():\r\n",
        "    if 'weight' in name:\r\n",
        "      nn.init.normal_(param.data, mean=0., std = 0.01)\r\n",
        "    else:\r\n",
        "      nn.init.constant_(param.data, 0.)\r\n",
        "\r\n",
        "model.apply(init_model)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(10004, 32)\n",
              "    (rnn): GRU(32, 64, bidirectional=True)\n",
              "    (fc): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=192, out_features=8, bias=True)\n",
              "    )\n",
              "    (embedding): Embedding(6400, 32)\n",
              "    (rnn): GRU(160, 64)\n",
              "    (out): Linear(in_features=224, out_features=6400, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzDB7jGZ5Bug",
        "outputId": "5e41be07-9f59-4ab4-d831-3e608cc1def3"
      },
      "source": [
        "def count_params (model: nn.Module):\r\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "\r\n",
        "print(f\"There are {count_params(model):,} parameters in the model.\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 2,055,752 parameters in the model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPbcN95I6aKv"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr= hype.LR)\r\n",
        "\r\n",
        "tar_PAD_IDX = eng_vocab['<pad>']\r\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tar_PAD_IDX)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPu8mg-4UVhX"
      },
      "source": [
        "#build scheduler for plateu of the loss rate\r\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,factor = 0.1, patience=10, threshold=0.001, min_lr= 10e-7, verbose= True)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T_DC5VA7BjV"
      },
      "source": [
        "def train(model: nn.Module, iterator: torch.utils.data.DataLoader, optimizer: optim.Optimizer, criteria: nn.Module , clip: float, device: str):\r\n",
        "  model.train()\r\n",
        "\r\n",
        "  epoch_loss = 0\r\n",
        "\r\n",
        "  for _, (src,tar) in enumerate(iterator):\r\n",
        "    src, tar = src.to(device), tar.to(device)\r\n",
        "\r\n",
        "    optimizer.zero_grad()\r\n",
        "\r\n",
        "    output = model(src, tar)\r\n",
        "\r\n",
        "    output = output[1:].view(-1, output.shape[-1])\r\n",
        "    tar = tar[1:].view(-1)\r\n",
        "\r\n",
        "    loss = criteria(output, tar)\r\n",
        "\r\n",
        "    loss.backward()\r\n",
        "\r\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\r\n",
        "\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    epoch_loss += loss.item()\r\n",
        "  \r\n",
        "  return epoch_loss/len(iterator)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gndqZe6cUOCT",
        "outputId": "56511f51-5aaf-4478-c8c3-8a211b2c2c9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vars(checkpoint)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch_num': 16,\n",
              " 'losses': [5.355511729620093,\n",
              "  4.436312052149757,\n",
              "  4.212425391128444,\n",
              "  3.977918492589251,\n",
              "  3.8003496959291656,\n",
              "  3.6709356165978604,\n",
              "  3.513562492442355,\n",
              "  3.4013117361218206,\n",
              "  3.2743682285835005,\n",
              "  3.1439867923999656,\n",
              "  3.037128121127903,\n",
              "  2.9269616992496026,\n",
              "  2.82783656508945,\n",
              "  2.7363877490770108,\n",
              "  2.626015943419597,\n",
              "  2.5558856908804195],\n",
              " 'model_params': OrderedDict([('encoder.embedding.weight',\n",
              "               tensor([[ 0.0417, -0.0096, -0.0141,  ..., -0.0094,  0.0448, -0.0461],\n",
              "                       [-0.0578, -0.0605,  0.1452,  ..., -0.0394, -0.0099, -0.0301],\n",
              "                       [-0.0112, -0.0335,  0.0107,  ..., -0.0147,  0.0032,  0.0034],\n",
              "                       ...,\n",
              "                       [ 0.0043, -0.0248, -0.0335,  ..., -0.0826, -0.0303,  0.0062],\n",
              "                       [ 0.0229, -0.0797, -0.0184,  ..., -0.1278,  0.1152, -0.1614],\n",
              "                       [ 0.0036, -0.1047, -0.0373,  ...,  0.1168,  0.0230,  0.0770]])),\n",
              "              ('encoder.rnn.weight_ih_l0',\n",
              "               tensor([[ 0.2403, -0.0583, -0.2196,  ...,  0.3147, -0.5081, -0.0951],\n",
              "                       [ 0.2779, -0.2013, -0.1554,  ..., -0.2280,  0.3584, -0.4086],\n",
              "                       [-0.3029,  0.2468,  0.1744,  ...,  0.8190, -0.7412,  0.8680],\n",
              "                       ...,\n",
              "                       [-0.5696,  0.0046,  0.0869,  ...,  0.3506, -1.5443,  0.9967],\n",
              "                       [-0.0296,  0.1058, -0.2610,  ...,  0.0061, -0.2837,  0.0130],\n",
              "                       [-0.2775, -0.2368,  0.0751,  ..., -0.1694, -0.9682,  0.6704]])),\n",
              "              ('encoder.rnn.weight_hh_l0',\n",
              "               tensor([[-5.8944e-02,  2.1292e-02,  9.1468e-02,  ..., -8.3270e-02,\n",
              "                         1.5466e-01,  8.4229e-03],\n",
              "                       [-7.7079e-02, -2.5213e-01,  1.2193e-04,  ...,  4.0829e-02,\n",
              "                        -1.2227e-01, -2.3216e-02],\n",
              "                       [ 5.7807e-02, -3.1468e-03, -2.1575e-02,  ..., -4.5452e-02,\n",
              "                         2.2304e-02, -1.0406e-01],\n",
              "                       ...,\n",
              "                       [-3.6896e-03, -1.0997e-01, -6.3107e-02,  ...,  1.4134e-01,\n",
              "                         3.8651e-02, -2.2033e-02],\n",
              "                       [ 5.7697e-02, -5.5570e-03,  6.2898e-02,  ..., -9.8580e-04,\n",
              "                         1.8290e-01,  1.7509e-01],\n",
              "                       [ 9.2901e-02,  5.9580e-02,  2.3177e-02,  ...,  1.9428e-02,\n",
              "                         4.0745e-03,  2.2779e-01]])),\n",
              "              ('encoder.rnn.bias_ih_l0',\n",
              "               tensor([ 5.3630e-02,  3.0502e-01, -2.5274e-02,  1.3100e-01,  1.2781e-01,\n",
              "                       -2.6342e-02,  1.7155e-01,  6.3386e-02,  2.2213e-01,  5.0738e-02,\n",
              "                        8.7541e-02,  1.2434e-01,  6.4105e-02,  1.9489e-01, -1.2890e-02,\n",
              "                        1.6873e-01,  3.9133e-03,  1.6117e-01,  8.8960e-02, -5.6639e-02,\n",
              "                       -2.0017e-03,  2.4367e-03,  1.3762e-01, -7.6362e-02,  1.4429e-01,\n",
              "                       -4.6280e-02,  9.1562e-02,  4.7978e-02,  7.1113e-02, -1.0966e-02,\n",
              "                        7.9121e-02,  4.0028e-03,  9.8388e-03,  2.3783e-01,  4.9891e-02,\n",
              "                        1.8797e-03,  8.7274e-02,  2.0493e-02,  8.6347e-02, -3.6240e-02,\n",
              "                        2.3615e-01, -3.9607e-03,  1.2543e-01,  8.6259e-02,  4.2846e-02,\n",
              "                        5.1909e-02,  2.2706e-01,  1.1072e-01,  3.9471e-02,  1.1382e-01,\n",
              "                       -1.1240e-01, -1.0713e-02,  3.3965e-02,  6.9870e-02,  1.0692e-01,\n",
              "                        7.4183e-02,  6.8279e-02,  2.5497e-02,  2.3805e-01,  1.0146e-02,\n",
              "                        2.4895e-01,  1.2698e-02,  1.1814e-03,  4.4182e-02,  2.7240e-01,\n",
              "                        2.1899e-01, -1.5714e-01, -3.0499e-03,  1.8306e-01,  1.0475e-01,\n",
              "                       -6.5254e-01, -4.7897e-01, -7.1434e-01,  9.3393e-02, -1.9506e-01,\n",
              "                       -4.7809e-02, -3.6098e-01, -5.4835e-01,  5.9561e-02, -4.0089e-01,\n",
              "                       -3.3622e-01, -2.5871e-01, -6.0016e-01, -2.3496e-01,  8.0379e-02,\n",
              "                       -6.7076e-01, -6.8590e-02, -5.3207e-01, -2.9725e-01, -1.1013e-01,\n",
              "                       -3.6739e-01, -6.9432e-01, -3.6097e-01, -2.3791e-01,  6.4666e-02,\n",
              "                        1.8739e-01, -5.7251e-01, -1.7406e-01, -1.1583e-01, -2.2899e-01,\n",
              "                       -1.1531e-01,  1.7120e-02, -3.4778e-01, -1.7542e-01, -1.3066e-01,\n",
              "                       -5.1113e-01,  1.0075e-01, -1.0998e-01,  4.2463e-02, -1.9452e-01,\n",
              "                        2.5609e-01,  2.1740e-01, -6.5190e-02, -2.9325e-01, -4.4097e-02,\n",
              "                       -5.7705e-01, -1.9332e-01,  6.1620e-02, -1.9608e-01, -8.1138e-01,\n",
              "                       -1.6913e-01, -3.1297e-01, -1.7733e-01,  8.8003e-02, -3.1955e-01,\n",
              "                       -3.9013e-01,  3.0243e-01, -1.4094e-01,  4.2636e-02, -1.6524e-01,\n",
              "                       -8.3894e-02,  5.3438e-02, -9.5901e-02,  2.4166e-02, -1.3702e-03,\n",
              "                       -4.6774e-03,  1.7311e-02, -3.5060e-02, -3.1957e-02,  2.0243e-02,\n",
              "                        2.2666e-01,  5.6784e-02, -3.8183e-02,  4.0253e-02,  1.5402e-01,\n",
              "                        1.6511e-01, -1.0331e-02,  4.1979e-02, -7.6594e-02, -6.7974e-02,\n",
              "                       -7.2135e-02, -1.3186e-02, -3.2656e-02, -3.9894e-02, -1.4849e-01,\n",
              "                       -1.8766e-02,  6.0696e-02,  2.1134e-02,  1.4389e-01, -3.7888e-02,\n",
              "                        3.7294e-02,  5.2212e-02,  1.0570e-02,  6.6834e-02, -2.7092e-02,\n",
              "                       -3.6640e-02, -1.3520e-01,  1.4580e-02, -8.5522e-02,  1.5990e-03,\n",
              "                        7.2006e-02, -9.1064e-02, -9.2181e-02,  4.3779e-02,  1.4034e-01,\n",
              "                       -4.2058e-02,  3.8205e-04,  1.0272e-01,  7.8035e-02, -2.7976e-02,\n",
              "                       -1.6405e-02,  2.4970e-02, -3.6281e-02,  1.6471e-01, -6.3938e-02,\n",
              "                       -1.9614e-02,  6.9218e-02, -2.8122e-03,  3.1972e-01,  5.9324e-02,\n",
              "                       -6.5207e-02, -6.8383e-02])),\n",
              "              ('encoder.rnn.bias_hh_l0',\n",
              "               tensor([ 0.0536,  0.3050, -0.0253,  0.1310,  0.1278, -0.0263,  0.1715,  0.0634,\n",
              "                        0.2221,  0.0507,  0.0875,  0.1243,  0.0641,  0.1949, -0.0129,  0.1687,\n",
              "                        0.0039,  0.1612,  0.0890, -0.0566, -0.0020,  0.0024,  0.1376, -0.0764,\n",
              "                        0.1443, -0.0463,  0.0916,  0.0480,  0.0711, -0.0110,  0.0791,  0.0040,\n",
              "                        0.0098,  0.2378,  0.0499,  0.0019,  0.0873,  0.0205,  0.0863, -0.0362,\n",
              "                        0.2361, -0.0040,  0.1254,  0.0863,  0.0428,  0.0519,  0.2271,  0.1107,\n",
              "                        0.0395,  0.1138, -0.1124, -0.0107,  0.0340,  0.0699,  0.1069,  0.0742,\n",
              "                        0.0683,  0.0255,  0.2380,  0.0101,  0.2489,  0.0127,  0.0012,  0.0442,\n",
              "                        0.2724,  0.2190, -0.1571, -0.0030,  0.1831,  0.1047, -0.6525, -0.4790,\n",
              "                       -0.7143,  0.0934, -0.1951, -0.0478, -0.3610, -0.5484,  0.0596, -0.4009,\n",
              "                       -0.3362, -0.2587, -0.6002, -0.2350,  0.0804, -0.6708, -0.0686, -0.5321,\n",
              "                       -0.2973, -0.1101, -0.3674, -0.6943, -0.3610, -0.2379,  0.0647,  0.1874,\n",
              "                       -0.5725, -0.1741, -0.1158, -0.2290, -0.1153,  0.0171, -0.3478, -0.1754,\n",
              "                       -0.1307, -0.5111,  0.1008, -0.1100,  0.0425, -0.1945,  0.2561,  0.2174,\n",
              "                       -0.0652, -0.2933, -0.0441, -0.5771, -0.1933,  0.0616, -0.1961, -0.8114,\n",
              "                       -0.1691, -0.3130, -0.1773,  0.0880, -0.3195, -0.3901,  0.3024, -0.1409,\n",
              "                        0.0563, -0.1476, -0.0915,  0.0603, -0.0620,  0.0190, -0.0713, -0.0597,\n",
              "                       -0.0165, -0.0733,  0.0290,  0.0292,  0.2555,  0.0829, -0.0560,  0.0141,\n",
              "                        0.2336,  0.2167, -0.0196,  0.0331, -0.0705, -0.0110, -0.0646,  0.0093,\n",
              "                       -0.0641, -0.1093, -0.2372,  0.0884,  0.1096,  0.0024,  0.1440, -0.0070,\n",
              "                        0.0115,  0.0829, -0.0522,  0.1237, -0.0150, -0.0687, -0.1427,  0.0106,\n",
              "                       -0.0811, -0.1057,  0.1666, -0.1108, -0.1516,  0.0428,  0.1049, -0.0546,\n",
              "                        0.0319,  0.1416,  0.0659, -0.1068, -0.0259,  0.0397, -0.0400,  0.2574,\n",
              "                       -0.0016, -0.0789,  0.1222,  0.0244,  0.3101,  0.1121, -0.0606,  0.0035])),\n",
              "              ('encoder.rnn.weight_ih_l0_reverse',\n",
              "               tensor([[-0.0431,  0.0222,  0.0374,  ...,  0.0819, -0.3161,  0.3443],\n",
              "                       [-0.2832, -0.5223,  1.1821,  ..., -0.3386,  0.0933, -0.3114],\n",
              "                       [ 0.1292, -0.3961,  0.0927,  ..., -0.2150,  0.1926, -0.1297],\n",
              "                       ...,\n",
              "                       [ 1.1373,  0.1052, -0.6528,  ...,  0.0760,  0.1336, -0.0206],\n",
              "                       [ 0.2750, -0.6348,  0.1400,  ..., -1.3078,  1.3401, -1.1223],\n",
              "                       [ 0.2074,  0.5653, -0.7063,  ...,  1.2277, -1.0096,  0.7490]])),\n",
              "              ('encoder.rnn.weight_hh_l0_reverse',\n",
              "               tensor([[-0.1147, -0.0830, -0.3595,  ...,  0.1194,  0.2369, -0.1669],\n",
              "                       [ 0.0681,  0.1415, -0.1040,  ..., -0.0769,  0.0084,  0.1242],\n",
              "                       [ 0.0344,  0.2197, -0.0839,  ..., -0.0383,  0.1052, -0.1142],\n",
              "                       ...,\n",
              "                       [-0.0991, -0.2134, -0.0069,  ...,  0.0565, -0.0168, -0.2468],\n",
              "                       [-0.0384,  0.1706,  0.0393,  ...,  0.0827,  0.3626, -0.1876],\n",
              "                       [ 0.0977, -0.0994, -0.0393,  ..., -0.0210, -0.1340,  0.2758]])),\n",
              "              ('encoder.rnn.bias_ih_l0_reverse',\n",
              "               tensor([ 2.2869e-03,  2.3685e-02,  1.3967e-01,  2.0000e-01,  6.3106e-02,\n",
              "                        7.8819e-02,  7.5206e-02,  1.1698e-01,  1.2940e-01,  1.0745e-01,\n",
              "                        3.1317e-01, -1.7524e-02,  1.1266e-01,  4.7159e-02,  1.1041e-01,\n",
              "                       -8.9793e-03,  1.5672e-01,  1.2383e-01,  2.1867e-01, -7.8381e-02,\n",
              "                        8.6828e-02,  2.9716e-02,  1.4265e-01,  7.1883e-02, -2.4570e-02,\n",
              "                        4.1062e-02, -7.0905e-02, -1.1258e-01, -3.2744e-02,  4.9182e-02,\n",
              "                        2.8624e-01,  1.2138e-01,  1.5464e-01,  1.5941e-02, -3.5837e-02,\n",
              "                        2.8117e-02,  1.4645e-01,  5.4280e-03,  1.1617e-01,  2.8049e-01,\n",
              "                        2.2867e-01,  1.0574e-01,  1.8287e-01,  2.0582e-01,  1.6833e-02,\n",
              "                        1.9550e-01,  4.8936e-02,  1.5095e-01,  6.2773e-02,  1.2737e-01,\n",
              "                        5.6820e-02,  7.4639e-02,  1.0030e-01,  7.2468e-03,  1.4373e-01,\n",
              "                        1.6249e-01,  1.5976e-01, -1.0488e-01, -4.1284e-02,  2.0994e-01,\n",
              "                        1.4399e-01,  1.1182e-01,  6.3265e-02, -4.5768e-02, -2.3360e-01,\n",
              "                       -7.0955e-01, -4.1613e-01, -2.2086e-01, -6.7740e-01, -4.8826e-02,\n",
              "                       -1.3237e-01, -5.5078e-01, -1.2262e-01,  1.5475e-01, -3.8767e-01,\n",
              "                       -2.2540e-01, -9.9728e-02,  1.7280e-01,  1.5780e-03, -1.7555e-01,\n",
              "                       -4.8732e-01, -3.0271e-01, -8.0693e-01,  1.7607e-01, -1.7345e-01,\n",
              "                        1.5196e-02, -2.5429e-01, -5.8495e-01,  1.4434e-01, -1.3345e-01,\n",
              "                       -3.2053e-01, -2.3609e-01, -5.4799e-01, -4.8919e-01, -1.6665e-02,\n",
              "                        1.1527e-01, -1.5990e-01, -3.2644e-01,  4.1918e-02, -9.0892e-02,\n",
              "                        3.8796e-02, -1.7374e-01, -1.1671e-01, -7.4902e-01, -4.5640e-01,\n",
              "                       -2.7091e-01, -6.8283e-01, -4.5018e-01, -9.4631e-02, -6.3331e-01,\n",
              "                       -3.6395e-01, -1.0118e-01, -2.0650e-01, -3.3671e-01, -5.4487e-01,\n",
              "                        1.5885e-01, -2.1747e-01, -2.7374e-01, -5.7723e-02, -9.3385e-02,\n",
              "                       -5.0406e-01, -6.2561e-01, -7.7721e-01, -8.4870e-02, -1.5193e-01,\n",
              "                       -6.1961e-01,  8.6739e-02, -9.4547e-02,  4.7539e-02,  3.4489e-02,\n",
              "                       -1.0796e-01, -1.6464e-01, -7.1575e-02,  2.3385e-02,  6.2136e-02,\n",
              "                       -6.4477e-02,  6.6439e-02, -1.0093e-01,  9.1928e-02,  2.0196e-02,\n",
              "                        7.9242e-02,  1.1195e-01,  1.8972e-01,  3.3801e-02, -6.3914e-02,\n",
              "                        2.1099e-02, -1.0954e-01, -5.1803e-02,  3.2677e-02, -1.6623e-02,\n",
              "                        2.4012e-02, -3.2206e-02, -6.6623e-02, -7.0004e-02,  6.9186e-02,\n",
              "                       -6.8044e-03,  3.1049e-02,  4.8566e-02,  2.8838e-01,  2.4513e-02,\n",
              "                        1.1323e-02,  9.4972e-02,  3.7345e-02,  1.0513e-01, -1.5958e-01,\n",
              "                        1.2427e-02,  3.2170e-02,  1.8638e-01,  1.9411e-02, -5.1795e-02,\n",
              "                        1.0328e-01,  3.6154e-02, -1.3000e-01, -7.0165e-02,  1.7076e-01,\n",
              "                        1.0024e-01, -5.1360e-03, -1.3633e-03,  1.3424e-02,  6.8548e-04,\n",
              "                        5.4537e-02,  4.8121e-02, -1.0097e-01,  2.4424e-02,  5.1376e-02,\n",
              "                        4.5999e-02,  2.2047e-02, -2.6528e-02, -1.4522e-01,  3.6162e-02,\n",
              "                       -7.2663e-02,  6.2124e-02])),\n",
              "              ('encoder.rnn.bias_hh_l0_reverse',\n",
              "               tensor([ 0.0023,  0.0237,  0.1397,  0.2000,  0.0631,  0.0788,  0.0752,  0.1170,\n",
              "                        0.1294,  0.1075,  0.3132, -0.0175,  0.1127,  0.0472,  0.1104, -0.0090,\n",
              "                        0.1567,  0.1238,  0.2187, -0.0784,  0.0868,  0.0297,  0.1427,  0.0719,\n",
              "                       -0.0246,  0.0411, -0.0709, -0.1126, -0.0327,  0.0492,  0.2862,  0.1214,\n",
              "                        0.1546,  0.0159, -0.0358,  0.0281,  0.1465,  0.0054,  0.1162,  0.2805,\n",
              "                        0.2287,  0.1057,  0.1829,  0.2058,  0.0168,  0.1955,  0.0489,  0.1510,\n",
              "                        0.0628,  0.1274,  0.0568,  0.0746,  0.1003,  0.0072,  0.1437,  0.1625,\n",
              "                        0.1598, -0.1049, -0.0413,  0.2099,  0.1440,  0.1118,  0.0633, -0.0458,\n",
              "                       -0.2336, -0.7095, -0.4161, -0.2209, -0.6774, -0.0488, -0.1324, -0.5508,\n",
              "                       -0.1226,  0.1548, -0.3877, -0.2254, -0.0997,  0.1728,  0.0016, -0.1755,\n",
              "                       -0.4873, -0.3027, -0.8069,  0.1761, -0.1734,  0.0152, -0.2543, -0.5850,\n",
              "                        0.1443, -0.1335, -0.3205, -0.2361, -0.5480, -0.4892, -0.0167,  0.1153,\n",
              "                       -0.1599, -0.3264,  0.0419, -0.0909,  0.0388, -0.1737, -0.1167, -0.7490,\n",
              "                       -0.4564, -0.2709, -0.6828, -0.4502, -0.0946, -0.6333, -0.3639, -0.1012,\n",
              "                       -0.2065, -0.3367, -0.5449,  0.1589, -0.2175, -0.2737, -0.0577, -0.0934,\n",
              "                       -0.5041, -0.6256, -0.7772, -0.0849, -0.1519, -0.6196,  0.0867, -0.0945,\n",
              "                       -0.0307, -0.0222, -0.0914, -0.1748,  0.0015,  0.0259,  0.0399, -0.1124,\n",
              "                        0.0738, -0.1232,  0.1830, -0.0108,  0.0487, -0.0058,  0.1385,  0.0615,\n",
              "                        0.0064,  0.0529, -0.1076,  0.0427,  0.0170,  0.0666,  0.0237,  0.0975,\n",
              "                        0.0363, -0.0460,  0.0176, -0.0261, -0.0172,  0.1083,  0.3000, -0.2134,\n",
              "                       -0.0233,  0.0498, -0.0610, -0.0225, -0.0708, -0.0596,  0.0422,  0.2809,\n",
              "                        0.0142,  0.0240,  0.1252, -0.0086, -0.0351, -0.1295,  0.1493,  0.2217,\n",
              "                        0.0264, -0.1131,  0.1774,  0.0558,  0.0313,  0.0165, -0.0414,  0.0319,\n",
              "                       -0.0029, -0.0060,  0.0347, -0.0325, -0.1007,  0.0718,  0.0914, -0.1195])),\n",
              "              ('encoder.fc.weight',\n",
              "               tensor([[-0.1091, -0.1858,  0.0866,  ..., -0.3053, -0.1982,  0.0753],\n",
              "                       [-0.0522, -0.0052,  0.1752,  ...,  0.0600, -0.1981,  0.1669],\n",
              "                       [ 0.1279,  0.0752, -0.0428,  ...,  0.2567, -0.3876,  0.1762],\n",
              "                       ...,\n",
              "                       [ 0.0569,  0.1505, -0.0262,  ...,  0.0010, -0.3942,  0.3947],\n",
              "                       [-0.0022,  0.0312, -0.0019,  ..., -0.2048, -0.2274,  0.1523],\n",
              "                       [-0.0448,  0.0991, -0.0100,  ...,  0.0180,  0.1508, -0.1455]])),\n",
              "              ('encoder.fc.bias',\n",
              "               tensor([-0.0272, -0.1361, -0.1231,  0.1047, -0.0577, -0.2081,  0.1163, -0.1986,\n",
              "                        0.0352,  0.1277, -0.1158,  0.1338,  0.0527, -0.0468, -0.3632,  0.1110,\n",
              "                        0.1437, -0.1812,  0.1309, -0.1080,  0.0936, -0.1624, -0.0454, -0.3335,\n",
              "                        0.0132, -0.0277,  0.0081,  0.0768,  0.3655,  0.0510, -0.2841,  0.1152,\n",
              "                        0.1755, -0.4643,  0.1267,  0.1105,  0.1513,  0.0461, -0.3787,  0.0424,\n",
              "                        0.1580, -0.1530, -0.5744, -0.0626, -0.1139,  0.0184, -0.5926, -0.0842,\n",
              "                       -0.1463, -0.1950, -0.2620, -0.4743,  0.1641, -0.2875, -0.0327,  0.0973,\n",
              "                       -0.1964, -0.1400,  0.0478, -0.1494, -0.1617, -0.4371, -0.0788, -0.2006])),\n",
              "              ('decoder.attention.attn.weight',\n",
              "               tensor([[ 0.0204,  0.0432,  0.1175,  ..., -0.1820, -0.0108, -0.1527],\n",
              "                       [ 0.1371, -0.0769,  0.0456,  ...,  0.2116, -0.0019,  0.0227],\n",
              "                       [ 0.3187,  0.0607, -0.0336,  ..., -0.0433, -0.0816,  0.0715],\n",
              "                       ...,\n",
              "                       [-0.1449,  0.0341, -0.0486,  ..., -0.3477, -0.0137,  0.0408],\n",
              "                       [ 0.2874, -0.0181,  0.0920,  ..., -0.1017, -0.0855,  0.1538],\n",
              "                       [-0.1434,  0.0434,  0.1968,  ..., -0.0441,  0.0023,  0.0596]])),\n",
              "              ('decoder.attention.attn.bias',\n",
              "               tensor([ 0.0875,  0.0321, -0.0981,  0.0497,  0.2906,  0.2325, -0.0161,  0.2043])),\n",
              "              ('decoder.embedding.weight',\n",
              "               tensor([[-0.0067,  0.0043,  0.0088,  ...,  0.0195,  0.0143,  0.0112],\n",
              "                       [-0.0008, -0.0072,  0.0083,  ..., -0.0087, -0.0013, -0.0027],\n",
              "                       [-0.5064,  0.5130, -0.7406,  ..., -0.5362, -0.5715, -0.5321],\n",
              "                       ...,\n",
              "                       [-0.0184,  0.0887,  0.0988,  ...,  0.0378,  0.1047,  0.0835],\n",
              "                       [-0.0855,  0.0139,  0.0457,  ...,  0.0396,  0.0605,  0.1373],\n",
              "                       [ 0.0604, -0.0379,  0.0182,  ...,  0.0156, -0.0071, -0.0318]])),\n",
              "              ('decoder.rnn.weight_ih_l0',\n",
              "               tensor([[ 1.7986e-01, -7.4060e-02, -6.1366e-02,  ...,  9.8834e-02,\n",
              "                         9.9977e-02, -2.6709e-02],\n",
              "                       [-7.4817e-02,  2.2377e-02, -3.0725e-02,  ..., -5.4908e-02,\n",
              "                         4.6672e-02, -1.7599e-01],\n",
              "                       [ 8.0354e-02,  4.9588e-01, -3.2395e-01,  ..., -1.2761e-01,\n",
              "                        -2.0803e-02, -1.0726e-02],\n",
              "                       ...,\n",
              "                       [ 1.0046e-02, -4.5818e-03, -2.5547e-01,  ...,  1.7539e-04,\n",
              "                        -3.9762e-02,  1.0159e-01],\n",
              "                       [-8.0930e-03,  3.2618e-01, -2.0730e-01,  ..., -2.6450e-02,\n",
              "                         2.8922e-02,  3.3904e-02],\n",
              "                       [ 8.9725e-02, -9.8316e-02,  1.0735e-01,  ..., -1.0722e-01,\n",
              "                        -1.0831e-01,  1.5301e-01]])),\n",
              "              ('decoder.rnn.weight_hh_l0',\n",
              "               tensor([[ 5.6969e-01, -1.4398e-01,  5.4746e-02,  ..., -1.5276e-01,\n",
              "                         2.7726e-03, -5.0864e-02],\n",
              "                       [ 2.0351e-01, -1.3692e-01,  3.8344e-01,  ...,  2.0366e-01,\n",
              "                         5.0553e-01, -2.2116e-01],\n",
              "                       [-5.1216e-06, -1.3476e-01, -6.2757e-02,  ..., -1.2862e-02,\n",
              "                        -1.1629e-01,  1.9711e-01],\n",
              "                       ...,\n",
              "                       [ 3.1109e-02,  2.6846e-01,  1.7483e-01,  ...,  2.2664e-01,\n",
              "                         1.7503e-01,  3.3872e-02],\n",
              "                       [-5.5717e-02,  1.4977e-01, -2.5969e-02,  ..., -1.4001e-02,\n",
              "                         1.8700e-01,  1.4469e-01],\n",
              "                       [ 7.1510e-02, -3.7978e-02, -1.5111e-01,  ..., -8.6505e-02,\n",
              "                         2.4474e-01,  1.6291e-01]])),\n",
              "              ('decoder.rnn.bias_ih_l0',\n",
              "               tensor([ 7.3011e-03,  1.4312e-01,  2.5902e-02,  1.4425e-01,  9.0774e-02,\n",
              "                       -8.0567e-03,  1.0458e-01, -3.9636e-02,  9.9682e-02,  1.6954e-01,\n",
              "                        1.3767e-01, -4.5157e-02,  1.2639e-01, -2.7593e-02, -1.1483e-02,\n",
              "                        1.2663e-01,  4.3737e-02, -2.1735e-02,  1.3721e-01,  1.0782e-01,\n",
              "                        9.8395e-02,  1.4221e-01,  1.5474e-01,  9.1728e-02,  1.6084e-01,\n",
              "                       -1.7255e-02,  1.2581e-01,  1.3131e-01,  1.1881e-01,  5.3884e-02,\n",
              "                        1.5728e-01,  1.5559e-01, -3.4305e-02,  1.3206e-01, -3.0450e-03,\n",
              "                        4.2245e-02,  6.1676e-03, -2.5536e-03,  7.6259e-02,  1.2478e-01,\n",
              "                        4.9258e-02,  5.0408e-03,  7.9893e-02,  2.2585e-01,  4.7320e-02,\n",
              "                        1.1116e-01,  1.0362e-01, -4.4990e-02, -4.7824e-02,  2.7219e-01,\n",
              "                        1.1098e-01,  6.4180e-02,  1.1000e-01, -3.9145e-03, -1.1698e-02,\n",
              "                        5.1047e-02,  1.0738e-01,  1.6560e-01,  9.6760e-02,  6.9623e-02,\n",
              "                        1.1458e-01,  1.8516e-02,  1.0254e-01, -2.2687e-02, -1.3190e-02,\n",
              "                       -1.0892e-01, -3.1941e-01, -3.8647e-01, -3.0036e-01, -3.7203e-02,\n",
              "                       -7.2985e-02, -3.3677e-01, -4.8259e-01, -1.4727e-01, -1.5996e-02,\n",
              "                        1.0160e-01, -2.2729e-01,  1.0396e-01, -3.1237e-02, -2.7499e-01,\n",
              "                       -3.1113e-01,  5.1360e-02, -7.1794e-02, -1.3137e-01, -2.6316e-01,\n",
              "                       -2.9990e-01,  1.6017e-04,  1.2461e-01,  2.3776e-02, -4.5490e-02,\n",
              "                       -1.8591e-01, -1.2392e-01, -1.0190e-01, -1.9609e-01,  1.3192e-01,\n",
              "                       -2.1114e-01, -3.5774e-01, -1.1748e-01, -3.4633e-01,  2.0148e-02,\n",
              "                       -3.5580e-01, -3.4958e-01, -4.5928e-03, -2.6675e-01, -4.0613e-02,\n",
              "                       -2.3494e-01, -8.5322e-02, -8.0835e-02,  4.7575e-02, -1.5104e-01,\n",
              "                       -1.1066e-01,  1.2792e-01, -3.7273e-01, -2.7957e-01,  1.2355e-02,\n",
              "                       -1.1690e-01, -1.6626e-01, -9.0662e-02,  1.0775e-01,  1.9121e-02,\n",
              "                       -9.7888e-02, -3.1585e-01, -1.2737e-01, -2.3524e-01, -1.7087e-01,\n",
              "                       -6.6931e-02, -1.0006e-01, -3.2207e-01, -6.2512e-02,  5.6864e-02,\n",
              "                       -1.3057e-01, -5.2584e-02,  4.8788e-03, -8.8899e-02, -8.9828e-02,\n",
              "                       -1.1038e-01, -7.3135e-02,  2.0329e-02,  5.2199e-02,  1.8795e-01,\n",
              "                        2.7088e-01,  1.1879e-01, -7.9451e-02, -1.1228e-01,  6.1815e-03,\n",
              "                       -9.9385e-02, -1.3076e-01,  1.0292e-01,  5.9279e-02, -3.0287e-02,\n",
              "                        1.4723e-02,  7.6670e-02, -2.9320e-02, -1.8096e-01, -5.1302e-02,\n",
              "                       -1.4328e-01,  2.5558e-03, -1.5113e-01,  4.5758e-02, -1.2341e-01,\n",
              "                        4.8080e-02, -5.0672e-02,  5.7532e-02, -1.2711e-02,  4.3395e-02,\n",
              "                        1.4865e-01, -5.8300e-02, -1.2112e-01, -1.4838e-01, -3.5009e-02,\n",
              "                        6.0581e-02,  8.9691e-02,  9.3968e-02,  1.0863e-01,  2.2173e-02,\n",
              "                       -1.9589e-01, -1.1133e-01,  1.1224e-01, -5.9517e-03,  4.9644e-02,\n",
              "                       -1.1418e-01,  2.8703e-02, -5.1913e-02,  4.1597e-03,  9.0671e-02,\n",
              "                        1.6109e-02, -8.2215e-03,  4.5815e-02,  1.0992e-01, -6.5017e-02,\n",
              "                        1.0666e-01, -8.6641e-02])),\n",
              "              ('decoder.rnn.bias_hh_l0',\n",
              "               tensor([ 7.3011e-03,  1.4312e-01,  2.5902e-02,  1.4425e-01,  9.0774e-02,\n",
              "                       -8.0567e-03,  1.0458e-01, -3.9636e-02,  9.9682e-02,  1.6954e-01,\n",
              "                        1.3767e-01, -4.5157e-02,  1.2639e-01, -2.7593e-02, -1.1483e-02,\n",
              "                        1.2663e-01,  4.3737e-02, -2.1735e-02,  1.3721e-01,  1.0782e-01,\n",
              "                        9.8395e-02,  1.4221e-01,  1.5474e-01,  9.1728e-02,  1.6084e-01,\n",
              "                       -1.7255e-02,  1.2581e-01,  1.3131e-01,  1.1881e-01,  5.3884e-02,\n",
              "                        1.5728e-01,  1.5559e-01, -3.4305e-02,  1.3206e-01, -3.0450e-03,\n",
              "                        4.2245e-02,  6.1676e-03, -2.5536e-03,  7.6259e-02,  1.2478e-01,\n",
              "                        4.9258e-02,  5.0408e-03,  7.9893e-02,  2.2585e-01,  4.7320e-02,\n",
              "                        1.1116e-01,  1.0362e-01, -4.4990e-02, -4.7824e-02,  2.7219e-01,\n",
              "                        1.1098e-01,  6.4180e-02,  1.1000e-01, -3.9145e-03, -1.1698e-02,\n",
              "                        5.1047e-02,  1.0738e-01,  1.6560e-01,  9.6760e-02,  6.9623e-02,\n",
              "                        1.1458e-01,  1.8516e-02,  1.0254e-01, -2.2687e-02, -1.3190e-02,\n",
              "                       -1.0892e-01, -3.1941e-01, -3.8647e-01, -3.0036e-01, -3.7203e-02,\n",
              "                       -7.2985e-02, -3.3677e-01, -4.8259e-01, -1.4727e-01, -1.5996e-02,\n",
              "                        1.0160e-01, -2.2729e-01,  1.0396e-01, -3.1237e-02, -2.7499e-01,\n",
              "                       -3.1113e-01,  5.1360e-02, -7.1794e-02, -1.3137e-01, -2.6316e-01,\n",
              "                       -2.9990e-01,  1.6017e-04,  1.2461e-01,  2.3776e-02, -4.5490e-02,\n",
              "                       -1.8591e-01, -1.2392e-01, -1.0190e-01, -1.9609e-01,  1.3192e-01,\n",
              "                       -2.1114e-01, -3.5774e-01, -1.1748e-01, -3.4633e-01,  2.0148e-02,\n",
              "                       -3.5580e-01, -3.4958e-01, -4.5928e-03, -2.6675e-01, -4.0613e-02,\n",
              "                       -2.3494e-01, -8.5322e-02, -8.0835e-02,  4.7575e-02, -1.5104e-01,\n",
              "                       -1.1066e-01,  1.2792e-01, -3.7273e-01, -2.7957e-01,  1.2355e-02,\n",
              "                       -1.1690e-01, -1.6626e-01, -9.0662e-02,  1.0775e-01,  1.9121e-02,\n",
              "                       -9.7888e-02, -3.1585e-01, -1.2737e-01, -2.3524e-01, -1.7087e-01,\n",
              "                       -6.6931e-02, -1.0006e-01, -3.2207e-01,  1.1731e-01,  2.0542e-01,\n",
              "                        2.8203e-01, -1.7044e-01, -4.4440e-02,  4.7477e-02, -9.7799e-02,\n",
              "                        1.1681e-01,  8.8301e-02, -1.6764e-01, -1.1070e-01, -1.0084e-01,\n",
              "                       -2.4142e-01, -1.5378e-01,  7.2238e-02, -1.2651e-01, -1.1151e-01,\n",
              "                        3.6979e-02, -9.3120e-02,  1.1066e-01, -2.0325e-01,  4.0858e-02,\n",
              "                        1.1452e-02,  8.4839e-02,  5.8773e-02,  7.9794e-02,  1.2922e-01,\n",
              "                       -1.4605e-01, -6.3174e-02, -1.2727e-01,  4.6793e-02, -1.3216e-01,\n",
              "                       -4.4785e-02,  3.2463e-02, -1.2015e-02, -4.9458e-02, -7.4903e-02,\n",
              "                       -4.2015e-02,  2.4398e-02, -1.4521e-01, -6.0600e-02,  6.6692e-02,\n",
              "                        7.6382e-02,  9.3098e-02, -1.1140e-01,  1.0251e-01,  5.6366e-02,\n",
              "                        4.8010e-02, -1.2347e-02,  1.3640e-01,  4.7335e-02, -1.7658e-02,\n",
              "                       -6.5276e-02,  3.2685e-02,  3.1070e-02, -3.8260e-02,  9.8691e-02,\n",
              "                        7.1985e-02,  6.2945e-02,  1.0513e-01,  1.1847e-01,  1.3498e-01,\n",
              "                        1.4903e-01,  1.6395e-01])),\n",
              "              ('decoder.out.weight',\n",
              "               tensor([[-0.1211, -0.2247, -0.1114,  ..., -0.0263,  0.0720,  0.1549],\n",
              "                       [-0.1404, -0.2327, -0.1217,  ..., -0.0258,  0.0703,  0.1391],\n",
              "                       [-0.1209, -0.2437, -0.1054,  ..., -0.0209,  0.0818,  0.1539],\n",
              "                       ...,\n",
              "                       [ 0.1099, -0.0185, -0.2234,  ..., -0.7766,  0.0695,  0.1808],\n",
              "                       [-0.0371, -0.0724, -0.1898,  ..., -0.2588,  0.0947,  0.1306],\n",
              "                       [-0.2512, -0.0628,  0.0667,  ...,  0.0570, -0.0240, -0.0769]])),\n",
              "              ('decoder.out.bias',\n",
              "               tensor([-0.0738, -0.0745, -0.0732,  ..., -0.0577, -0.0824, -0.0590]))]),\n",
              " 'optim_params': {'param_groups': [{'amsgrad': False,\n",
              "    'betas': (0.9, 0.999),\n",
              "    'eps': 1e-08,\n",
              "    'lr': 0.001,\n",
              "    'params': [0,\n",
              "     1,\n",
              "     2,\n",
              "     3,\n",
              "     4,\n",
              "     5,\n",
              "     6,\n",
              "     7,\n",
              "     8,\n",
              "     9,\n",
              "     10,\n",
              "     11,\n",
              "     12,\n",
              "     13,\n",
              "     14,\n",
              "     15,\n",
              "     16,\n",
              "     17,\n",
              "     18,\n",
              "     19],\n",
              "    'weight_decay': 0}],\n",
              "  'state': {0: {'exp_avg': tensor([[-1.5859e-03, -4.3050e-03, -3.4775e-03,  ..., -2.8476e-03,\n",
              "             -1.3587e-03,  2.5258e-03],\n",
              "            [-3.5178e-03,  7.4503e-04,  1.2793e-04,  ...,  6.3583e-03,\n",
              "             -1.2131e-02,  6.6081e-03],\n",
              "            [-4.5252e-03, -3.4630e-03, -4.2330e-04,  ..., -4.9811e-03,\n",
              "             -1.8303e-03,  6.7899e-03],\n",
              "            ...,\n",
              "            [-5.6052e-45, -2.1590e-19,  5.6052e-45,  ...,  5.6052e-45,\n",
              "              3.9724e-19, -1.8142e-19],\n",
              "            [ 1.8150e-13, -1.6669e-20,  2.1380e-20,  ...,  2.1021e-13,\n",
              "              1.1581e-13,  5.1060e-14],\n",
              "            [ 9.6396e-16,  2.2729e-21, -8.4198e-16,  ...,  5.6052e-45,\n",
              "             -1.7937e-19, -6.8738e-16]]),\n",
              "    'exp_avg_sq': tensor([[8.9709e-05, 8.3066e-05, 1.0938e-04,  ..., 8.3894e-05, 1.8658e-04,\n",
              "             1.0036e-04],\n",
              "            [3.4998e-04, 2.8866e-04, 1.2262e-04,  ..., 5.0025e-04, 1.7835e-03,\n",
              "             1.0281e-03],\n",
              "            [1.2267e-03, 2.9089e-04, 9.4923e-04,  ..., 3.7509e-04, 1.0833e-03,\n",
              "             9.3370e-04],\n",
              "            ...,\n",
              "            [8.0153e-09, 1.9788e-08, 1.5030e-09,  ..., 4.8499e-10, 7.0119e-08,\n",
              "             1.7411e-08],\n",
              "            [1.3602e-08, 3.5151e-09, 3.8281e-09,  ..., 1.8199e-08, 9.2781e-09,\n",
              "             2.6686e-08],\n",
              "            [1.8908e-08, 4.4811e-09, 1.4897e-08,  ..., 1.3085e-09, 1.9219e-08,\n",
              "             8.6724e-09]]),\n",
              "    'step': 5104},\n",
              "   1: {'exp_avg': tensor([[-4.6431e-06, -1.4805e-05,  2.1714e-05,  ..., -1.7395e-05,\n",
              "              1.0320e-05,  6.4444e-06],\n",
              "            [-1.5381e-05, -1.8632e-05, -7.9945e-06,  ...,  8.9283e-06,\n",
              "             -9.8558e-06,  3.3947e-05],\n",
              "            [ 2.8244e-06, -7.1039e-06,  1.1041e-05,  ...,  5.1387e-06,\n",
              "              9.0564e-06, -3.3790e-05],\n",
              "            ...,\n",
              "            [ 8.6427e-06, -1.4969e-05,  1.2872e-04,  ...,  2.7301e-05,\n",
              "              7.3907e-05, -1.7481e-05],\n",
              "            [ 2.0143e-04, -4.3111e-05,  1.7306e-05,  ..., -5.7099e-05,\n",
              "             -3.0488e-05,  3.3892e-05],\n",
              "            [-2.2298e-05, -8.4622e-05,  1.7186e-04,  ...,  1.2348e-04,\n",
              "              8.7009e-06,  1.6092e-04]]),\n",
              "    'exp_avg_sq': tensor([[1.9394e-09, 2.1545e-09, 2.7513e-09,  ..., 2.1546e-09, 1.5109e-09,\n",
              "             2.7125e-09],\n",
              "            [1.0533e-09, 1.5625e-09, 1.3840e-09,  ..., 1.4758e-09, 9.1423e-10,\n",
              "             1.2977e-09],\n",
              "            [1.0674e-09, 1.9053e-09, 1.5095e-09,  ..., 1.3353e-09, 8.7292e-10,\n",
              "             1.0294e-09],\n",
              "            ...,\n",
              "            [4.1373e-08, 1.2140e-07, 1.1446e-07,  ..., 7.4121e-08, 2.2519e-08,\n",
              "             3.3255e-08],\n",
              "            [1.4121e-07, 8.1129e-08, 1.3377e-07,  ..., 7.4946e-08, 9.5680e-08,\n",
              "             9.1065e-08],\n",
              "            [1.4457e-07, 2.3507e-07, 3.1214e-07,  ..., 1.8665e-07, 5.9367e-08,\n",
              "             8.3254e-08]]),\n",
              "    'step': 5104},\n",
              "   2: {'exp_avg': tensor([[ 9.8217e-05,  8.8467e-05,  4.3961e-05,  ...,  1.3588e-05,\n",
              "              3.5078e-05,  4.0966e-05],\n",
              "            [-2.4449e-05, -3.8026e-05,  2.2217e-05,  ..., -3.5477e-05,\n",
              "             -3.8872e-05, -1.6014e-06],\n",
              "            [-2.3931e-05, -3.4516e-05, -7.9927e-05,  ...,  4.4234e-05,\n",
              "             -7.1725e-05, -8.9238e-05],\n",
              "            ...,\n",
              "            [-3.9831e-05, -4.6283e-05,  8.3898e-05,  ..., -2.4451e-04,\n",
              "             -5.1904e-05, -4.0580e-04],\n",
              "            [ 3.2472e-06,  1.0534e-04,  1.4598e-04,  ...,  3.8607e-05,\n",
              "              1.8310e-04, -1.0381e-04],\n",
              "            [ 9.3299e-05,  1.0018e-04, -1.3078e-04,  ...,  2.7688e-05,\n",
              "              1.8364e-04, -1.3055e-04]]),\n",
              "    'exp_avg_sq': tensor([[6.8464e-08, 1.0929e-07, 5.3406e-08,  ..., 4.4009e-08, 3.6824e-08,\n",
              "             6.4492e-08],\n",
              "            [7.8441e-09, 1.2606e-08, 1.1123e-08,  ..., 1.1852e-08, 6.7625e-09,\n",
              "             1.3994e-08],\n",
              "            [2.5403e-08, 5.4719e-08, 5.1762e-08,  ..., 5.8800e-08, 1.6064e-08,\n",
              "             6.8471e-08],\n",
              "            ...,\n",
              "            [7.0082e-07, 1.3469e-06, 5.2763e-07,  ..., 3.9172e-07, 3.1511e-07,\n",
              "             5.5181e-07],\n",
              "            [5.3825e-07, 1.0551e-06, 4.6790e-07,  ..., 4.6031e-07, 3.3837e-07,\n",
              "             4.3117e-07],\n",
              "            [1.0054e-06, 2.0890e-06, 1.0349e-06,  ..., 7.7056e-07, 3.0884e-07,\n",
              "             6.8232e-07]]),\n",
              "    'step': 5104},\n",
              "   3: {'exp_avg': tensor([ 6.1931e-05, -2.3221e-05, -4.6943e-05,  8.6061e-05, -1.1249e-04,\n",
              "            -6.1921e-05, -8.5151e-05, -5.5560e-05, -1.7019e-04, -1.2287e-05,\n",
              "            -6.3339e-05,  1.9224e-04,  3.6841e-04, -5.7421e-05,  3.2169e-05,\n",
              "            -1.1447e-04,  2.3268e-04,  2.4289e-04,  3.9130e-04,  1.5297e-04,\n",
              "            -3.5327e-05,  4.7481e-05, -8.8237e-05, -2.8383e-05,  3.4396e-04,\n",
              "             5.7937e-05,  1.7611e-04, -5.6797e-05, -5.0570e-05, -3.7005e-05,\n",
              "            -1.4490e-04,  4.7379e-05, -1.9923e-04,  6.7370e-06, -1.2112e-04,\n",
              "             1.5640e-05, -1.0270e-04, -3.3768e-05,  2.2892e-04,  1.3564e-04,\n",
              "            -1.5104e-04,  5.9434e-06,  1.0265e-04,  2.6656e-05, -6.0826e-05,\n",
              "            -6.8030e-05,  9.8097e-05, -9.0707e-05, -8.4693e-05,  3.0235e-04,\n",
              "            -8.7342e-06, -1.1340e-05,  3.4764e-05, -1.2981e-04,  1.2863e-05,\n",
              "             1.0241e-04,  5.1663e-05,  3.8290e-04,  3.7294e-05, -2.2555e-04,\n",
              "             3.2782e-05, -1.4618e-04,  3.2844e-05, -3.6738e-05,  1.4102e-04,\n",
              "             1.8876e-04,  1.8964e-05, -4.4548e-05, -1.3784e-05,  2.1066e-05,\n",
              "             1.8637e-04,  2.9912e-04, -1.6842e-04,  5.4945e-05, -7.0446e-05,\n",
              "            -2.8849e-04, -1.0616e-04,  3.2677e-05,  1.8786e-04,  8.2047e-05,\n",
              "             2.8972e-04,  2.1565e-04, -4.7571e-05, -9.6496e-05, -6.3498e-06,\n",
              "            -6.9304e-06, -2.5324e-04,  2.2366e-05,  4.3161e-04, -8.9267e-05,\n",
              "             2.2974e-04,  3.3705e-04,  2.9331e-04,  1.6112e-04,  1.0785e-04,\n",
              "            -2.4747e-05,  4.1281e-04,  6.5477e-05,  6.8693e-05, -4.4448e-05,\n",
              "             2.1333e-04,  2.2853e-04, -6.0948e-05, -1.0925e-04,  9.3133e-05,\n",
              "             3.7916e-05, -1.8911e-04,  5.7995e-04,  1.3818e-04,  4.7581e-05,\n",
              "            -2.0290e-04, -5.7817e-04,  2.5485e-04,  8.5414e-05,  2.8671e-05,\n",
              "             7.6953e-05,  4.6978e-04, -6.6186e-05,  1.6878e-04, -9.3710e-05,\n",
              "            -1.8031e-04, -7.8694e-05, -3.1889e-04,  1.2840e-04, -1.2397e-04,\n",
              "             9.3157e-05,  2.1797e-04,  3.1073e-05,  2.5548e-04, -4.0044e-04,\n",
              "            -4.8160e-04, -9.5490e-04,  1.6220e-04, -1.1309e-03,  7.4665e-04,\n",
              "            -7.5897e-04, -5.6043e-04, -5.8061e-04, -3.4809e-04,  2.2063e-04,\n",
              "             1.7683e-03, -2.9368e-04, -1.2311e-03, -1.4292e-05,  1.3234e-03,\n",
              "             1.3667e-03,  1.6916e-04, -7.0596e-04,  1.0531e-03,  8.8961e-04,\n",
              "             3.0366e-04, -4.9882e-04, -5.5754e-04, -1.9857e-04, -1.2081e-03,\n",
              "             1.7029e-03,  1.4271e-03, -4.4292e-04,  4.3815e-04,  1.0983e-03,\n",
              "             1.2026e-04, -5.8684e-05, -1.9250e-03,  4.8373e-05,  4.6568e-04,\n",
              "             4.2670e-04,  3.1163e-04,  6.9930e-04, -2.4250e-06, -9.2719e-04,\n",
              "             9.1104e-04, -6.1185e-04,  5.8951e-04,  6.3323e-04,  2.3891e-04,\n",
              "            -1.2398e-03,  1.4522e-03,  5.7542e-04, -1.7475e-04, -1.1396e-03,\n",
              "            -1.9325e-04,  9.8119e-04, -2.0645e-04,  2.3370e-03,  1.3577e-03,\n",
              "            -2.2154e-03,  2.1048e-04,  4.9389e-04,  1.6347e-03,  1.0125e-03,\n",
              "             7.3047e-04,  8.3958e-04]),\n",
              "    'exp_avg_sq': tensor([3.2128e-07, 6.9156e-08, 2.8435e-07, 3.2957e-07, 1.1390e-07, 1.9363e-07,\n",
              "            6.1836e-07, 2.4752e-07, 6.6815e-07, 7.7454e-08, 2.7635e-07, 3.2592e-07,\n",
              "            5.4844e-07, 2.2776e-07, 1.7872e-07, 7.7098e-08, 3.4964e-07, 3.7956e-07,\n",
              "            5.6513e-07, 2.5982e-07, 7.3029e-08, 2.4003e-07, 1.3888e-07, 7.7882e-08,\n",
              "            2.1801e-07, 2.0289e-07, 6.7602e-07, 2.1384e-07, 1.8598e-07, 7.6785e-08,\n",
              "            9.3065e-08, 2.4428e-07, 1.3123e-07, 5.6115e-08, 2.1060e-07, 2.7214e-07,\n",
              "            1.2631e-07, 5.6054e-08, 1.0321e-07, 9.6980e-08, 1.1534e-07, 1.3041e-07,\n",
              "            2.0846e-07, 1.4179e-07, 1.4009e-07, 1.9966e-07, 1.5127e-07, 1.9658e-07,\n",
              "            1.2680e-07, 2.7633e-07, 1.8753e-07, 9.6905e-08, 1.7867e-07, 3.4297e-07,\n",
              "            1.4124e-07, 8.4493e-07, 1.5238e-07, 3.6753e-07, 4.4311e-07, 1.9538e-07,\n",
              "            5.8478e-07, 2.0727e-07, 1.6050e-07, 1.0668e-07, 2.1695e-07, 2.4123e-07,\n",
              "            2.0671e-07, 2.1917e-07, 9.9056e-08, 1.2806e-07, 4.2139e-07, 2.6869e-07,\n",
              "            3.4199e-07, 5.1781e-07, 1.0020e-07, 1.4875e-07, 4.3787e-07, 3.4283e-07,\n",
              "            1.9909e-07, 1.5542e-07, 3.8363e-07, 5.6720e-07, 7.8564e-07, 1.5629e-07,\n",
              "            9.8009e-08, 2.3049e-07, 2.0085e-07, 1.8826e-07, 4.3190e-07, 1.7432e-07,\n",
              "            4.0179e-07, 2.0702e-07, 1.5809e-07, 2.0270e-07, 1.6519e-07, 1.6649e-07,\n",
              "            1.9681e-07, 1.9299e-07, 1.0481e-07, 2.9235e-07, 1.3839e-07, 2.1386e-07,\n",
              "            3.7225e-07, 3.6743e-07, 1.7223e-07, 5.6904e-07, 6.8407e-07, 4.1508e-07,\n",
              "            2.6988e-07, 1.1910e-07, 2.7039e-07, 4.3265e-07, 1.3305e-07, 2.4219e-07,\n",
              "            1.2030e-07, 2.0004e-07, 7.0352e-07, 1.5187e-07, 2.3040e-07, 8.9744e-07,\n",
              "            2.7915e-06, 2.2276e-07, 8.1485e-07, 1.2596e-07, 8.1984e-07, 2.7372e-07,\n",
              "            2.1654e-07, 2.8646e-06, 3.9486e-05, 9.5979e-06, 3.0631e-05, 3.8512e-05,\n",
              "            1.8735e-05, 2.9334e-05, 6.0660e-05, 4.4588e-05, 2.8336e-05, 2.8718e-05,\n",
              "            2.1290e-05, 2.5698e-05, 5.2696e-05, 2.9864e-05, 5.0612e-05, 1.8225e-05,\n",
              "            3.8335e-05, 3.3871e-05, 5.0547e-05, 3.2535e-05, 2.2928e-05, 5.1298e-05,\n",
              "            2.1619e-05, 1.9870e-05, 2.2250e-05, 3.5370e-05, 3.9698e-05, 3.5816e-05,\n",
              "            3.9915e-05, 3.5788e-05, 2.4355e-05, 3.3039e-05, 1.8105e-05, 1.7617e-05,\n",
              "            3.2086e-05, 5.3086e-05, 3.3593e-05, 2.4412e-05, 3.8299e-05, 3.8067e-05,\n",
              "            1.5505e-05, 6.5119e-05, 3.1217e-05, 2.7230e-05, 2.6210e-05, 2.5898e-05,\n",
              "            1.7583e-05, 3.3072e-05, 3.6560e-05, 3.1219e-05, 2.7103e-05, 2.5992e-05,\n",
              "            3.6964e-05, 3.9243e-05, 2.5004e-05, 5.8416e-05, 6.9430e-05, 4.9766e-05,\n",
              "            2.4333e-05, 2.3951e-05, 3.2319e-05, 4.2137e-05, 3.5593e-05, 5.8811e-05]),\n",
              "    'step': 5104},\n",
              "   4: {'exp_avg': tensor([ 6.1931e-05, -2.3221e-05, -4.6943e-05,  8.6061e-05, -1.1249e-04,\n",
              "            -6.1921e-05, -8.5151e-05, -5.5560e-05, -1.7019e-04, -1.2287e-05,\n",
              "            -6.3338e-05,  1.9224e-04,  3.6841e-04, -5.7421e-05,  3.2169e-05,\n",
              "            -1.1447e-04,  2.3268e-04,  2.4289e-04,  3.9130e-04,  1.5297e-04,\n",
              "            -3.5327e-05,  4.7481e-05, -8.8237e-05, -2.8383e-05,  3.4396e-04,\n",
              "             5.7937e-05,  1.7611e-04, -5.6797e-05, -5.0570e-05, -3.7005e-05,\n",
              "            -1.4490e-04,  4.7379e-05, -1.9923e-04,  6.7370e-06, -1.2112e-04,\n",
              "             1.5640e-05, -1.0270e-04, -3.3768e-05,  2.2892e-04,  1.3564e-04,\n",
              "            -1.5104e-04,  5.9434e-06,  1.0265e-04,  2.6656e-05, -6.0827e-05,\n",
              "            -6.8030e-05,  9.8097e-05, -9.0707e-05, -8.4693e-05,  3.0235e-04,\n",
              "            -8.7342e-06, -1.1340e-05,  3.4764e-05, -1.2981e-04,  1.2863e-05,\n",
              "             1.0241e-04,  5.1663e-05,  3.8290e-04,  3.7294e-05, -2.2555e-04,\n",
              "             3.2782e-05, -1.4618e-04,  3.2844e-05, -3.6738e-05,  1.4102e-04,\n",
              "             1.8876e-04,  1.8964e-05, -4.4548e-05, -1.3784e-05,  2.1066e-05,\n",
              "             1.8637e-04,  2.9912e-04, -1.6842e-04,  5.4945e-05, -7.0446e-05,\n",
              "            -2.8849e-04, -1.0616e-04,  3.2677e-05,  1.8786e-04,  8.2047e-05,\n",
              "             2.8972e-04,  2.1565e-04, -4.7571e-05, -9.6496e-05, -6.3498e-06,\n",
              "            -6.9305e-06, -2.5324e-04,  2.2366e-05,  4.3161e-04, -8.9267e-05,\n",
              "             2.2974e-04,  3.3705e-04,  2.9331e-04,  1.6112e-04,  1.0785e-04,\n",
              "            -2.4747e-05,  4.1281e-04,  6.5477e-05,  6.8693e-05, -4.4448e-05,\n",
              "             2.1333e-04,  2.2853e-04, -6.0948e-05, -1.0925e-04,  9.3133e-05,\n",
              "             3.7916e-05, -1.8911e-04,  5.7995e-04,  1.3818e-04,  4.7581e-05,\n",
              "            -2.0290e-04, -5.7817e-04,  2.5485e-04,  8.5414e-05,  2.8671e-05,\n",
              "             7.6953e-05,  4.6978e-04, -6.6186e-05,  1.6878e-04, -9.3710e-05,\n",
              "            -1.8031e-04, -7.8694e-05, -3.1889e-04,  1.2840e-04, -1.2397e-04,\n",
              "             9.3157e-05,  2.1797e-04,  3.1073e-05,  2.6963e-04, -4.5759e-04,\n",
              "            -1.3828e-04, -6.4559e-04,  6.2932e-06, -4.6950e-04,  9.5436e-04,\n",
              "            -1.8827e-04, -1.0321e-04, -2.9658e-04, -3.7094e-04,  8.6401e-05,\n",
              "             6.6508e-04, -2.0589e-04, -5.4724e-04,  4.3305e-05,  7.7786e-04,\n",
              "             4.1992e-04,  2.5087e-04, -4.3958e-05,  6.6574e-04,  3.3735e-04,\n",
              "             2.3144e-04, -9.2686e-05, -5.1344e-04,  1.6074e-04, -4.5220e-04,\n",
              "             4.0508e-04,  5.9810e-04,  1.5921e-04,  2.9584e-04,  3.3272e-04,\n",
              "             3.8463e-06, -1.5968e-04, -9.4871e-04,  1.2748e-04,  3.8202e-04,\n",
              "             3.9909e-04,  5.7966e-05,  4.4357e-04,  2.8548e-05, -3.4330e-04,\n",
              "             2.3658e-04, -1.7187e-04,  2.3158e-04,  3.2020e-04,  3.3031e-04,\n",
              "            -9.0308e-04,  7.5171e-04,  6.8509e-04, -1.1481e-04, -3.9542e-04,\n",
              "             1.2590e-04,  5.8175e-04, -1.0144e-04,  7.5900e-04,  3.7693e-04,\n",
              "            -9.3725e-04,  9.5336e-05, -1.3076e-05,  1.1562e-03,  3.8092e-04,\n",
              "             4.8794e-04,  7.0812e-05]),\n",
              "    'exp_avg_sq': tensor([3.2128e-07, 6.9156e-08, 2.8435e-07, 3.2957e-07, 1.1390e-07, 1.9363e-07,\n",
              "            6.1836e-07, 2.4752e-07, 6.6815e-07, 7.7454e-08, 2.7635e-07, 3.2592e-07,\n",
              "            5.4844e-07, 2.2776e-07, 1.7872e-07, 7.7098e-08, 3.4964e-07, 3.7956e-07,\n",
              "            5.6513e-07, 2.5982e-07, 7.3029e-08, 2.4003e-07, 1.3888e-07, 7.7882e-08,\n",
              "            2.1801e-07, 2.0289e-07, 6.7602e-07, 2.1384e-07, 1.8598e-07, 7.6785e-08,\n",
              "            9.3065e-08, 2.4428e-07, 1.3123e-07, 5.6115e-08, 2.1060e-07, 2.7214e-07,\n",
              "            1.2631e-07, 5.6054e-08, 1.0321e-07, 9.6980e-08, 1.1534e-07, 1.3041e-07,\n",
              "            2.0846e-07, 1.4179e-07, 1.4009e-07, 1.9966e-07, 1.5127e-07, 1.9658e-07,\n",
              "            1.2680e-07, 2.7633e-07, 1.8753e-07, 9.6905e-08, 1.7867e-07, 3.4297e-07,\n",
              "            1.4124e-07, 8.4493e-07, 1.5238e-07, 3.6753e-07, 4.4311e-07, 1.9538e-07,\n",
              "            5.8478e-07, 2.0727e-07, 1.6050e-07, 1.0668e-07, 2.1695e-07, 2.4123e-07,\n",
              "            2.0671e-07, 2.1917e-07, 9.9056e-08, 1.2806e-07, 4.2139e-07, 2.6869e-07,\n",
              "            3.4199e-07, 5.1781e-07, 1.0020e-07, 1.4875e-07, 4.3787e-07, 3.4283e-07,\n",
              "            1.9909e-07, 1.5542e-07, 3.8363e-07, 5.6720e-07, 7.8564e-07, 1.5629e-07,\n",
              "            9.8009e-08, 2.3049e-07, 2.0085e-07, 1.8826e-07, 4.3190e-07, 1.7432e-07,\n",
              "            4.0179e-07, 2.0702e-07, 1.5809e-07, 2.0270e-07, 1.6519e-07, 1.6649e-07,\n",
              "            1.9681e-07, 1.9299e-07, 1.0481e-07, 2.9235e-07, 1.3839e-07, 2.1386e-07,\n",
              "            3.7225e-07, 3.6743e-07, 1.7223e-07, 5.6904e-07, 6.8407e-07, 4.1508e-07,\n",
              "            2.6988e-07, 1.1910e-07, 2.7039e-07, 4.3265e-07, 1.3305e-07, 2.4219e-07,\n",
              "            1.2030e-07, 2.0004e-07, 7.0352e-07, 1.5187e-07, 2.3040e-07, 8.9744e-07,\n",
              "            2.7915e-06, 2.2276e-07, 8.1485e-07, 1.2596e-07, 8.1984e-07, 2.7372e-07,\n",
              "            2.1654e-07, 2.8646e-06, 1.2857e-05, 4.4078e-06, 7.4553e-06, 1.3469e-05,\n",
              "            5.4434e-06, 7.4896e-06, 1.5358e-05, 1.2333e-05, 8.6246e-06, 9.5592e-06,\n",
              "            6.6647e-06, 8.6683e-06, 1.9500e-05, 1.0960e-05, 1.6060e-05, 5.5197e-06,\n",
              "            1.4081e-05, 1.2545e-05, 1.4599e-05, 8.7313e-06, 6.1574e-06, 8.9801e-06,\n",
              "            6.5309e-06, 5.5140e-06, 6.3377e-06, 1.0337e-05, 1.0595e-05, 8.2468e-06,\n",
              "            1.2072e-05, 1.0006e-05, 8.5854e-06, 8.6864e-06, 4.9299e-06, 6.8682e-06,\n",
              "            9.2508e-06, 1.4504e-05, 9.5484e-06, 8.5349e-06, 1.1180e-05, 1.0587e-05,\n",
              "            5.1722e-06, 1.7058e-05, 1.3068e-05, 7.3193e-06, 7.3342e-06, 7.0120e-06,\n",
              "            8.1873e-06, 1.2235e-05, 1.0848e-05, 1.1121e-05, 8.0687e-06, 7.7742e-06,\n",
              "            1.0806e-05, 1.1756e-05, 7.4594e-06, 1.5174e-05, 1.8510e-05, 1.3320e-05,\n",
              "            1.0265e-05, 6.7360e-06, 1.3681e-05, 1.0657e-05, 1.0167e-05, 1.7057e-05]),\n",
              "    'step': 5104},\n",
              "   5: {'exp_avg': tensor([[-1.7171e-05, -8.6827e-06,  3.1927e-05,  ..., -1.1338e-05,\n",
              "              5.6659e-06, -2.5056e-05],\n",
              "            [-3.1431e-05, -3.6033e-05, -1.1861e-05,  ..., -1.5642e-05,\n",
              "             -4.0097e-05,  1.0822e-05],\n",
              "            [-1.3472e-05, -3.5907e-05,  2.2150e-05,  ..., -1.7783e-05,\n",
              "             -1.2709e-05,  9.8918e-07],\n",
              "            ...,\n",
              "            [ 1.5556e-05, -2.8919e-05, -2.8925e-05,  ..., -2.3596e-05,\n",
              "             -7.6113e-05, -1.1440e-04],\n",
              "            [-4.5235e-06, -1.1698e-04,  2.1354e-04,  ..., -1.8916e-05,\n",
              "             -1.1658e-04,  6.1828e-05],\n",
              "            [ 1.9527e-04,  8.2646e-05,  2.1278e-05,  ..., -5.3792e-05,\n",
              "              6.2617e-05, -1.3297e-04]]),\n",
              "    'exp_avg_sq': tensor([[3.5139e-09, 3.2033e-09, 5.5049e-09,  ..., 2.4395e-09, 1.3261e-09,\n",
              "             1.7341e-09],\n",
              "            [1.6238e-09, 3.3235e-09, 1.4561e-09,  ..., 3.2418e-09, 7.4778e-09,\n",
              "             5.9901e-09],\n",
              "            [4.2948e-09, 6.6002e-09, 3.2470e-09,  ..., 8.0216e-09, 5.1267e-09,\n",
              "             5.6664e-09],\n",
              "            ...,\n",
              "            [5.2584e-08, 2.5051e-07, 8.6323e-08,  ..., 2.8245e-07, 2.3065e-07,\n",
              "             2.3921e-07],\n",
              "            [2.2757e-07, 5.6919e-08, 2.4830e-07,  ..., 3.6749e-08, 6.6689e-08,\n",
              "             3.7084e-08],\n",
              "            [4.0224e-07, 7.1305e-08, 1.9845e-07,  ..., 4.9395e-08, 1.3934e-07,\n",
              "             1.1629e-07]]),\n",
              "    'step': 5104},\n",
              "   6: {'exp_avg': tensor([[-3.6939e-05,  6.1336e-05, -5.0204e-05,  ...,  8.3617e-05,\n",
              "             -7.5693e-05, -9.4077e-07],\n",
              "            [ 5.1679e-05,  2.8031e-04,  2.7858e-04,  ..., -6.6400e-05,\n",
              "             -2.2966e-04,  2.1113e-04],\n",
              "            [-1.7870e-05, -3.2564e-05, -4.6508e-05,  ...,  2.3485e-05,\n",
              "              5.5122e-05, -9.4196e-05],\n",
              "            ...,\n",
              "            [-4.8744e-04,  1.6089e-05, -5.7063e-04,  ...,  5.5729e-04,\n",
              "             -5.5367e-04,  4.8572e-04],\n",
              "            [-1.2117e-04, -2.7811e-06, -2.7612e-05,  ...,  2.0677e-04,\n",
              "              5.5505e-05,  1.7654e-04],\n",
              "            [ 1.8247e-05, -1.8798e-04,  1.4069e-06,  ..., -2.2970e-04,\n",
              "             -2.5307e-04,  6.5870e-05]]),\n",
              "    'exp_avg_sq': tensor([[8.0952e-08, 1.0469e-07, 1.3041e-07,  ..., 1.0245e-07, 9.4665e-08,\n",
              "             7.6387e-08],\n",
              "            [3.2551e-07, 1.8897e-07, 5.5199e-07,  ..., 2.4980e-07, 1.7331e-07,\n",
              "             1.5382e-07],\n",
              "            [1.1499e-07, 8.9331e-08, 1.5899e-07,  ..., 6.4762e-08, 1.7525e-07,\n",
              "             1.3932e-07],\n",
              "            ...,\n",
              "            [9.8922e-07, 4.3358e-07, 1.4890e-06,  ..., 1.0530e-06, 8.9537e-07,\n",
              "             6.4650e-07],\n",
              "            [6.4082e-07, 5.9365e-07, 6.5126e-07,  ..., 4.3537e-07, 4.0392e-07,\n",
              "             5.2260e-07],\n",
              "            [8.5687e-07, 5.5962e-07, 8.0493e-07,  ..., 6.2215e-07, 5.6585e-07,\n",
              "             3.8332e-07]]),\n",
              "    'step': 5104},\n",
              "   7: {'exp_avg': tensor([-3.3091e-05, -6.0233e-05,  9.8441e-07, -1.6005e-04, -3.6859e-04,\n",
              "            -6.5145e-05, -1.6268e-04, -6.8275e-06,  2.1633e-06, -9.6069e-05,\n",
              "            -1.1918e-04, -1.4738e-04, -1.1639e-04,  1.6272e-04,  2.5054e-05,\n",
              "             1.6793e-04,  1.7614e-04, -2.1590e-05,  1.3634e-05,  6.5502e-04,\n",
              "             7.0247e-05,  1.1935e-04, -5.8606e-05,  1.4559e-04,  3.0860e-04,\n",
              "             2.8645e-04, -8.3547e-05,  4.9916e-05, -2.1029e-05, -1.5377e-04,\n",
              "             5.4765e-04,  1.8371e-06, -1.2995e-05, -5.3301e-06,  4.9111e-06,\n",
              "            -3.0661e-04,  5.1972e-04,  2.7507e-04,  6.1374e-05, -1.9569e-04,\n",
              "            -5.8419e-05, -3.2114e-04,  7.6520e-04,  8.8323e-05,  1.4753e-04,\n",
              "            -2.5031e-04, -5.2705e-05, -9.5036e-05,  1.1374e-04, -2.5280e-04,\n",
              "             6.2904e-05,  3.8775e-05,  1.5268e-04,  8.8382e-05,  3.0071e-04,\n",
              "             1.4354e-04, -4.4815e-05, -2.7548e-05, -1.0800e-04, -5.0902e-05,\n",
              "             1.0120e-04,  3.3386e-04, -3.3747e-05, -1.0917e-04,  4.1160e-05,\n",
              "            -9.3350e-05, -1.1728e-04,  2.1717e-04,  2.8394e-04,  5.6486e-04,\n",
              "             3.4768e-05,  5.0341e-04, -3.3468e-05, -2.5436e-04,  1.0861e-04,\n",
              "            -5.9475e-04,  5.8719e-06,  1.8306e-04, -3.1928e-04,  1.2430e-06,\n",
              "            -3.0542e-04, -2.6256e-04,  1.0950e-04,  5.3870e-04,  7.9599e-05,\n",
              "             2.3410e-04,  1.5671e-05,  2.2514e-05, -3.0767e-04, -2.3996e-04,\n",
              "            -6.2705e-05,  5.7333e-05, -5.0227e-05, -1.6349e-04,  2.2162e-03,\n",
              "             1.7189e-04, -1.0722e-04, -1.7074e-04,  1.0622e-04,  6.8502e-05,\n",
              "             1.5971e-03,  4.8965e-05, -2.8403e-04,  1.2517e-04,  1.6495e-04,\n",
              "             7.1926e-05,  5.5999e-05,  3.4300e-04,  8.8687e-04,  2.1835e-04,\n",
              "             2.8274e-04, -1.4863e-04, -1.6411e-04, -5.8496e-05, -9.2679e-05,\n",
              "             6.2800e-05,  3.9273e-04, -3.6388e-06,  3.7738e-04,  5.2655e-04,\n",
              "            -4.2675e-04,  7.3117e-05,  1.0610e-04,  1.2376e-04, -1.7915e-04,\n",
              "            -2.9582e-04,  1.6820e-04,  2.4443e-04, -9.0609e-04,  3.5604e-03,\n",
              "             4.5991e-05,  3.1816e-03, -6.2048e-04, -9.9915e-04, -4.7875e-04,\n",
              "             1.9472e-03,  3.7193e-04,  4.2345e-04, -6.1433e-04,  3.4317e-04,\n",
              "            -5.0439e-04, -1.4922e-04, -1.4086e-03,  2.6418e-04, -1.7728e-03,\n",
              "            -4.5824e-04,  1.6345e-03,  2.0955e-03,  4.9110e-04,  8.9929e-04,\n",
              "            -6.2026e-04,  3.8500e-05,  1.2472e-03,  9.8011e-05,  1.6706e-03,\n",
              "            -4.0162e-04,  1.6031e-03, -7.8114e-04, -3.0196e-03, -5.1101e-04,\n",
              "            -1.4528e-04,  9.8683e-05, -4.4155e-04,  3.2030e-04,  1.0785e-03,\n",
              "            -1.0788e-03,  1.1097e-03, -1.7839e-03, -3.6244e-05, -7.9335e-04,\n",
              "            -2.7838e-03,  8.3583e-04,  1.6347e-03,  1.2417e-03,  4.5131e-04,\n",
              "            -1.2578e-03,  3.4148e-05,  2.1878e-03, -4.4794e-04,  4.4547e-06,\n",
              "            -8.3040e-04, -3.6338e-04,  4.4909e-04, -2.7308e-03,  1.1732e-03,\n",
              "             2.6537e-03, -1.8947e-03, -7.6303e-04,  9.6798e-04,  5.2652e-04,\n",
              "            -6.4331e-04,  2.6336e-03]),\n",
              "    'exp_avg_sq': tensor([1.8145e-07, 6.9585e-07, 3.8261e-07, 1.1621e-06, 5.0707e-07, 9.0524e-07,\n",
              "            2.6465e-07, 8.7968e-07, 5.6819e-07, 5.4722e-07, 4.4432e-07, 1.9381e-07,\n",
              "            1.6497e-07, 2.1779e-07, 7.3071e-07, 2.1000e-07, 2.9995e-07, 4.9627e-07,\n",
              "            7.8724e-07, 7.6714e-06, 3.8247e-07, 9.8877e-07, 3.1012e-07, 5.6443e-07,\n",
              "            1.7298e-06, 2.0669e-07, 1.5181e-07, 1.0078e-07, 1.1959e-07, 5.8735e-07,\n",
              "            9.1414e-07, 6.5452e-07, 1.9991e-07, 5.1399e-07, 4.8134e-07, 4.0381e-07,\n",
              "            2.4010e-06, 4.2428e-07, 3.3011e-07, 7.9709e-07, 3.8509e-07, 4.2892e-07,\n",
              "            1.9349e-06, 2.4885e-07, 7.6303e-07, 7.3469e-07, 1.6420e-07, 5.2452e-07,\n",
              "            1.4614e-07, 4.4871e-07, 7.1546e-07, 1.4480e-07, 3.6502e-07, 3.5366e-07,\n",
              "            3.7459e-07, 1.2198e-06, 8.4588e-07, 1.1986e-07, 6.3244e-07, 1.5711e-07,\n",
              "            2.7348e-07, 4.6378e-07, 9.0280e-08, 2.7352e-07, 2.9998e-07, 3.7004e-07,\n",
              "            5.2552e-07, 3.0442e-07, 3.9802e-07, 1.2707e-06, 7.4620e-07, 3.9196e-07,\n",
              "            3.2813e-07, 8.9320e-07, 6.8067e-07, 7.1447e-07, 6.4189e-07, 3.6715e-07,\n",
              "            1.9921e-06, 3.1077e-07, 3.4192e-07, 3.2619e-07, 4.9978e-07, 1.8180e-06,\n",
              "            3.0414e-07, 3.5855e-07, 2.7477e-07, 2.6654e-07, 1.1590e-06, 6.8204e-07,\n",
              "            5.2785e-07, 2.6722e-07, 2.6245e-07, 4.2604e-07, 5.4066e-05, 4.6476e-07,\n",
              "            6.8762e-07, 3.2113e-07, 3.0519e-07, 7.6296e-07, 4.8461e-05, 9.1881e-07,\n",
              "            4.5683e-07, 7.6888e-07, 1.8976e-07, 8.2849e-07, 2.6006e-07, 7.1936e-07,\n",
              "            1.0746e-05, 9.2834e-07, 3.5545e-07, 7.7571e-07, 4.0049e-07, 7.5779e-07,\n",
              "            2.6462e-07, 5.7793e-07, 1.2383e-06, 1.8032e-07, 5.8924e-06, 4.3076e-06,\n",
              "            5.8939e-07, 5.1862e-07, 4.8775e-07, 2.8935e-07, 1.5924e-06, 7.9223e-07,\n",
              "            1.9707e-07, 2.6028e-07, 9.4181e-06, 5.2472e-05, 1.7260e-05, 8.3384e-05,\n",
              "            5.8184e-05, 4.7934e-05, 1.8643e-05, 6.6030e-05, 2.5310e-05, 9.4917e-06,\n",
              "            1.8737e-05, 1.3611e-05, 7.7860e-06, 4.8208e-05, 4.0080e-05, 1.2315e-05,\n",
              "            2.7628e-05, 2.6196e-05, 1.9861e-05, 1.0431e-04, 1.3897e-05, 1.1915e-05,\n",
              "            1.7683e-05, 3.0506e-05, 1.2114e-04, 6.7328e-06, 1.7216e-05, 9.9848e-06,\n",
              "            2.4164e-05, 7.3986e-05, 4.1712e-05, 1.2735e-05, 1.1626e-05, 2.2794e-05,\n",
              "            8.9113e-06, 1.2919e-05, 5.9097e-05, 1.8696e-05, 1.3937e-05, 2.3047e-05,\n",
              "            1.9463e-05, 1.2805e-05, 8.4644e-05, 1.6033e-05, 8.7354e-05, 3.3086e-05,\n",
              "            1.5479e-05, 2.6167e-05, 6.6929e-06, 2.3798e-05, 2.1465e-05, 4.0010e-06,\n",
              "            2.5115e-05, 3.2170e-05, 4.0560e-05, 1.0550e-04, 2.5559e-05, 4.6688e-05,\n",
              "            4.9723e-05, 1.2198e-05, 1.6922e-05, 2.4911e-05, 2.4102e-05, 6.5139e-05]),\n",
              "    'step': 5104},\n",
              "   8: {'exp_avg': tensor([-3.3091e-05, -6.0233e-05,  9.8440e-07, -1.6005e-04, -3.6859e-04,\n",
              "            -6.5145e-05, -1.6268e-04, -6.8276e-06,  2.1633e-06, -9.6069e-05,\n",
              "            -1.1918e-04, -1.4738e-04, -1.1639e-04,  1.6272e-04,  2.5054e-05,\n",
              "             1.6793e-04,  1.7614e-04, -2.1590e-05,  1.3634e-05,  6.5502e-04,\n",
              "             7.0246e-05,  1.1935e-04, -5.8606e-05,  1.4559e-04,  3.0860e-04,\n",
              "             2.8645e-04, -8.3547e-05,  4.9916e-05, -2.1029e-05, -1.5377e-04,\n",
              "             5.4765e-04,  1.8371e-06, -1.2995e-05, -5.3301e-06,  4.9111e-06,\n",
              "            -3.0661e-04,  5.1972e-04,  2.7507e-04,  6.1374e-05, -1.9569e-04,\n",
              "            -5.8419e-05, -3.2114e-04,  7.6520e-04,  8.8323e-05,  1.4753e-04,\n",
              "            -2.5031e-04, -5.2705e-05, -9.5036e-05,  1.1374e-04, -2.5280e-04,\n",
              "             6.2904e-05,  3.8775e-05,  1.5268e-04,  8.8382e-05,  3.0071e-04,\n",
              "             1.4354e-04, -4.4815e-05, -2.7548e-05, -1.0800e-04, -5.0902e-05,\n",
              "             1.0120e-04,  3.3386e-04, -3.3747e-05, -1.0917e-04,  4.1160e-05,\n",
              "            -9.3350e-05, -1.1728e-04,  2.1717e-04,  2.8394e-04,  5.6486e-04,\n",
              "             3.4768e-05,  5.0341e-04, -3.3468e-05, -2.5436e-04,  1.0861e-04,\n",
              "            -5.9475e-04,  5.8719e-06,  1.8306e-04, -3.1928e-04,  1.2430e-06,\n",
              "            -3.0542e-04, -2.6256e-04,  1.0950e-04,  5.3870e-04,  7.9599e-05,\n",
              "             2.3410e-04,  1.5671e-05,  2.2514e-05, -3.0767e-04, -2.3996e-04,\n",
              "            -6.2705e-05,  5.7333e-05, -5.0227e-05, -1.6349e-04,  2.2162e-03,\n",
              "             1.7189e-04, -1.0722e-04, -1.7074e-04,  1.0622e-04,  6.8502e-05,\n",
              "             1.5971e-03,  4.8965e-05, -2.8403e-04,  1.2517e-04,  1.6495e-04,\n",
              "             7.1926e-05,  5.5999e-05,  3.4300e-04,  8.8687e-04,  2.1835e-04,\n",
              "             2.8274e-04, -1.4863e-04, -1.6411e-04, -5.8496e-05, -9.2679e-05,\n",
              "             6.2800e-05,  3.9273e-04, -3.6388e-06,  3.7738e-04,  5.2655e-04,\n",
              "            -4.2675e-04,  7.3117e-05,  1.0610e-04,  1.2376e-04, -1.7915e-04,\n",
              "            -2.9582e-04,  1.6820e-04,  2.4443e-04, -1.1293e-04,  1.8003e-03,\n",
              "            -2.0553e-04,  8.1818e-04, -6.3632e-04, -8.2879e-05,  3.1122e-05,\n",
              "             3.0484e-04,  2.8945e-05,  4.9968e-04, -1.1547e-04, -3.6463e-05,\n",
              "            -2.7921e-04,  4.9983e-05, -8.5607e-04,  1.8862e-04, -7.4910e-04,\n",
              "            -6.1517e-04,  5.2738e-04,  8.4869e-04,  4.0937e-04,  1.7252e-04,\n",
              "            -1.7726e-05, -2.5099e-04, -6.6320e-05, -2.3118e-04,  1.0167e-03,\n",
              "            -3.3622e-04,  1.2937e-03, -6.6157e-04, -2.1508e-03,  1.7020e-05,\n",
              "            -6.9378e-05,  3.5067e-04, -2.1251e-04, -4.5886e-05,  7.6080e-04,\n",
              "            -4.3656e-04,  4.3590e-04, -9.8635e-04, -6.9913e-05, -3.0147e-04,\n",
              "            -9.4993e-04,  1.8421e-04,  1.1580e-03,  9.5279e-04,  3.9306e-04,\n",
              "            -7.6881e-04, -4.5088e-05,  6.8569e-04, -6.5970e-04, -1.0197e-04,\n",
              "            -1.5967e-04,  3.1168e-04,  4.7442e-04, -4.5854e-04, -1.1323e-04,\n",
              "             1.1660e-03, -1.1567e-03, -3.9865e-04,  9.8712e-04,  4.6720e-04,\n",
              "            -2.3178e-04,  6.6433e-04]),\n",
              "    'exp_avg_sq': tensor([1.8145e-07, 6.9585e-07, 3.8261e-07, 1.1621e-06, 5.0707e-07, 9.0524e-07,\n",
              "            2.6465e-07, 8.7968e-07, 5.6819e-07, 5.4722e-07, 4.4432e-07, 1.9381e-07,\n",
              "            1.6497e-07, 2.1779e-07, 7.3071e-07, 2.1000e-07, 2.9995e-07, 4.9627e-07,\n",
              "            7.8724e-07, 7.6714e-06, 3.8247e-07, 9.8877e-07, 3.1012e-07, 5.6443e-07,\n",
              "            1.7298e-06, 2.0669e-07, 1.5181e-07, 1.0078e-07, 1.1959e-07, 5.8735e-07,\n",
              "            9.1414e-07, 6.5452e-07, 1.9991e-07, 5.1399e-07, 4.8134e-07, 4.0381e-07,\n",
              "            2.4010e-06, 4.2428e-07, 3.3011e-07, 7.9709e-07, 3.8509e-07, 4.2892e-07,\n",
              "            1.9349e-06, 2.4885e-07, 7.6303e-07, 7.3469e-07, 1.6420e-07, 5.2452e-07,\n",
              "            1.4614e-07, 4.4871e-07, 7.1546e-07, 1.4480e-07, 3.6502e-07, 3.5366e-07,\n",
              "            3.7459e-07, 1.2198e-06, 8.4588e-07, 1.1986e-07, 6.3244e-07, 1.5711e-07,\n",
              "            2.7348e-07, 4.6378e-07, 9.0280e-08, 2.7352e-07, 2.9998e-07, 3.7004e-07,\n",
              "            5.2552e-07, 3.0442e-07, 3.9802e-07, 1.2707e-06, 7.4620e-07, 3.9196e-07,\n",
              "            3.2813e-07, 8.9320e-07, 6.8067e-07, 7.1447e-07, 6.4189e-07, 3.6715e-07,\n",
              "            1.9921e-06, 3.1077e-07, 3.4192e-07, 3.2619e-07, 4.9978e-07, 1.8180e-06,\n",
              "            3.0414e-07, 3.5855e-07, 2.7477e-07, 2.6654e-07, 1.1590e-06, 6.8204e-07,\n",
              "            5.2785e-07, 2.6722e-07, 2.6245e-07, 4.2604e-07, 5.4066e-05, 4.6476e-07,\n",
              "            6.8762e-07, 3.2113e-07, 3.0519e-07, 7.6296e-07, 4.8461e-05, 9.1881e-07,\n",
              "            4.5683e-07, 7.6888e-07, 1.8976e-07, 8.2849e-07, 2.6006e-07, 7.1936e-07,\n",
              "            1.0746e-05, 9.2834e-07, 3.5545e-07, 7.7571e-07, 4.0049e-07, 7.5779e-07,\n",
              "            2.6462e-07, 5.7793e-07, 1.2383e-06, 1.8032e-07, 5.8924e-06, 4.3076e-06,\n",
              "            5.8939e-07, 5.1862e-07, 4.8775e-07, 2.8935e-07, 1.5924e-06, 7.9223e-07,\n",
              "            1.9707e-07, 2.6028e-07, 3.2766e-06, 9.4858e-06, 4.8709e-06, 1.3410e-05,\n",
              "            1.0992e-05, 9.3438e-06, 5.7038e-06, 9.7701e-06, 4.2233e-06, 2.9100e-06,\n",
              "            2.6929e-06, 2.7813e-06, 2.7639e-06, 2.7493e-06, 7.9698e-06, 2.8968e-06,\n",
              "            6.9763e-06, 1.0030e-05, 4.6466e-06, 9.4337e-06, 4.2738e-06, 2.5808e-06,\n",
              "            3.8981e-06, 5.7348e-06, 5.2594e-06, 1.8996e-06, 5.1412e-06, 2.2966e-06,\n",
              "            5.5208e-06, 1.1863e-05, 1.3374e-05, 1.6089e-06, 4.7447e-06, 9.4452e-06,\n",
              "            2.1865e-06, 2.8835e-06, 1.4831e-05, 7.2587e-06, 4.3003e-06, 5.9183e-06,\n",
              "            7.5962e-06, 3.8606e-06, 1.8548e-05, 5.6833e-06, 1.7031e-05, 8.2817e-06,\n",
              "            5.6537e-06, 5.7619e-06, 1.5990e-06, 4.5310e-06, 3.9445e-06, 1.3296e-06,\n",
              "            6.7978e-06, 4.7449e-06, 1.2329e-05, 1.4265e-05, 5.4641e-06, 8.0850e-06,\n",
              "            8.9259e-06, 4.5226e-06, 6.7014e-06, 3.8413e-06, 2.4834e-06, 5.1473e-06]),\n",
              "    'step': 5104},\n",
              "   9: {'exp_avg': tensor([[ 2.3845e-04,  4.5478e-04,  2.4996e-05,  ..., -8.8900e-05,\n",
              "             -1.1510e-04,  1.7784e-04],\n",
              "            [ 2.7326e-05,  1.6002e-04,  7.1664e-05,  ...,  6.0691e-05,\n",
              "              1.3238e-04,  1.0652e-04],\n",
              "            [ 8.1388e-05, -1.5856e-06,  6.4549e-05,  ...,  1.1409e-05,\n",
              "              3.1739e-05, -9.1564e-06],\n",
              "            ...,\n",
              "            [ 1.6474e-04,  1.2538e-04, -4.2522e-05,  ...,  1.8552e-05,\n",
              "             -1.2209e-04,  2.3351e-05],\n",
              "            [ 1.7180e-04, -1.9824e-04, -8.8505e-06,  ..., -9.3627e-05,\n",
              "             -2.2223e-04, -3.9259e-04],\n",
              "            [ 2.6503e-04, -4.8679e-05, -6.2458e-05,  ..., -8.4641e-05,\n",
              "              6.4872e-05, -1.6815e-04]]),\n",
              "    'exp_avg_sq': tensor([[3.8576e-07, 1.0947e-06, 7.1993e-07,  ..., 4.0158e-07, 7.2554e-07,\n",
              "             6.1683e-07],\n",
              "            [1.1121e-07, 2.0906e-07, 3.9046e-08,  ..., 4.5695e-08, 1.1053e-07,\n",
              "             1.3762e-07],\n",
              "            [2.6961e-07, 2.0246e-07, 9.6956e-08,  ..., 9.9536e-08, 1.3085e-07,\n",
              "             1.0518e-07],\n",
              "            ...,\n",
              "            [3.5797e-07, 3.0456e-07, 1.5420e-07,  ..., 1.6718e-07, 1.5620e-07,\n",
              "             1.2865e-07],\n",
              "            [8.1135e-07, 7.5069e-07, 3.8171e-07,  ..., 3.1404e-07, 5.4454e-07,\n",
              "             4.1918e-07],\n",
              "            [4.2706e-07, 3.0319e-07, 1.1715e-07,  ..., 1.1759e-07, 1.6948e-07,\n",
              "             1.6460e-07]]),\n",
              "    'step': 5104},\n",
              "   10: {'exp_avg': tensor([-1.5789e-04, -2.1597e-04,  7.5901e-05, -2.2646e-04, -2.0851e-04,\n",
              "            -3.5191e-04, -3.2252e-04, -6.0631e-05,  2.9123e-04,  2.2866e-05,\n",
              "            -4.7771e-05,  4.1289e-04,  4.8884e-05, -1.3365e-03, -5.8544e-06,\n",
              "            -1.8177e-04,  1.4334e-04, -3.4331e-04, -2.0008e-04,  2.3121e-04,\n",
              "            -2.0104e-05,  2.5740e-04,  5.8742e-04,  6.1237e-04, -2.7690e-04,\n",
              "            -3.3711e-04,  5.6889e-05, -3.1511e-04, -2.6968e-04, -1.5705e-04,\n",
              "             8.5526e-04, -1.2729e-04,  4.7604e-05,  7.9498e-05, -7.8288e-06,\n",
              "            -2.9493e-04, -1.4676e-04,  2.8011e-05,  9.8731e-05, -7.5681e-04,\n",
              "            -2.6422e-04,  3.4547e-05,  2.9153e-06,  1.2107e-05, -4.9267e-04,\n",
              "             2.2937e-04,  1.8176e-06,  3.0690e-04,  3.1395e-04,  6.5697e-04,\n",
              "             1.9672e-03, -1.0956e-04, -1.4091e-04,  4.8143e-05,  1.7878e-03,\n",
              "            -6.9646e-04,  3.1831e-04,  3.0943e-05, -1.7218e-04,  2.5196e-05,\n",
              "             9.1197e-05,  5.9936e-05,  8.5101e-04,  3.5637e-04]),\n",
              "    'exp_avg_sq': tensor([2.1077e-06, 3.0079e-07, 3.9692e-07, 1.5806e-07, 1.6261e-07, 1.9309e-06,\n",
              "            7.0254e-07, 4.9001e-07, 4.7024e-07, 1.2191e-06, 2.1296e-06, 1.0742e-06,\n",
              "            1.4061e-07, 1.7347e-05, 1.7731e-06, 9.1356e-07, 2.7854e-07, 7.7921e-07,\n",
              "            8.9234e-07, 6.7156e-07, 3.3608e-07, 9.8670e-08, 3.7006e-06, 2.5677e-06,\n",
              "            1.6297e-06, 1.2471e-06, 3.0789e-07, 6.7575e-07, 7.6525e-07, 1.7979e-06,\n",
              "            2.9848e-06, 7.2838e-07, 1.2044e-07, 2.4148e-07, 1.7102e-07, 1.9270e-06,\n",
              "            4.4862e-07, 1.0932e-07, 1.2850e-06, 1.2313e-06, 2.5684e-07, 1.0376e-07,\n",
              "            4.6190e-08, 1.0504e-06, 1.4461e-06, 5.8195e-06, 1.9073e-08, 1.1065e-06,\n",
              "            3.4823e-07, 1.6122e-06, 2.2283e-05, 4.7027e-07, 9.0860e-07, 6.6984e-07,\n",
              "            1.3624e-04, 7.1568e-06, 1.2711e-06, 4.4915e-08, 9.3643e-07, 1.1464e-06,\n",
              "            1.0487e-06, 6.3725e-07, 1.8170e-06, 5.9271e-07]),\n",
              "    'step': 5104},\n",
              "   11: {'exp_avg': tensor([[-3.4907e-04, -6.0064e-04, -4.3563e-04,  ..., -3.7634e-04,\n",
              "              1.2117e-03, -6.5292e-04],\n",
              "            [ 1.8654e-04, -1.6614e-03,  6.5302e-04,  ...,  1.1628e-03,\n",
              "             -1.0948e-03,  1.1719e-03],\n",
              "            [ 1.8120e-03,  2.6331e-04,  7.4871e-04,  ...,  3.8163e-04,\n",
              "             -1.3238e-03,  2.0727e-03],\n",
              "            ...,\n",
              "            [ 4.2239e-04, -1.3421e-04, -5.6374e-04,  ..., -6.8571e-07,\n",
              "              4.2623e-04, -5.3809e-04],\n",
              "            [ 9.7904e-04,  8.7782e-04, -4.6081e-05,  ...,  6.5471e-05,\n",
              "             -8.0892e-04,  1.6410e-03],\n",
              "            [-1.3167e-05, -6.3176e-04, -2.1322e-04,  ..., -2.5036e-04,\n",
              "              8.2588e-04, -7.1850e-04]]),\n",
              "    'exp_avg_sq': tensor([[4.2305e-06, 4.6712e-06, 3.2202e-06,  ..., 4.2330e-06, 4.6700e-06,\n",
              "             5.2421e-06],\n",
              "            [2.2953e-05, 3.5255e-05, 2.2821e-05,  ..., 2.9129e-05, 3.7216e-05,\n",
              "             2.1582e-05],\n",
              "            [1.6057e-05, 2.5711e-05, 1.7703e-05,  ..., 8.5540e-06, 1.2269e-05,\n",
              "             1.0058e-05],\n",
              "            ...,\n",
              "            [9.9528e-06, 1.9815e-05, 1.0094e-05,  ..., 1.3066e-05, 9.5616e-06,\n",
              "             4.8214e-06],\n",
              "            [1.4662e-05, 1.7250e-05, 1.3496e-05,  ..., 1.4922e-05, 1.3001e-05,\n",
              "             1.1217e-05],\n",
              "            [3.7000e-06, 4.1750e-06, 2.9998e-06,  ..., 2.8231e-06, 3.1859e-06,\n",
              "             2.9578e-06]]),\n",
              "    'step': 5104},\n",
              "   12: {'exp_avg': tensor([ 1.3412e-03, -7.2763e-05,  1.2111e-03, -3.6827e-04, -1.7609e-04,\n",
              "            -3.9903e-05, -7.7667e-04,  1.1465e-03]),\n",
              "    'exp_avg_sq': tensor([5.7056e-06, 3.7115e-05, 2.7139e-05, 5.3376e-05, 5.9855e-06, 2.2623e-05,\n",
              "            1.9239e-05, 5.2746e-06]),\n",
              "    'step': 5104},\n",
              "   13: {'exp_avg': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "              0.0000e+00,  0.0000e+00],\n",
              "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
              "              0.0000e+00,  0.0000e+00],\n",
              "            [-2.5376e-04,  6.1014e-04,  2.9088e-05,  ..., -5.7850e-05,\n",
              "             -5.6766e-05, -1.8550e-04],\n",
              "            ...,\n",
              "            [ 1.4209e-32, -5.6052e-45, -5.3810e-43,  ...,  1.0178e-34,\n",
              "             -5.6052e-45, -2.7750e-32],\n",
              "            [ 5.6052e-45,  0.0000e+00, -5.6052e-45,  ...,  5.6052e-45,\n",
              "             -7.2555e-26, -5.6052e-45],\n",
              "            [-5.6052e-45,  5.6052e-45,  5.6052e-45,  ...,  4.4545e-25,\n",
              "              1.3571e-25, -8.2629e-26]]),\n",
              "    'exp_avg_sq': tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
              "             0.0000e+00],\n",
              "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
              "             0.0000e+00],\n",
              "            [1.6207e-06, 1.1839e-06, 1.2582e-06,  ..., 1.3167e-06, 1.2347e-06,\n",
              "             1.4428e-06],\n",
              "            ...,\n",
              "            [1.0185e-10, 6.9000e-12, 1.4621e-11,  ..., 6.2668e-12, 3.6858e-11,\n",
              "             3.5653e-10],\n",
              "            [1.4189e-10, 0.0000e+00, 3.3362e-12,  ..., 1.5761e-10, 5.1867e-11,\n",
              "             7.4587e-11],\n",
              "            [1.9920e-10, 1.1118e-09, 3.5226e-11,  ..., 8.9536e-10, 4.8141e-10,\n",
              "             3.0485e-11]]),\n",
              "    'step': 5104},\n",
              "   14: {'exp_avg': tensor([[-1.8950e-04, -9.4514e-05, -1.8239e-04,  ...,  2.2621e-05,\n",
              "             -1.7402e-05,  2.4765e-04],\n",
              "            [-2.3823e-05,  5.1968e-05,  3.1409e-05,  ...,  9.6952e-06,\n",
              "             -1.4896e-04,  2.0172e-05],\n",
              "            [-1.4843e-04, -4.3180e-05, -2.1342e-04,  ...,  2.0062e-04,\n",
              "             -4.1464e-04,  1.2820e-04],\n",
              "            ...,\n",
              "            [ 2.2996e-04,  4.7365e-05,  2.0619e-04,  ..., -1.8778e-04,\n",
              "             -1.8613e-04,  7.2415e-04],\n",
              "            [ 1.0329e-05,  4.2341e-06,  2.5190e-05,  ..., -3.7141e-05,\n",
              "              9.1652e-05, -3.9244e-05],\n",
              "            [-3.9680e-05,  8.6029e-05, -1.8480e-05,  ..., -1.5465e-04,\n",
              "              5.1487e-05,  5.7332e-06]]),\n",
              "    'exp_avg_sq': tensor([[2.2005e-07, 1.5804e-07, 2.1459e-07,  ..., 3.0517e-07, 7.4223e-07,\n",
              "             5.5074e-07],\n",
              "            [6.0555e-08, 5.4676e-08, 8.8936e-08,  ..., 5.9269e-08, 5.2326e-08,\n",
              "             4.1615e-08],\n",
              "            [1.3781e-06, 4.0479e-07, 6.3006e-07,  ..., 8.6737e-07, 2.1185e-06,\n",
              "             1.5982e-06],\n",
              "            ...,\n",
              "            [6.2472e-07, 3.7621e-07, 5.0087e-07,  ..., 7.1034e-07, 1.4901e-06,\n",
              "             1.0575e-06],\n",
              "            [6.0113e-08, 2.7967e-08, 3.1817e-08,  ..., 4.1281e-08, 9.4368e-08,\n",
              "             7.5683e-08],\n",
              "            [6.8007e-08, 7.0411e-08, 1.4059e-07,  ..., 6.0652e-08, 6.0708e-08,\n",
              "             4.5401e-08]]),\n",
              "    'step': 5104},\n",
              "   15: {'exp_avg': tensor([[-5.8093e-05,  1.1012e-04,  3.1088e-04,  ...,  3.8929e-04,\n",
              "              3.2397e-04,  1.0494e-04],\n",
              "            [-1.9153e-04, -1.4730e-04, -1.7460e-04,  ...,  7.7002e-05,\n",
              "             -2.1964e-04, -1.4486e-04],\n",
              "            [ 6.8324e-05, -5.8059e-04, -1.6788e-04,  ..., -9.5373e-04,\n",
              "             -1.9456e-04, -1.9092e-04],\n",
              "            ...,\n",
              "            [ 4.2096e-06, -3.2931e-05, -9.7944e-05,  ..., -8.4176e-05,\n",
              "             -1.0055e-04,  1.9568e-06],\n",
              "            [-4.0498e-05, -1.5414e-05,  4.3399e-05,  ..., -5.2424e-05,\n",
              "              8.7863e-05,  4.7019e-06],\n",
              "            [-4.0035e-05, -4.5779e-05, -7.4822e-05,  ..., -5.3423e-05,\n",
              "             -7.6809e-06,  4.3474e-05]]),\n",
              "    'exp_avg_sq': tensor([[1.3514e-06, 3.5083e-06, 1.0515e-06,  ..., 1.7693e-06, 3.1539e-06,\n",
              "             3.3775e-06],\n",
              "            [9.1725e-08, 1.1433e-07, 1.0200e-07,  ..., 1.2623e-07, 7.9865e-08,\n",
              "             1.0683e-07],\n",
              "            [3.4229e-06, 7.9932e-06, 4.7777e-06,  ..., 5.3732e-06, 7.0003e-06,\n",
              "             6.7815e-06],\n",
              "            ...,\n",
              "            [3.3589e-07, 4.4973e-07, 3.1188e-07,  ..., 3.1305e-07, 6.3783e-07,\n",
              "             4.9517e-07],\n",
              "            [1.9144e-08, 2.0314e-08, 1.9882e-08,  ..., 1.9328e-08, 2.2867e-08,\n",
              "             2.4433e-08],\n",
              "            [1.6837e-08, 1.9892e-08, 1.5635e-08,  ..., 2.0420e-08, 1.0420e-08,\n",
              "             1.6211e-08]]),\n",
              "    'step': 5104},\n",
              "   16: {'exp_avg': tensor([ 1.7395e-04, -2.1369e-04, -3.3090e-04,  3.9154e-05,  5.7821e-05,\n",
              "             1.4744e-04, -9.4217e-08,  2.9998e-05, -6.0787e-05, -1.2986e-04,\n",
              "             4.3543e-05,  3.7519e-04,  7.8127e-04, -3.8309e-04,  1.2250e-04,\n",
              "            -1.4300e-07,  1.6921e-05, -3.2384e-04,  8.4865e-05, -1.1817e-08,\n",
              "             9.0427e-05, -1.2654e-05,  1.4751e-05,  9.1066e-06,  2.3311e-04,\n",
              "             1.5283e-04,  2.9201e-04,  1.2206e-06,  3.9079e-04,  2.3439e-05,\n",
              "             2.4587e-05,  1.2516e-06,  1.6726e-04,  7.0139e-05, -5.2138e-06,\n",
              "            -1.5709e-04,  7.0059e-05,  3.7834e-05,  4.5473e-05,  2.2602e-07,\n",
              "             6.5720e-05,  6.1329e-05,  3.2077e-04, -1.3798e-06,  7.7746e-05,\n",
              "             2.1949e-05,  5.9241e-04, -3.5182e-04,  2.8834e-04, -4.6426e-07,\n",
              "             7.4392e-05,  4.6199e-05,  6.1567e-05, -3.9884e-05,  2.1120e-05,\n",
              "             8.6615e-05, -1.8065e-08, -3.9594e-05,  2.7261e-06, -4.9178e-05,\n",
              "             1.0776e-06, -1.0974e-04,  1.0760e-04,  1.3530e-04, -3.1957e-04,\n",
              "             4.3003e-05, -2.9370e-06,  1.7507e-07,  5.2726e-05, -3.2174e-04,\n",
              "            -1.7040e-07,  1.7955e-04, -2.2448e-04, -4.1695e-05,  2.7555e-05,\n",
              "             2.1745e-04,  2.0058e-05,  7.5845e-04, -6.3410e-04, -5.4136e-08,\n",
              "             4.0397e-06,  5.1455e-04, -2.5735e-06,  5.9196e-08, -1.5774e-05,\n",
              "             2.1528e-06,  3.6021e-04, -2.3698e-04,  2.3826e-04, -2.7197e-05,\n",
              "            -4.8872e-04, -2.5698e-05, -2.3091e-04, -4.4626e-04, -2.0784e-04,\n",
              "            -2.1797e-05, -4.2712e-04, -4.7330e-05, -9.9764e-05, -1.7911e-04,\n",
              "            -1.0799e-05, -2.1269e-05, -3.8529e-04,  8.2001e-06,  8.2963e-05,\n",
              "             1.0584e-04, -1.4457e-04, -2.4485e-04, -9.3516e-05, -3.0684e-04,\n",
              "            -7.1945e-04,  3.9546e-05, -2.0675e-05, -2.8395e-07, -4.7529e-04,\n",
              "             6.6077e-05, -9.1291e-05, -2.2365e-05, -3.8067e-05, -9.7023e-04,\n",
              "             3.2562e-08, -2.3743e-07, -1.1378e-04, -7.7275e-05,  4.4900e-06,\n",
              "             1.1387e-04,  5.2758e-05, -2.4251e-04,  3.4970e-04, -1.0911e-04,\n",
              "            -3.2165e-04, -3.2526e-05, -6.5792e-04,  4.3703e-04,  6.9311e-07,\n",
              "             4.6012e-05,  1.9436e-04,  1.0136e-03,  2.5454e-04, -8.1938e-04,\n",
              "            -2.3088e-03,  5.3866e-04,  6.2796e-04,  1.7849e-06, -9.9686e-05,\n",
              "             1.3551e-04,  1.0224e-03, -1.0427e-06,  9.8261e-05, -7.2582e-06,\n",
              "             2.0119e-04,  3.4775e-05,  9.8147e-05,  6.8678e-04,  6.2435e-04,\n",
              "            -1.1125e-04, -7.2869e-04,  5.9801e-05,  1.2454e-04, -1.4202e-04,\n",
              "            -2.5648e-04,  5.4776e-04, -1.1009e-04, -1.0824e-04, -1.2839e-04,\n",
              "            -1.2966e-04, -7.1497e-05,  9.8237e-05, -5.1072e-06,  9.1181e-05,\n",
              "            -1.3873e-05, -4.2184e-04, -7.2445e-04,  6.0956e-05,  4.1410e-04,\n",
              "            -1.7230e-04,  2.6635e-04,  8.2271e-05,  5.1619e-04,  4.9669e-04,\n",
              "             5.1957e-05,  8.2778e-05, -1.7304e-04, -3.8553e-04, -7.7994e-07,\n",
              "            -9.0630e-05, -1.6588e-04,  2.9010e-04, -2.3721e-05,  2.0738e-04,\n",
              "             1.7436e-04,  1.3543e-04]),\n",
              "    'exp_avg_sq': tensor([3.5738e-06, 1.3896e-07, 7.7791e-06, 2.1922e-07, 3.9065e-07, 1.5008e-06,\n",
              "            1.0169e-10, 6.8835e-08, 1.0058e-07, 1.8546e-06, 1.9839e-07, 2.0200e-06,\n",
              "            5.9131e-06, 2.4544e-06, 2.7933e-06, 9.7097e-11, 3.5083e-07, 1.9657e-06,\n",
              "            9.6253e-08, 7.6252e-11, 1.5462e-06, 1.0328e-08, 1.8465e-08, 3.3040e-10,\n",
              "            1.4419e-06, 2.1274e-06, 4.0099e-07, 9.7708e-11, 5.9284e-07, 6.5184e-08,\n",
              "            3.1159e-09, 9.6066e-11, 1.1374e-07, 4.5574e-07, 3.0165e-08, 1.8837e-06,\n",
              "            2.1772e-07, 2.2420e-08, 5.8088e-07, 4.4108e-09, 5.7979e-08, 5.4318e-08,\n",
              "            4.0865e-07, 1.5844e-10, 3.1546e-06, 5.9691e-09, 1.3997e-06, 2.7723e-06,\n",
              "            5.3943e-07, 1.7285e-10, 1.6478e-07, 4.4138e-07, 6.2724e-08, 7.3878e-07,\n",
              "            6.6943e-07, 2.8192e-07, 8.9807e-11, 3.8047e-08, 8.7013e-08, 6.6839e-08,\n",
              "            1.1058e-10, 3.2564e-06, 5.4718e-08, 1.5807e-07, 4.7939e-06, 1.9850e-07,\n",
              "            4.4952e-08, 2.4553e-10, 3.2830e-07, 1.3814e-06, 5.6700e-11, 1.5231e-07,\n",
              "            1.8532e-07, 8.1486e-08, 3.1058e-07, 2.1204e-05, 1.3336e-08, 1.7760e-05,\n",
              "            4.0258e-06, 4.7073e-11, 4.7908e-10, 3.4553e-06, 5.9525e-07, 2.5202e-11,\n",
              "            1.5803e-06, 1.1381e-10, 2.4208e-06, 2.2853e-07, 3.2350e-07, 2.9851e-07,\n",
              "            5.0509e-07, 5.4273e-08, 5.4360e-07, 3.9793e-07, 5.4131e-07, 6.3255e-09,\n",
              "            4.5445e-07, 4.4223e-07, 6.9394e-08, 5.7310e-07, 5.6262e-08, 4.2309e-09,\n",
              "            8.7193e-07, 2.7502e-09, 7.3568e-07, 4.9576e-07, 1.1901e-06, 3.9956e-06,\n",
              "            6.1949e-07, 6.7273e-07, 6.2557e-06, 4.2648e-07, 9.2670e-09, 1.1984e-10,\n",
              "            1.7346e-05, 1.0052e-07, 1.7639e-07, 1.2338e-07, 4.4643e-06, 4.1531e-05,\n",
              "            3.9186e-11, 2.7466e-10, 4.1484e-07, 3.9821e-07, 5.3285e-10, 2.1199e-07,\n",
              "            3.0819e-08, 1.7739e-07, 1.4272e-05, 1.9373e-07, 8.1429e-06, 4.6214e-07,\n",
              "            1.5739e-05, 1.7344e-05, 3.7675e-08, 1.3498e-07, 4.2757e-07, 1.8631e-05,\n",
              "            1.4679e-06, 7.8199e-06, 8.4854e-06, 5.2220e-06, 8.8121e-06, 3.0999e-08,\n",
              "            4.8778e-07, 1.0185e-05, 4.0267e-06, 2.8025e-08, 3.1380e-06, 3.0991e-07,\n",
              "            4.3667e-07, 4.6068e-08, 2.0858e-06, 6.8959e-06, 5.5805e-06, 3.1555e-07,\n",
              "            4.4176e-06, 2.3583e-06, 1.1380e-06, 2.3136e-07, 3.7206e-07, 5.4256e-06,\n",
              "            2.6642e-07, 1.8560e-05, 2.7398e-07, 4.9436e-07, 2.1225e-06, 8.9052e-08,\n",
              "            3.3310e-06, 2.8798e-07, 4.5909e-06, 5.4544e-06, 7.1284e-06, 7.1932e-08,\n",
              "            9.0071e-06, 1.7157e-05, 6.8586e-07, 2.4231e-07, 4.0016e-06, 8.9480e-06,\n",
              "            1.2153e-06, 5.1616e-06, 5.5694e-06, 7.6368e-06, 3.6246e-08, 2.8901e-07,\n",
              "            4.9056e-07, 7.2416e-07, 5.0242e-08, 6.0963e-06, 2.1511e-07, 1.8104e-07]),\n",
              "    'step': 5104},\n",
              "   17: {'exp_avg': tensor([ 1.7395e-04, -2.1369e-04, -3.3090e-04,  3.9154e-05,  5.7821e-05,\n",
              "             1.4744e-04, -9.4217e-08,  2.9998e-05, -6.0787e-05, -1.2986e-04,\n",
              "             4.3543e-05,  3.7519e-04,  7.8127e-04, -3.8309e-04,  1.2250e-04,\n",
              "            -1.4300e-07,  1.6921e-05, -3.2384e-04,  8.4865e-05, -1.1817e-08,\n",
              "             9.0427e-05, -1.2654e-05,  1.4751e-05,  9.1066e-06,  2.3311e-04,\n",
              "             1.5283e-04,  2.9201e-04,  1.2206e-06,  3.9079e-04,  2.3439e-05,\n",
              "             2.4587e-05,  1.2516e-06,  1.6726e-04,  7.0139e-05, -5.2138e-06,\n",
              "            -1.5709e-04,  7.0059e-05,  3.7834e-05,  4.5473e-05,  2.2602e-07,\n",
              "             6.5720e-05,  6.1329e-05,  3.2077e-04, -1.3798e-06,  7.7746e-05,\n",
              "             2.1949e-05,  5.9241e-04, -3.5182e-04,  2.8834e-04, -4.6426e-07,\n",
              "             7.4392e-05,  4.6199e-05,  6.1567e-05, -3.9884e-05,  2.1120e-05,\n",
              "             8.6615e-05, -1.8065e-08, -3.9594e-05,  2.7261e-06, -4.9178e-05,\n",
              "             1.0776e-06, -1.0974e-04,  1.0760e-04,  1.3530e-04, -3.1957e-04,\n",
              "             4.3003e-05, -2.9370e-06,  1.7507e-07,  5.2726e-05, -3.2174e-04,\n",
              "            -1.7040e-07,  1.7955e-04, -2.2448e-04, -4.1695e-05,  2.7555e-05,\n",
              "             2.1745e-04,  2.0058e-05,  7.5845e-04, -6.3410e-04, -5.4136e-08,\n",
              "             4.0397e-06,  5.1455e-04, -2.5735e-06,  5.9196e-08, -1.5774e-05,\n",
              "             2.1528e-06,  3.6021e-04, -2.3698e-04,  2.3826e-04, -2.7197e-05,\n",
              "            -4.8872e-04, -2.5698e-05, -2.3091e-04, -4.4626e-04, -2.0784e-04,\n",
              "            -2.1797e-05, -4.2712e-04, -4.7330e-05, -9.9764e-05, -1.7911e-04,\n",
              "            -1.0799e-05, -2.1269e-05, -3.8529e-04,  8.2001e-06,  8.2963e-05,\n",
              "             1.0584e-04, -1.4457e-04, -2.4485e-04, -9.3516e-05, -3.0684e-04,\n",
              "            -7.1945e-04,  3.9546e-05, -2.0675e-05, -2.8395e-07, -4.7529e-04,\n",
              "             6.6077e-05, -9.1291e-05, -2.2365e-05, -3.8067e-05, -9.7023e-04,\n",
              "             3.2562e-08, -2.3743e-07, -1.1378e-04, -7.7275e-05,  4.4900e-06,\n",
              "             1.1387e-04,  5.2758e-05, -2.4251e-04,  1.4089e-04, -9.1666e-05,\n",
              "            -9.6939e-05, -2.2048e-05, -6.4466e-04,  8.9388e-05,  4.1521e-07,\n",
              "             5.9284e-06,  2.5897e-06,  1.0136e-03,  1.6644e-05, -1.1062e-04,\n",
              "            -4.2625e-04,  9.4047e-05,  9.4892e-05,  1.6042e-06, -2.2670e-05,\n",
              "            -1.9966e-04,  8.7556e-04, -4.1994e-07,  6.2426e-05, -4.4204e-05,\n",
              "             1.7672e-04,  1.7229e-05,  6.7276e-05,  2.3319e-04,  2.1607e-04,\n",
              "            -1.2776e-04, -4.4403e-04, -7.4130e-05,  1.1763e-04, -1.4210e-04,\n",
              "            -7.8447e-05,  3.4695e-04, -1.1984e-04, -6.0874e-05, -6.0555e-05,\n",
              "            -8.3479e-05, -2.2548e-06,  2.0114e-05,  2.7190e-05,  8.3868e-05,\n",
              "            -5.9367e-05, -4.2184e-04, -1.2647e-04,  2.9287e-05,  8.8198e-05,\n",
              "            -1.1495e-03,  7.0069e-05,  8.2072e-05,  4.4506e-04,  4.6237e-04,\n",
              "            -4.0096e-06,  2.6080e-04,  2.6244e-05, -3.5412e-04, -3.7251e-07,\n",
              "            -5.7101e-05, -9.9346e-05,  2.8813e-04, -1.6588e-05,  6.4641e-05,\n",
              "             8.3610e-05,  6.9188e-05]),\n",
              "    'exp_avg_sq': tensor([3.5738e-06, 1.3896e-07, 7.7791e-06, 2.1922e-07, 3.9065e-07, 1.5008e-06,\n",
              "            1.0169e-10, 6.8835e-08, 1.0058e-07, 1.8546e-06, 1.9839e-07, 2.0200e-06,\n",
              "            5.9131e-06, 2.4544e-06, 2.7933e-06, 9.7097e-11, 3.5083e-07, 1.9657e-06,\n",
              "            9.6253e-08, 7.6252e-11, 1.5462e-06, 1.0328e-08, 1.8465e-08, 3.3040e-10,\n",
              "            1.4419e-06, 2.1274e-06, 4.0099e-07, 9.7708e-11, 5.9284e-07, 6.5184e-08,\n",
              "            3.1159e-09, 9.6066e-11, 1.1374e-07, 4.5574e-07, 3.0165e-08, 1.8837e-06,\n",
              "            2.1772e-07, 2.2420e-08, 5.8088e-07, 4.4108e-09, 5.7979e-08, 5.4318e-08,\n",
              "            4.0865e-07, 1.5844e-10, 3.1546e-06, 5.9691e-09, 1.3997e-06, 2.7723e-06,\n",
              "            5.3943e-07, 1.7285e-10, 1.6478e-07, 4.4138e-07, 6.2724e-08, 7.3878e-07,\n",
              "            6.6943e-07, 2.8192e-07, 8.9807e-11, 3.8047e-08, 8.7013e-08, 6.6839e-08,\n",
              "            1.1058e-10, 3.2564e-06, 5.4718e-08, 1.5807e-07, 4.7939e-06, 1.9850e-07,\n",
              "            4.4952e-08, 2.4553e-10, 3.2830e-07, 1.3814e-06, 5.6700e-11, 1.5231e-07,\n",
              "            1.8532e-07, 8.1486e-08, 3.1058e-07, 2.1204e-05, 1.3336e-08, 1.7760e-05,\n",
              "            4.0258e-06, 4.7073e-11, 4.7908e-10, 3.4553e-06, 5.9525e-07, 2.5202e-11,\n",
              "            1.5803e-06, 1.1381e-10, 2.4208e-06, 2.2853e-07, 3.2350e-07, 2.9851e-07,\n",
              "            5.0509e-07, 5.4273e-08, 5.4360e-07, 3.9793e-07, 5.4131e-07, 6.3255e-09,\n",
              "            4.5445e-07, 4.4223e-07, 6.9394e-08, 5.7310e-07, 5.6262e-08, 4.2309e-09,\n",
              "            8.7193e-07, 2.7502e-09, 7.3568e-07, 4.9576e-07, 1.1901e-06, 3.9956e-06,\n",
              "            6.1949e-07, 6.7273e-07, 6.2557e-06, 4.2648e-07, 9.2670e-09, 1.1984e-10,\n",
              "            1.7346e-05, 1.0052e-07, 1.7639e-07, 1.2338e-07, 4.4643e-06, 4.1531e-05,\n",
              "            3.9186e-11, 2.7466e-10, 4.1484e-07, 3.9821e-07, 5.3285e-10, 2.1199e-07,\n",
              "            3.0819e-08, 1.7739e-07, 3.3533e-06, 3.1354e-08, 9.7211e-07, 1.7791e-07,\n",
              "            1.0847e-05, 2.9263e-06, 1.1095e-08, 2.9497e-08, 1.8760e-07, 9.6585e-06,\n",
              "            4.9707e-07, 2.4797e-07, 9.5351e-07, 1.9350e-07, 1.0691e-06, 8.9564e-09,\n",
              "            1.9681e-07, 1.5682e-06, 3.8584e-06, 8.3677e-09, 6.7177e-07, 2.4250e-07,\n",
              "            3.5392e-07, 1.3280e-08, 2.4890e-07, 1.4796e-06, 3.6710e-06, 2.8405e-07,\n",
              "            2.8414e-06, 1.5560e-06, 1.0955e-06, 2.0898e-07, 7.9038e-08, 2.5845e-06,\n",
              "            1.7128e-07, 9.4702e-06, 1.0358e-07, 3.7712e-07, 1.1037e-06, 1.9176e-08,\n",
              "            2.1025e-06, 1.3468e-07, 1.8965e-06, 5.4280e-06, 3.1107e-07, 1.5442e-08,\n",
              "            2.6089e-06, 8.9038e-06, 3.1718e-07, 2.1958e-07, 3.0401e-06, 6.9375e-06,\n",
              "            9.9152e-07, 2.1932e-06, 8.3085e-07, 3.2775e-06, 1.0694e-08, 1.6090e-07,\n",
              "            1.0675e-07, 2.6708e-07, 2.5103e-08, 7.0556e-07, 3.9789e-08, 3.5720e-08]),\n",
              "    'step': 5104},\n",
              "   18: {'exp_avg': tensor([[-1.2163e-09,  2.6870e-09, -4.8610e-10,  ...,  1.2471e-10,\n",
              "              2.2386e-10,  7.5687e-11],\n",
              "            [-1.3012e-09,  2.7206e-09, -5.2287e-10,  ...,  1.2992e-10,\n",
              "              2.2865e-10,  7.5146e-11],\n",
              "            [-1.2034e-09,  2.6403e-09, -4.8869e-10,  ...,  1.3399e-10,\n",
              "              2.2685e-10,  7.3957e-11],\n",
              "            ...,\n",
              "            [ 5.4227e-07,  1.8624e-06, -1.2144e-06,  ..., -2.7519e-07,\n",
              "              7.9904e-07, -1.5112e-08],\n",
              "            [ 2.2702e-07,  3.6819e-06, -1.4291e-06,  ...,  3.6597e-07,\n",
              "              2.5982e-07, -1.3697e-07],\n",
              "            [-1.3744e-06,  1.9310e-06,  3.8409e-07,  ...,  1.5306e-07,\n",
              "             -2.3242e-10,  8.3514e-09]]),\n",
              "    'exp_avg_sq': tensor([[5.3340e-14, 6.4430e-14, 5.5584e-14,  ..., 1.1341e-16, 1.5665e-16,\n",
              "             1.3019e-16],\n",
              "            [5.4615e-14, 6.6395e-14, 5.7343e-14,  ..., 1.1523e-16, 1.5835e-16,\n",
              "             1.3279e-16],\n",
              "            [5.0102e-14, 6.1357e-14, 5.2778e-14,  ..., 1.1173e-16, 1.5401e-16,\n",
              "             1.2964e-16],\n",
              "            ...,\n",
              "            [2.1967e-09, 3.2282e-09, 3.2040e-09,  ..., 2.3049e-10, 9.6280e-10,\n",
              "             8.9267e-11],\n",
              "            [6.7084e-10, 3.3064e-09, 2.4375e-09,  ..., 2.1551e-10, 5.6361e-11,\n",
              "             5.6800e-10],\n",
              "            [3.4304e-09, 3.5109e-09, 3.4283e-09,  ..., 4.7007e-10, 1.7362e-11,\n",
              "             4.4669e-11]]),\n",
              "    'step': 5104},\n",
              "   19: {'exp_avg': tensor([3.6425e-09, 3.6813e-09, 3.5669e-09,  ..., 2.7059e-06, 4.1236e-06,\n",
              "            2.0475e-06]),\n",
              "    'exp_avg_sq': tensor([2.7247e-12, 2.7337e-12, 2.7027e-12,  ..., 3.2344e-09, 3.3110e-09,\n",
              "            3.5144e-09]),\n",
              "    'step': 5104}}},\n",
              " 'scheduler_params': {'_last_lr': [0.001],\n",
              "  'best': 2.626015943419597,\n",
              "  'cooldown': 0,\n",
              "  'cooldown_counter': 0,\n",
              "  'eps': 1e-08,\n",
              "  'factor': 0.1,\n",
              "  'last_epoch': 14,\n",
              "  'min_lrs': [1e-06],\n",
              "  'mode': 'min',\n",
              "  'mode_worse': inf,\n",
              "  'num_bad_epochs': 0,\n",
              "  'patience': 10,\n",
              "  'threshold': 0.001,\n",
              "  'threshold_mode': 'rel',\n",
              "  'verbose': True}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiBBqVvdSpDv"
      },
      "source": [
        "#hype.load_checkpoint = False"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IobAIJgP8Ky",
        "outputId": "bc74c338-c17f-45bd-899d-907af8ad1fb7"
      },
      "source": [
        "if hype.load_checkpoint:\r\n",
        "  checkpoint = torch.load('seq2seq_attn_checkpoint.pth')\r\n",
        "\r\n",
        "  model.load_state_dict(checkpoint.model_params)\r\n",
        "  optimizer.load_state_dict(checkpoint.optim_params)\r\n",
        "  scheduler.load_state_dict(checkpoint.scheduler_params)\r\n",
        "  print(f\"epochs: {checkpoint.epoch_num} || loss: {checkpoint.losses}\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epochs: 6 || loss: [5.355511729620093, 4.436312052149757, 4.212425391128444, 3.977918492589251, 3.8003496959291656, 3.6709356165978604]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOB3y3DkiYdx"
      },
      "source": [
        "# model.state_dict()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJrZNBXRZCNy",
        "outputId": "d914bc0d-cddc-4374-b6fa-d4b28f47881d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vars(hype)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'BATCH_SIZE': 128,\n",
              " 'CLIP': 1,\n",
              " 'DEVICE': 'cpu',\n",
              " 'LR': 0.1,\n",
              " 'NUM_EPOCHS': 10,\n",
              " 'load_checkpoint': True,\n",
              " 'save_checkpoint': True}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "65649839b75e4461839b67b32a92a711",
            "1bcc0995b94c450c8eb5683552a0e6ab",
            "1d9b3d62c0c74b2e927b3cedcff6a84d",
            "761de3c3b44046deaaeadda67799b232",
            "7682f7ec71454ff1acf59f5ea0380813",
            "012f0f348cfb45099d6f540aea98fae1",
            "7b107e34362a475a9e24d319ee1eba33",
            "1395a12c6f084572a059be06a9b1156a"
          ]
        },
        "id": "3MucNUcv_pG9",
        "outputId": "da6cd500-49d5-4fcb-c91e-1fcf07b10544"
      },
      "source": [
        "epoch_t = notebook.trange(hype.NUM_EPOCHS, desc='loss')\r\n",
        "\r\n",
        "for epoch in epoch_t:\r\n",
        "\r\n",
        "  train_loss = train(model,train_iter, optimizer, criterion, hype.CLIP, hype.DEVICE)\r\n",
        "\r\n",
        "  checkpoint.epoch_num += 1 \r\n",
        "  checkpoint.model_params = model.state_dict()\r\n",
        "  checkpoint.optim_params = optimizer.state_dict()\r\n",
        "  checkpoint.scheduler_params = scheduler.state_dict()\r\n",
        "  checkpoint.losses.append(train_loss)\r\n",
        "\r\n",
        "  if hype.save_checkpoint:\r\n",
        "    torch.save(checkpoint,'seq2seq_attn_checkpoint.pth')\r\n",
        "    \r\n",
        "  scheduler.step(train_loss)\r\n",
        "\r\n",
        "  epoch_t.set_description(f\"loss: {train_loss: .5f}\")\r\n",
        "  epoch_t.refresh()\r\n",
        "  time.sleep(0.1)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65649839b75e4461839b67b32a92a711",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='loss', max=10.0, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-d9f0nIB0no"
      },
      "source": [
        "# # Saving a checkpoint\r\n",
        "\r\n",
        "# if hype.save_checkpoint:\r\n",
        "#   checkpoint.model_params = model.state_dict()\r\n",
        "#   checkpoint.optim_params = optimizer.state_dict()\r\n",
        "#   torch.save(checkpoint,'seq2seq_attn_checkpoint.pth')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdrO9trQnwK8"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBh_ugPXoshz"
      },
      "source": [
        "def translate_sentence(sentence, src_tokenizer, trg_tokenizer, src_vocab, trg_vocab, model, device, max_len = 50):\r\n",
        "\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    if isinstance(sentence, str):\r\n",
        "        tokens = [token.lower() for token in src_tokenizer(sentence)]\r\n",
        "    else:\r\n",
        "        tokens = [token.lower() for token in sentence]\r\n",
        "\r\n",
        "    tokens = [src_vocab['<sos>']] + tokens + [src_vocab['<eos>']]\r\n",
        "        \r\n",
        "    src_indexes = [src_vocab.stoi[token] for token in tokens]\r\n",
        "    \r\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\r\n",
        "\r\n",
        "    src_len = torch.LongTensor([len(src_indexes)]).to(device)\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "        encoder_outputs, hidden = model.encoder(src_tensor)\r\n",
        "\r\n",
        "    # mask = model.create_mask(src_tensor)\r\n",
        "        \r\n",
        "    trg_indexes = [trg_vocab.stoi[trg_vocab['<sos>']]]\r\n",
        "\r\n",
        "    # attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\r\n",
        "    \r\n",
        "    for i in range(max_len):\r\n",
        "\r\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\r\n",
        "                \r\n",
        "        with torch.no_grad():\r\n",
        "            output, hidden = model.decoder(trg_tensor, hidden, encoder_outputs,)\r\n",
        "\r\n",
        "        # attentions[i] = attention\r\n",
        "            \r\n",
        "        pred_token = output.argmax(1).item()\r\n",
        "        \r\n",
        "        trg_indexes.append(pred_token)\r\n",
        "\r\n",
        "        if pred_token == trg_vocab.stoi['<eos>']:\r\n",
        "            break\r\n",
        "    \r\n",
        "    trg_tokens = [trg_vocab.itos[i] for i in trg_indexes]\r\n",
        "    \r\n",
        "    return trg_tokens[1:]"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XCBSRPBq0yA",
        "outputId": "7dea6fdc-3db7-403f-8dc7-265e7a52ae88"
      },
      "source": [
        "sentence = data['marathi'][224]\r\n",
        "translation = data['english'][224]\r\n",
        "print(sentence)\r\n",
        "out = translate_sentence(sentence, tokenize_mar, tokenize_eng, mar_vocab, eng_vocab, model, hype.DEVICE)\r\n",
        "print(translation)\r\n",
        "print(out)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "टॉमला सावध कर.\n",
            "Warn Tom.\n",
            "['Tom', 'still', 'still', 'Tom', \"'s\", 'help', '.', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSJBY23Uq522"
      },
      "source": [
        "## BLEU Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW451gOXxAzQ"
      },
      "source": [
        "from torchtext.data.metrics import bleu_score"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqS9X-RowQrQ"
      },
      "source": [
        "def calculate_bleu_score(data, src_tokenizer, trg_tokenizer, src_vocab, trg_vocab, model, device):\r\n",
        "  \r\n",
        "  trgs = []\r\n",
        "  preds = []\r\n",
        "\r\n",
        "  for i in range(len(data)):\r\n",
        "    src = data['marathi'][i]\r\n",
        "    trg = data['english'][i]\r\n",
        "\r\n",
        "    trg = trg_tokenizer(trg)\r\n",
        "\r\n",
        "    pred = translate_sentence(src, src_tokenizer, trg_tokenizer, src_vocab, trg_vocab, model, device)\r\n",
        "\r\n",
        "    #preds.append(trg)\r\n",
        "    preds.append(pred[:-1])\r\n",
        "    trgs.append([trg])\r\n",
        "\r\n",
        "  return bleu_score(preds, trgs)"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CiLX7ikxAGD",
        "outputId": "1ea1aa3b-4d9d-4ba6-c9e6-18373dda6fd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "bleu = calculate_bleu_score(data, tokenize_mar, tokenize_eng, mar_vocab, eng_vocab, model, hype.DEVICE)\r\n",
        "print(f\"The BLEU score is {bleu*100:.2f}\")"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BLEU score is 3.27\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}